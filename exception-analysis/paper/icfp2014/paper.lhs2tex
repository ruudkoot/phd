\documentclass[authoryear,preprint]{sigplanconf}

%% FIXME: Rule [T-Abs] still introduces a bit of poisoning. A rule with more
%%        fresh variables would likely result in a nicer proof (as for [T-Fst]).
%% FIXME: mathtimes
%% FIXME: consistent terminology:
%%        - "our" vs. "the"
%%        - "arm" vs. "branch" vs. ?
%%        - product vs. pair vs. tuple
%%        - statement vs. expression

%% \rotatebox[origin=c]{180}{$\bigstar$}

\newenvironment{WORKINPROGRESS}{\color{BrickRed}}{\ignorespacesafterend}
\newcommand{\LORUMIPSUM}{\begin{WORKINPROGRESS}
Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
\end{WORKINPROGRESS}}
\newcommand{\BLAHBLAHBLAH}{\textcolor{BrickRed}{blah, blah, blah...}}

%include polycode.fmt
%include forall.fmt

%format do = "\textbf{do}"
%format return = "\textbf{return}"
%format case = "\textbf{case}"
%format of = "\textbf{of}"
%format if = "\textbf{if}"
%format then = "\textbf{then}"
%format else = "\textbf{else}"
%format type = "\textbf{type}"
%format where = "\textbf{where}"

%format crash (a) = "\lightning^{" a "}"

%format % = "\div"

%format ~~> = "\leadsto"
%format ~~~> = "\longrightarrow^{*}"
% format Ord = "\mathbf{Ord}"
%format alpha = "\alpha"
%format beta = "\beta"
%format beta_1 = "\beta_1"
%format beta_2 = "\beta_2"
%format tau = "\tau"
%format alphabeta = "\alpha\beta"
%format taualpha = "\tau\alpha"
%format bot = "\bot"
%format : = "\bm{::}"
%format :: = ":"
%format [ = "\bm{\left[}"
%format ] = "\bm{\right]}"
%format x_1
%format x_2
%format e_1
%format e_2
%format e_3
%format e_4
%format risers_1
%format risers_2
%format risers_3
%format N (a) = "\bm{[}" a "\bm{]}^{\SingletonNil}"
%format CL (a) = "\bm{[}" a "\bm{]}^{\SingletonCons}"
%format NC (a) = "\bm{[}" a "\bm{]}^{\SingletonNil \sqcup \SingletonCons}"
%format POLYV (a) (b) = "\bm{[}" a "\bm{]}^{" b "}"
%format LABELLEDLIST (a) (b) = "\bm{[}" a "\bm{]}^{" b "}"

%format rectype = "\textbf{rectype}"
%format /\ = "\land"
%format \/ = "\lor"
%format FPNil (a) = "\bm{\left[}\alpha\bm{\right]}^{\textbf{0}}"
%format FPSingleton (a) = "\bm{\left[}\alpha\bm{\right]}^{\textbf{1}}"
%format FPList (a) = "\bm{\left[}\alpha\bm{\right]}"
%format case_List = "\textbf{case}_{\bm{\left[\cdot\right]}}"

\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}

\usepackage{graphicx}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{tikz}
\usepackage{hyperref}
\usepackage{doi}

\usepackage[utf8]{inputenc}

\usepackage{xspace}

\usepackage{stmaryrd}
\usepackage{bm}
%\usepackage{bbm}

\usepackage{adjustbox}

%% Double-blind peer-review
\newcommand{\ANONYMOUS}[2]{#1}

%% Generic formatting stuff
\newcommand{\BigBreak}{\\[0.5\baselineskip]}
\newcommand{\MaybeBigBreak}{\\}

%% Generic text stuff
\newcommand{\ala}{\emph{\`a la}\xspace}

%% Generic math stuff
\newcommand{\isdef}{\stackrel{\text{def}}{=}}
\newcommand{\IndCase}[1]{\emph{Case} \CiteRule{#1}:}

%% Types
\newcommand{\Var}{\textbf{Var}}
\newcommand{\AnnVar}{\textbf{AnnVar}}
\newcommand{\Shape}{\textbf{Ty}}
\newcommand{\ShapeScheme}{\textbf{TySch}}

%% Syntax
\newcommand{\Crash}[1]{\lightning^{#1}}
\newcommand{\BTrue}{\textbf{true}}
\newcommand{\BFalse}{\textbf{false}}

\newcommand{\Abs}[2]{\lambda #1.#2}
\newcommand{\App}[2]{#1\ #2}
\newcommand{\Op}[2]{#1 \oplus #2}
\newcommand{\Let}[3]{\textbf{let}\ #1 = #2\ \textbf{in}\ #3}
\newcommand{\Fix}[2]{\textbf{fix}\ #1.\ #2}
\newcommand{\IfThenElse}[3]{\textbf{if}\ #1\ \textbf{then}\ #2\ \textbf{else}\ #3}
\newcommand{\Pair}[2]{\bm{\left(}#1\bm{,} #2\bm{\right)}}
\newcommand{\Fst}[1]{\textbf{fst}\ #1}
\newcommand{\Snd}[1]{\textbf{snd}\ #1}
\newcommand{\LNil}{\bm{\left[\right]}}
\newcommand{\LCons}[2]{#1 \bm{::} #2}
\newcommand{\Case}[5]{\textbf{case}\ #1\ \textbf{of} \left\{ \LNil \mapsto #2; #3 \bm{::} #4 \mapsto #5 \right\}}
\newcommand{\CaseBREAK}[5]{\textbf{case}\ #1\ \textbf{of}\\\left\{ \LNil \mapsto #2; #3 \bm{::} #4 \mapsto #5 \right\}}
\newcommand{\Bind}[2]{\textbf{bind}\ #1\ \textbf{in}\ #2}
\newcommand{\Close}[2]{\textbf{close}\ #1\ \textbf{in}\ #2}
\newcommand{\CloseEMPH}[2]{\emph{\textbf{close}}\ #1\ \emph{\textbf{in}}\ #2}

\newcommand{\PMF}{\textbf{pattern-match-failure}\xspace}

%% Semantics
\newcommand{\Eval}[4]{\left<#1; #2\right> \Downarrow \left<#3;#4\right>}
\newcommand{\Transform}[1]{\widehat{#1}}

\newcommand{\Reduce}[3][\rho]{#1~\vdash~#2 \longrightarrow~#3}
\newcommand{\InterpretOp}[1]{\llbracket #1 \rrbracket}

%% Typing
\newcommand{\Rule}[3]{\frac{#2}{#3}\mbox{\ [\textsc{#1}]}}
\newcommand{\CiteRule}[1]{\mbox{[\textsc{#1}]}}
\newcommand{\Judge}[3][C; \Gamma]{{#1 \vdash #2 : #3}}              %declarative
\newcommand{\JudgeUL}[3][C; \Gamma]{{#1 \vdash_{\mathrm{UL}} #2 : #3}}   %underlying
\newcommand{\Centail}[2][C]{{#1 \Vdash #2}}
\newcommand{\CM}[2][\theta]{{#1 \vDash #2}}
\newcommand{\Ref}{\delta}
\newcommand{\Exn}{\chi}
\newcommand{\Judgement}[5][\Gamma]{#1 \vdash #2 : #3 \leadsto #4\ \&\ #5} %algo
\newcommand{\PmSch}{\sigma}
\newcommand{\PmTy}{\varsigma}
\newcommand{\Sh}{\tau}
\newcommand{\ShSch}{\sigma}
\newcommand{\TopLevel}[1]{\lceil #1\rceil}
\newcommand{\Fresh}{\ \mathrm{fresh}}
\newcommand{\SUBST}[1]{#1\!\left[\overline{\beta}/\overline{\alpha}\right]}
\newcommand{\TyBool}{\mathbb{B}}
\newcommand{\TyInt}{\mathbb{Z}}
\newcommand{\TyFun}[3]{#1 \xrightarrow{#3} #2}
\newcommand{\TyPair}[3]{#1 \bm{\times}^{#3} #2}
\newcommand{\TyList}[2]{\bm{\left[}#1\bm{\right]}^{#2}}
\newcommand{\TyForall}[3]{\forall\overline{#1}.\ #2\ \textbf{with}\ #3}
\newcommand{\TyForallNOOVERLINE}[3]{\forall #1.\ #2\ \textbf{with}\ #3}
\newcommand{\E}{\textbf{Nil}}
\newcommand{\NE}{\textbf{Cons}}

\newcommand{\EC}[3][C]{{#1 \vdash #2 \bowtie #3}}

\newcommand{\SingletonTrue}{\textbf{T}}
\newcommand{\SingletonFalse}{\textbf{F}}
\newcommand{\SingletonNeg}{\textbf{-}}
\newcommand{\SingletonZero}{\textbf{0}}
\newcommand{\SingletonPos}{\textbf{+}}
\newcommand{\SingletonNil}{\textbf{N}}
\newcommand{\SingletonCons}{\textbf{C}}

%% Constraints
\newcommand{\AnnLat}{\Lambda}
\newcommand{\CC}[5][]{#2 \sqsubseteq_\Ref #3 \Rightarrow #4 \leq_{#1} #5}
\newcommand{\CCS}[5][]{#2 \sqsubseteq_\Ref #3 \Rightarrow #4 \sqsubseteq_{#1} #5}
\newcommand{\CCD}[6][]{#2 \sqsubseteq_\Ref #3 \lor #4 \Rightarrow #5 \leq_{#1} #6}
\newcommand{\CCDO}[6][]{#2 \sqsubseteq_{\Ref_{1}} #3 \lor #4 \Rightarrow #5 \leq_{#1} #6}

%% Extensions
\newcommand{\MP}[2]{#1~\star~#2}

%% Theorems
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{conjecture}{Conjecture}
\newtheorem{lemma}{Lemma}
\newtheorem{conjectured-lemma}{Lemma}
\theoremstyle{definition}
\newtheorem{mydef}{Definition}

\begin{document}

\conferenceinfo{ICFP '14}{September 1--3, 2014, Gothenburg, Sweden.}
\copyrightyear{2014}
\copyrightdata{[to be supplied]} 

\titlebanner{DRAFT---Do not distribute}
\preprintfooter{Submitted to ICFP '14}

\title{Type-based Exception Analysis for\\Non-strict Higher-order Functional Languages\\with Imprecise Exception Semantics}

\authorinfo{\ANONYMOUS{Ruud Koot}{Robb Stark}\thanks{This material is based upon work supported by the \ANONYMOUS{Netherlands Organisation for Scientific Research (NWO)}{Night's Watch}.}\and \ANONYMOUS{Jurriaan Hage}{Daenerys Targaryen}}
{Department of Computing and Information Sciences\\Utrecht University}
{\ANONYMOUS{\{r.koot,j.hage\}@@uu.nl}{\{r.stark,d.targaryen\}@@winterfell.no}}
%\authorinfo{Robb Stark\thanks{This material is based upon work supported by the \ANONYMOUS{Netherlands Organisation for Scientific Research (NWO)}{Night's Watch}.}}
%{Winterfell University\\Westeros}{r.stark@@winterfell.no}
%\authorinfo{Daenerys Targaryen}{Astapor Academy\\Essos}{d.targaryen@@astapor.es}

\maketitle

\begin{abstract}
Most statically typed functional programming languages allow programmers to write partial functions: functions that are not defined on all the elements of the domain they are claimed to work on by their type. Thus in practise, well-typed programs can---and \emph{do}---still go wrong.
A compiler should warn the programmer about the places in the program where such wrongness may occur. 

Contemporary compilers for functional languages employ a local and purely syntactic analysis to detect incomplete \textbf{case}-expressions---those that do not cover all possible patterns of constructors allowed for by the type of the scrutinee, the source of most partiality in a program.
As programs often maintain invariants on their data---restricting the potential values of the scrutinee to a subtype of its given or inferred type---many of these incomplete \textbf{case}-expressions are in actuality completely benign.
Such an analysis will thus report many false positives, overwhelming the programmer.

We develop and prove the correctness of a constraint-based type system that detects harmful sources of partiality by accurately tracing the flow of both exceptions---the manifestation of partiality gone wrong---and ordinary data through the program, as well as the dependencies between them.
The latter is crucial for usable precision, but has been omitted from previously published exception analyses.
\end{abstract}

% FIXME: add/remove categories (http://www.acm.org/about/class/ccs98-html, or 2012?)
\category{D.2.4}{Software Engineering}{Software/Program Verification}
%\category{D.3}{Software}{Applicative (functional) languages}
%\category{D.3.3}{Programming Languages}{Language Constructs and Features}[Polymorphism]
%\category{F.3.1}{Logics and Meanings of Programs}{Specifying and Verifying and Reasoning about Programs}[Logics of programs]
\category{F.3.1}{Logics and Meanings of Programs}{Specifying and Verifying and Reasoning about Programs}[Mechanical verification]
\category{F.3.2}{Logics and Meanings of Programs}{Semantics of Programming Languages}[Program analysis]
%\category{F.3.3}{Logics and Meanings of Programs}{Studies of Program Constructs}[Type structure]

% FIXME: what to put here?
\terms
Languages, Theory, Verification

% FIXME: add/remove keywords
\keywords
type-based program analysis, exception analysis, imprecise exceptions, pattern-matching, polymorphic recursion, static contract checking

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}\label{sec-introduction} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Many modern programming languages come equipped with a type system. Type systems attempt to prevent bad behaviour at run-time by rejecting programs that may cause such behaviour at compile-time. As predicting the dynamic behaviour of an arbitrary program is undecidable, type systems---or at least those in languages relying on type inference---will always have to either reject some programs that can never cause bad behaviour, or accept some that do.

A major source of trouble are \emph{partial functions}---functions that are not defined on all the elements of their domain, usually because they cannot be given any sensible definition on some of those elements. Canonical examples include the division operator, which is undefined when its right-hand argument is zero, and the |head| function, extracting the first element from a list, which is undefined on the empty list. %FIXME: openFile
Outright rejecting such functions does not seem like a reasonable course of action, so we are only left with the possibility of accepting them as well-typed at compile-time and having them raise an \emph{exception} at run-time, when invoked on an element in their domain on which they were left undefined.

Still, we would like to warn the programmer when we accept a correctly typed program that may potentially crash due to an exception at run-time. Most compilers for functional languages will already emit a warning when a function is defined by a non-exhaustive pattern-match, listing the missing patterns. These warnings are generated by a very local and syntactic analysis, however, generating many false positives, distracting the programmer. For example, they will complain the |head| function is missing a clause for the empty list, even if |head| is only ever invoked on a syntactically non-empty list, or not at all. Worse still are spurious warnings for local let-bound functions, for which one can no longer argue the warning is useful, as the function cannot be called from a different context at a future time.

Unlike other exception analyses that have appeared in the literature---%FIXME: list 'em
which primarily attempt to track uncaught user-thrown or environment-induced exceptions, such as those that could be encountered when reading invalid data from disk---we are first and foremost concerned with accurately tracking the exceptions raised by failed pattern-matches. Therefore, our analysis might equally well be called a \emph{pattern-match analysis}, although it is certainly not strictly limited to one as such. To get results of usable accuracy---eliminating as many false positives as possible---requires carefully keeping track of the data-flow through the program. This additionally improves the accuracy of reporting potential exceptions not related to pattern matching and opens the way for employing the analysis to perform static contract checking.

\subsection{Contributions}

Our contributions include the following:
\begin{itemize}
\item We develop a type-driven---and thus \emph{modular}---exception analysis that tracks data flow in order to give accurate warnings about exceptions raised due to pattern-match failures.
\item Accuracy is achieved through the simultaneous use of \emph{subtyping} (modelling data flow), \emph{conditional constraints} (modelling control flow), \emph{parametric polyvariance} (to achieve context-sensitivity) and \emph{polyvariant recursion} (to avoid poisoning).
\item The analysis works for \emph{call-by-name} languages with an \emph{imprecise exception semantics}. Such a semantics is necessary to justify several program transformations applied by optimizing compilers for call-by-name languages with distinguishable exceptions%, but---perhaps counterintuitively---complicates precisely analyzing them.
\item We give an operational semantics for imprecise exceptions and prove the analysis sound with respect to this semantics.
\item The analysis presented in this paper is implemented as a prototype and, in addition to a pen-and-paper proof, the metatheory has been mostly mechanized in Coq. Both are available \ANONYMOUS{from: \url{http://www.staff.science.uu.nl/~0422819/tbea/}}{as supplementary materials}.
\end{itemize}

\subsection{Overview}
In Section~\ref{sec-motivation} we give a number of examples where we, as a programmer, would like to be presented with more accurate warnings---about possible exceptions a program can raise or pattern-match failures that can occur at run-time---than compilers will currently provide.
In Section~\ref{sec-informalities} we give an informal overview of how this problem can be addressed using a type system, and the features such a type system should support in order to obtain sufficiently accurate results.
In Section~\ref{sec-formalities} we present a formalized static and dynamic semantics and state a number metatheoretic result to prove the soundness of our analysis.
In Section~\ref{sec-algorithm} we discuss the algorithmic issues complicating the automatic inference of types in our proposed type system and how they can be overcome. In Section~\ref{sec-extensions} we discuss a number of extensions to the exception analyis and indicate a number of directions for future research. Finally, we discuss the related work on exception and pattern-match analyses in Section~\ref{sec-relatedwork}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Motivation}\label{sec-motivation} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Many algorithms maintain invariants on the data structures they use, that cannot easily be encoded into their types. These invariants often ensure that certain incomplete \textbf{case}-expressions are guaranteed not to cause a pattern-match failure.

\subsection{\emph{risers}} \label{sec-risers} %%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

An example of such an algorithm is the |risers| function from \cite{Mitchell:2008:PBE:1411286.1411293}, computing monotonically increasing subsegments of a list:
\begin{center}
\begin{code}
risers  ::  Ord alpha => [alpha] -> [[alpha]]
risers  []               =  []
risers  [x]              =  [[x]]
risers (x_1 : x_2 : xs)  =
    if x_1 <= x_2 then (x_1 : y) : ys else [x_1] : (y : ys)
        where (y : ys) = risers (x_2 : xs)
\end{code}
\end{center}
For example:
\begin{center}
|risers [1, 3, 5, 1, 2] ~~~> [[1, 3, 5], [1, 2]]|.
\end{center}

The irrefutable pattern in the \textbf{where}-clause in the third alternative of |risers| expects the recursive call to return a non-empty list. A naive analysis might raise a warning here. If we think a bit longer, however, we see that we also pass the recursive call to |risers| a non-empty list. This means we will end up in either the second or third alternative inside the recursive call. Both the second alternative and both branches of the \textbf{if}-expression in the third alternative produce a non-empty list, satisfying the assumption we made earlier and allowing us to conclude that this functional is total and will never raise a pattern-match failure exception. (Raising or propagating an exception because we pattern-match on exceptional values present in the input still belongs to the possibilities, though.)

\subsection{\emph{bitstring}} %%%%%%%%%%%%%%%%%%%%%%%%%%
%format Integer = "\mathbb{Z}"
Another example, from \cite{Freeman:1991:RTM:113445.113468}, comprises a collection of mathematical operations working on bitstrings: integers encoded as lists of the binary digits 0 and 1, with the least significant bit first. We model bitstrings as the type
\begin{center}
\begin{code}
type Bitstring = [Integer]
\end{code}
\end{center}
This type is a too lenient in that it does not restrict the elements of the lists to the digits 0 and 1. We can however maintain this property as an implicit invariant.

If we now define an addition operation on bitstrings:
\begin{center}
\begin{code}
add :: Bitstring -> Bitstring -> Bitstring
add []      y      = y
add x       []     = x
add (0:x)   (0:y)  = 0 : add x y
add (0:x)   (1:y)  = 1 : add x y
add (1:x)   (0:y)  = 1 : add x y
add (1:x)   (1:y)  = 0 : add (add [1] x) y
\end{code}
\end{center}
we see that the patterns in |add| are far from complete. However, if only passed arguments that satisfy the invariant it will neither crash due to a pattern-match failure, nor invalidate the invariant.

\subsection{\emph{desugar}}\label{sec-desugar} %%%%%%%%%

Compilers work with large and complex data types to represent the abstract syntax tree. These data structures must be able to represent all syntactic constructs the parser is able to recognize. This results in an abstract syntax tree that is unnecessarily complex, and too cumbersome for the later stages of the compiler---such as the optimizer---to work with. This problem is resolved by \emph{desugaring} the original abstract syntax tree into a simpler---but semantically equivalent---abstract syntax tree that does not use all of the constructors available in the original abstract syntax tree.

The compiler writer now has a choice between two different options: either write a desugaring stage |desugar :: ComplexAST -> SimpleAST|---duplicating most of the data type representing and functions operating on the abstract syntax tree---or take the easy route |desugar :: AST -> AST| and assume certain constructors will no longer be present in the abstract syntax tree at stages of the compiler executed after the desugaring step. The former has all the usual downsides of code duplication---such as having to manually keep multiple data types synchronized---while the latter forgoes many of the advantages of strong typing and type safety: if the compiler pipeline is restructured and one of the stages that was originally assumed to run only after the desugaring suddenly runs before that point the error might only be detected at run-time by a pattern-match failure. A pattern-match analysis should be able to detect such errors statically.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Informalities}\label{sec-informalities} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We formulate our analysis in terms of a constraint-based type and effect system \cite{Talpin:1994:TED:191349.184660,Abadi:1999:CCD:292540.292555}.

\subsection{Data flow}

How would we capture the informal reasoning we used in Section~\ref{sec-risers} to convince ourselves that |risers| does not cause a pattern-match failure using a type system? A reasonable first approach would be to annotate all list types with the kind of list it can be: $\SingletonNil$ if it must be an empty list, a list that that necessary has a nil-constructor at the head of its spine; $\SingletonCons$ if it must be a non-empty list having a cons-constructor at its head; $\SingletonNil \sqcup \SingletonCons$ if it can be either. We can then assign to each of the three individual branches of |risers| the following types:
\begin{center}
\begin{code}
risers_1 :: forall alpha. Ord alpha => N alpha -> N (NC alpha)
risers_2 :: forall alpha. Ord alpha => CL alpha -> CL (NC alpha)
risers_3 :: forall alpha. Ord alpha => CL alpha -> CL (NC alpha)
\end{code}
\end{center}
From the three individual branches we may infer:
\begin{center}
\begin{code}
risers :: forall alpha. Ord alpha => NC alpha -> NC (NC alpha)
\end{code}
\end{center}

Assigning this type to |risers| will still let us believe that a pattern-match failure may occur in the irrefutable pattern in the \textbf{where}-clause, as this type tells us any invocation of |risers|---including the recursive call in the \textbf{where}-clause---may evaluate to an empty list.
The problem is that |risers_1|---the branch that can never be reached from the call in the \textbf{where}-clause---is \emph{poisoning} the overall result. \emph{Polyvariance} (or \emph{property polymorphism}) can rescue us from this precarious situation, however. We can instead assign to each of the branches, and thereby the overall result, the type:
\begin{center}
\begin{code}
risers :: forall alphabeta. Ord alpha => POLYV alpha beta -> POLYV (NC alpha) beta
\end{code}
\end{center}

In the recursive call to |risers| we know the argument passed is a non-empty list, so we can instantiate $\beta$ to $\SingletonCons$, informing us that the result of the recursive call will be a non-empty list as well and guaranteeing that the irrefutable pattern-match will succeed.
There is one little subtlety here, though: in a conventional Hindley--Milner type system we are not allowed, or even able, to instantiate $\beta$ to anything, as the type is kept monomorphic for recursive calls. We, therefore, have to extend our type system with \emph{polyvariant recursion}.
While inferring polymorphic recursive types is undecidable in general \cite{Kfoury:1993:TRP:169701.169687,Henglein:1993:TIP:169701.169692}---and, %FIXME: citation
being a program analysis, we cannot rely on any programmer-supplied annotations---earlier research \cite{Tofte:1994:ITC:174675.177855,Dussart:1995:PRS:647163.717680,Rittri:1995:DIU:224164.224197,Leroy:2000:TAU:349214.349230} has shown that this special case of polyvariant recursion is often both crucial to obtain adequate precision and feasible to infer automatically.

\subsection{Exception flow}

The intentention of our analysis it to track the exceptions that may be raised during the execution of a program. As with the data flow we express this set of exceptions as an annotation on the type of a program. For example, the program:
\begin{center}
\begin{code}
f x = x % 0
\end{code}
\end{center}
should be given the exception type:
%format Integer_alpha = "\mathbb{Z}^\alpha"
%format Integer_alpha_divbyzero = "\mathbb{Z}^{\alpha \sqcup \textbf{division-by-zero}}"
%format -_|_> = "\xrightarrow{\emptyset}"
\begin{center}
\begin{code}
f :: forall alpha. Integer_alpha -_|_> Integer_alpha_divbyzero
\end{code}
\end{center}

This type explains that $f$ is a function accepting an integer as its first and only parameter. As we are working in a call-by-name language, this integer might actually still be a thunk that raises an exception from the set $\alpha$ when evaluated. The program then divides this argument by zero, returning the result. While the result will be of type integer, this operation is almost guaranteed to raise a division-by-zero exception. It is \emph{almost} guaranteed and not completely guaranteed to raise a division-by-zero exception, as the division operator is strict in both of its arguments and might thus force the left-hand side argument to be evaluated before raising the \textbf{division-by-zero} exception. This evaluation might then in turn cause an exception from the set $\alpha$ to be raised first. The complete result type is thus an integer with an exception annotation consisting of the union (or \emph{join}) of the exception set $\alpha$ on the argument together with an additional exception \textbf{division-by-zero}. Finally, we note that there is an empty exception set annotating the function space constructor, indicating that no exceptions will be raised when evaluating $f$ to a closure.

While this approach seems promising at first, it is not immediately adequate for our puropose: detecting potential pattern-match failures that may occur at run time. Consider the following program:
\begin{center}
\begin{code}
head (x : xs) = x
\end{code}
\end{center}
After an initial desugaring step, a compiler will translate this program into:
%format |-> = "\mapsto"
%format pmf = "\PMF"
\begin{center}
\begin{code}
head xs = case  xs of
                []      |->  crash pmf
                y : ys  |->  y
\end{code}
\end{center}
which can be assigned the exception type:
%format tau_alpha = "\tau^\alpha"
%format tau_alpha_beta_pfm = "\tau^{\alpha\sqcup\beta\sqcup\PMF}"
%format taualphabeta = "\tau\alpha\beta"
\begin{center}
\begin{code}
head :: forall taualphabeta. LABELLEDLIST tau_alpha beta -_|_> tau_alpha_beta_pfm
\end{code}
\end{center}
This type tells us that |head| might always raise a \PMF exception, irrespective of what argument is applied to. Clearly, we won't be able to outperform a simple syntactic analysis in this manner.
What we need is a way to introduce a dependency of the exception flow on the data flow of the program, so we can express that |head| will only raise a \PMF if it possible for the argument passed to it to be an empty list. We can do so by introducing conditional constraints into our type system:
%format tau_abc = "\tau\alpha\beta\gamma"
%format tau_alpha_beta = "\tau^{\alpha\sqcup\beta\sqcup\gamma}"
%format constraint_set_thing = "\textbf{with} \left\{\SingletonNil \sqsubseteq \beta \Rightarrow \PMF \sqsubseteq \gamma\right\}"
\begin{code}
head :: forall tau_abc.  LABELLEDLIST tau_alpha beta -_|_> tau_alpha_beta
                         constraint_set_thing
\end{code}
This type explains that |head| will return an element of type $\tau$ that might---when inspected---raise any exception present in the elements of the list ($\alpha$), the spine of the list ($\beta$) or from an additional set of exceptions ($\gamma$), with the constraint that if the list to which |head| is applied is empty, then this exception set contains the \PMF exception, otherwise it is taken to be empty.
(We apologize for the slight abuse of notation---using the annotation $\beta$ to hold both data and exception-flow information---this will be remedied in the formal type system.)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Formalities}\label{sec-formalities} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Language} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

As our language of discourse we take a call-by-name $\lambda$-calculus with booleans, integers, pairs, lists, exceptional values, general recursion, let-bindings, pattern-matching, and a set of primitive operators:

%% Syntax %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\begin{figure}[h]
\begin{eqnarray*}
v &::=& b
  \quad || \quad n
  \quad || \quad \Crash{\ell}
  \quad || \quad \LNil
  \quad || \quad \Close{e}{\rho}\\
\\
e &::=& x
  \quad || \quad v
  \quad || \quad \Abs{x}{e}
  \quad || \quad \Fix{f}{e}
  \quad || \quad \App{e_1}{e_2}\\
  & || & \Let{x}{e_1}{e_2}
  \quad || \quad \IfThenElse{e_1}{e_2}{e_3}\\
  & || & \Op{e_1}{e_2}
  \quad || \quad \Pair{e_1}{e_2}
  \quad || \quad \Fst{e}
  \quad || \quad \Snd{e}\\
  & || & \LCons{e_1}{e_2}
  \quad || \quad \Case{e_1}{e_2}{x_1}{x_2}{e_3}\\
  & || & \Bind{\rho}{e}\\
\\ % Syntactic domains
&&b \in \TyBool \quad
n \in \TyInt \quad
f, x \in \textbf{Var} \quad
\ell \in \mathcal{P}\left(\textbf{Lbl}\right) %\quad
%\oplus \in \mathbf{Op}
\end{eqnarray*}
%\caption{Syntax}
%\label{fig-syntax}
%\end{figure}

\paragraph{Syntax} The values $v$ of the language include an exceptional value $\Crash{\ell}$ where the annotation $\ell$ denotes a set of \emph{exception labels}. We leave the exception labels uninterpreted, but an actual implementation will use them to distinguish between distinct exceptions (for example, division-by-zero or a pattern-match failure), as well as to store any additional information necessary to produce informative error messages, such as source locations.

We adopt the following syntactic convention: we denote non-exceptional values by $v$ and possibly exceptional values by $v^\ell$, where $\ell$ corresponds to the set of exception labels in case $v^\ell$ is an exceptional value and corresponding to the empty set otherwise.

The \textbf{case}-construct in the language is always assumed to be complete. As our primary goal is to detect pattern-match failures produced by incomplete \textbf{case}-expressions, we assume any incomplete \textbf{case}-expression written by the programmer has first been appropriately desugared into an equivalent complete \textbf{case}-expression by filling out any missing arms in the incomplete \textbf{case}-expression with an exceptional value $\Crash{\PMF}$ before being passed to the analysis \cite{Augustsson:1985:CPM:5280.5303,Maranget:2008:CPM:1411304.1411311}.

The $\textbf{close}$ and $\textbf{bind}$ constructs are only necessary to formalize the small-step operational semantics (Section \ref{sec-operational-semantics}) and are assumed to be absent from the program under analysis.

As call-by-name languages model exceptions as exceptional values, instead of exceptional control-flow, we do not need a \textbf{throw} or \textbf{raise}-construct. As most call-by-name languages omit a \textbf{catch}-construct, we shall do so as well.

\paragraph{Static semantics} We assume that the program is well-typed according to the canonical monomorphic type system and the underlying type of each subexpression is available to the analysis.
In Section~\ref{sec-polymorphism} we discuss how the analysis can be extended to a language with a polymorphic underlying type system.

\subsection{Types} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Shapes %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The types $\tau \in \Shape$ of the type system are given by:
\begin{eqnarray*}
\Sh    &::=& \alpha
       \quad || \quad \TyFun{\Sh_1}{\Sh_2}{\alpha}
       \quad || \quad \TyPair{\Sh_1}{\Sh_2}{\alpha}
       \quad || \quad \TyList{\Sh}{\alpha}
\end{eqnarray*}
Types are \emph{simply annotated types}, comprised of a single base type consisting of an \emph{annotation variable} $\alpha \in \AnnVar$ and the compound types for functions, pairs and lists, each having its constructor annotated with an annotation variable.
Simply annotated types are given meaning in combination with a mapping or substitution from its free annotation variables to a lattice $\AnnLat$, forming $\AnnLat$-annotated types.

The auxiliary function $\left\lceil\ \cdot\ \right\rceil : \Shape \to \AnnVar$ extracts the outer-most annotation from a simply annotated type~$\Sh$:
\begin{eqnarray*}
\begin{aligned}
\left\lceil \alpha                        \right\rceil &= \alpha             \\
\left\lceil \TyFun{\Sh_1}{\Sh_2}{\alpha}  \right\rceil &= \alpha
\end{aligned}
\quad\quad\quad\quad
\begin{aligned}
\left\lceil \TyPair{\Sh_1}{\Sh_2}{\alpha} \right\rceil &= \alpha             \\
\left\lceil \TyList{\Sh}{\alpha}          \right\rceil &= \alpha
\end{aligned}
\end{eqnarray*}

A type $\Sh$ can be combined with a constraint set $C$ (Section~\ref{sec-constraints}) and have some of its free annotation variables quantified over into a type scheme~$\sigma \in \ShapeScheme$:
\begin{eqnarray*}
\ShSch &::=& \TyForall{\alpha}{\Sh}{C}
\end{eqnarray*}
%(We prefer the notation $\TyForall{\alpha}{\Sh}{C}$ over the standard notation $\forall\overline{\alpha}.\ C\Rightarrow\tau$ for \emph{qualified types} in order to avoid confusion with the \emph{conditional constraints} introduced later.)

\subsection{Environments}
An environment $\Gamma$ binds variables to type schemes and an environment $\rho$ binds variables to expressions:
\begin{eqnarray*}
\Gamma &::=& \epsilon
  \quad || \quad \Gamma, x : \sigma\\
\rho &::=& \epsilon
  \quad || \quad \rho, x : e
\end{eqnarray*}
As environments can be permuted, so long as shadowing of variables is not affected, we take the liberty of writing $\Gamma, x : \tau$ and $\rho, x : e$ to match the nearest (most recently bound) variable $x$ in an environment.


%% Instrumented semantics %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Operational semantics}\label{sec-operational-semantics}

The operational semantics of the language is given in Figure~\ref{fig-operational-semantics} and models a call-by-name language with an \emph{imprecise exception semantics} \cite{PeytonJones:1999:SIE:301618.301637}.

The small-step reduction relation $\Reduce{e}{e'}$ has an explicit environment $\rho$, mapping variables to expressions (not necessarily values). Closures are represented by the operator $\Close{e}{\rho}$, which closes the expression $e$ in the environment $\rho$. The operator $\Bind{\rho}{e}$ binds the free variables in the expression $e$ to expressions in the environment $\rho$. While similar there is one important distinction between the \textbf{close} and the \textbf{bind}-construct: a closure $\Close{e}{\rho}$ is a value, while a \textbf{bind}-expression can still be reduced further.

\begin{figure*}[t]
\begin{gather*}
\Rule{E-Var}
     {}
     {\Reduce[\rho, x : e]{x}{\Bind{\rho}{e}}}
     \quad
\Rule{E-Abs}
     {}
     {\Reduce{\Abs{x}{e}}{\Close{\Abs{x}{e}}{\rho}}}
     \MaybeBigBreak
\Rule{E-App}
     {\Reduce{e_1}{e_1'}}
     {\Reduce{\App{e_1}{e_2}}{\App{e_1'}{e_2}}}
     \quad
\Rule{E-AppAbs}
     {}
     {\Reduce{\App{(\Close{\Abs{x}{e_1}}{\rho_1})}{e_2}}{\Bind{\left(\rho_1, x : \Bind{\rho}{e_2}\right)}{e_1}}}
     \MaybeBigBreak
\Rule{E-AppExn1}
     {\Reduce{e_2}{e_2'}}
     {\Reduce{\App{\Crash{\ell_1}}{e_2}}{\App{\Crash{\ell_1}}{e_2'}}}
     \quad
\Rule{E-AppExn2}
     {}
     {\Reduce{\App{\Crash{\ell_1}}{v_2^{\ell_2}}}{\Crash{\ell_1 \sqcup \ell_2}}}
     \MaybeBigBreak
\Rule{E-Let}
     {}
     {\Reduce{\Let{x}{e_1}{e_2}}{\Bind{\left(\rho, x : \Bind{\rho}{e_1}\right)}{e_2}}}
     \quad
\Rule{E-Fix}
     {}
     {\Reduce{\Fix{f}{e}}{\Bind{\left(\rho, f : \Bind{\rho}{\Fix{f}{e}}\right)}{e}}}
     \MaybeBigBreak
\Rule{E-If}
     {\Reduce{e_1}{e_1'}}
     {\Reduce{\IfThenElse{e_1}{e_2}{e_3}}{\IfThenElse{e_1'}{e_2}{e_3}}}
     \quad
\Rule{E-IfTrue}
     {}
     {\Reduce{\IfThenElse{\BTrue}{e_2}{e_3}}{e_2}}
     \MaybeBigBreak
\Rule{E-IfFalse}
     {}
     {\Reduce{\IfThenElse{\BFalse}{e_2}{e_3}}{e_3}}
     \quad
\Rule{E-IfExn1}
     {\Reduce{e_2}{e_2'}}
     {\Reduce{\IfThenElse{\Crash{\ell_1}}{e_2}{e_3}}{\IfThenElse{\Crash{\ell_1}}{e_2'}{e_3}}}
     \MaybeBigBreak
\Rule{E-IfExn2}
     {\Reduce{e_3}{e_3'}}
     {\Reduce{\IfThenElse{\Crash{\ell_1}}{e_2}{e_3}}{\IfThenElse{\Crash{\ell_1}}{e_2}{e_3'}}}
     \quad
\Rule{E-IfExn3}
     {}
     {\Reduce{\IfThenElse{\Crash{\ell_1}}{v_2^{\ell_2}}{v_3^{\ell_3}}}{\Crash{\ell_1 \sqcup \ell_2 \sqcup \ell_3}}}
     \MaybeBigBreak
\Rule{E-Op1}
     {\Reduce{e_1}{e_1'}}
     {\Reduce{\Op{e_1}{e_2}}{\Op{e_1'}{e_2}}}
     \quad
\Rule{E-Op2}
     {\Reduce{e_2}{e_2'}}
     {\Reduce{\Op{e_1}{e_2}}{\Op{e_1}{e_2'}}}
     \quad
\Rule{E-OpNum}
     {}
     {\Reduce{\Op{n_1}{n_2}}{\InterpretOp{\Op{n_1}{n_2}}}}
     \MaybeBigBreak
\Rule{E-OpExn1}
     {}
     {\Reduce{\Op{\Crash{\ell_1}}{n_2}}{\Crash{\ell_1}}}
     \quad
\Rule{E-OpExn2}
     {}
     {\Reduce{\Op{n_1}{\Crash{\ell_2}}}{\Crash{\ell_2}}}
     \quad
\Rule{E-OpExn3}
     {}
     {\Reduce{\Op{\Crash{\ell_1}}{\Crash{\ell_2}}}{\Crash{\ell_1 \sqcup \ell_2}}}
     \MaybeBigBreak
\Rule{E-Pair}
     {}
     {\Reduce{\Pair{e_1}{e_2}}{\Close{\Pair{e_1}{e_2}}{\rho}}}
     \quad
\Rule{E-Fst}
     {\Reduce{e}{e'}}
     {\Reduce{\Fst{e}}{\Fst{e'}}}
     \quad
\Rule{E-Snd}
     {\Reduce{e}{e'}}
     {\Reduce{\Snd{e}}{\Snd{e'}}}
     \MaybeBigBreak
\Rule{E-FstPair}
     {}
     {\Reduce{\Fst{\left(\Close{\Pair{e_1}{e_2}}}{\rho_1}\right)}
             {\Bind{\rho_1}{e_1}}
     }
     \quad
\Rule{E-SndPair}
     {}
     {\Reduce{\Snd{\left(\Close{\Pair{e_1}{e_2}}}{\rho_1}\right)}
             {\Bind{\rho_1}{e_2}}
     }
     \MaybeBigBreak
\Rule{E-FstExn}
     {}
     {\Reduce{\Fst{\Crash{\ell}}}{\Crash{\ell}}}
     \quad
\Rule{E-SndExn}
     {}
     {\Reduce{\Snd{\Crash{\ell}}}{\Crash{\ell}}}
     \quad
\Rule{E-Cons}
     {}
     {\Reduce{\LCons{e_1}{e_2}}{\Close{\LCons{e_1}{e_2}}{\rho}}}
     \MaybeBigBreak
\Rule{E-Case}
     {\Reduce{e_1}{e_1'}}
     {\Reduce{\Case{e_1}{e_2}{x_1}{x_2}{e_3}}{\Case{e_1'}{e_2}{x_1}{x_2}{e_3}}}
     \MaybeBigBreak
\Rule{E-CaseNil}
     {}
     {\Reduce{\Case{\LNil}{e_2}{x_1}{x_2}{e_3}}{e_2}}
     \MaybeBigBreak
\Rule{E-CaseCons}
     {}
     {\Reduce{\Case{\left(\Close{\LCons{e_1}{e_1'}}{\rho_1}\right)}{e_2}{x_1}{x_2}{e_3}\!}{\!\!\Bind{\left(\rho,x_1 : \Bind{\rho_1}{e_1}, x_2 : \Bind{\rho_1}{e_1'}\right)}{e_3}}}
     \MaybeBigBreak
\Rule{E-CaseExn1}
     {\Reduce{e_2}{e_2'}}
     {\Reduce{\Case{\Crash{\ell_1}}{e_2}{x_1}{x_2}{e_3}}{\Case{\Crash{\ell_1}}{e_2'}{x_1}{x_2}{e_3}}}
     \MaybeBigBreak
\Rule{E-CaseExn2}
     {\Reduce[\rho, x_1 : \Crash{\emptyset}, x_2 : \Crash{\emptyset}]{e_3}{e_3'}}
     {\Reduce{\Case{\Crash{\ell_1}}{e_2}{x_1}{x_2}{e_3}}{\Case{\Crash{\ell_1}}{e_2}{x_1}{x_2}{e_3'}}}
     \MaybeBigBreak
\Rule{E-CaseExn3}
     {}
     {\Reduce{\Case{\Crash{\ell_1}}{v_2^{\ell_2}}{x_1}{x_2}{v_3^{\ell_3}}}{\Crash{\ell_1 \sqcup \ell_2 \sqcup \ell_3}}}
     \MaybeBigBreak
\Rule{E-Bind1}
     {\Reduce[\rho_1]{e_1}{e_1'}}
     {\Reduce{\Bind{\rho_1}{e_1}}{\Bind{\rho_1}{e_1'}}}
     \quad
\Rule{E-Bind2}
     {}
     {\Reduce{\Bind{\rho_1}{v_1^{\ell_1}}}{v_1^{\ell_1}}}
\end{gather*}
\caption{Operational semantics ($\Reduce{e_1}{e_2}$)}
\label{fig-operational-semantics}
\end{figure*}

\CiteRule{E-Var} reduces a variable by looking up the expression bound to it in the environment. As we do not allow for recursive definitions without a mediating \textbf{fix}-construct, the variable $x$ is removed from the scope by binding $e$ to the environment $\rho$, having the (nearest) binding of $x$ removed. 
\CiteRule{E-Abs} reduces a lambda-abstraction to a closure, closing over its free variables in the current scope.
\CiteRule{E-App} first reduces $e_1$ until it has been evaluated to a function closure, after which \CiteRule{E-AppAbs} performs the application by binding $x$ to $e_2$ in the scope of $e_1$. The scope of $e_2$ is $\rho_1$, the scope that was closed over, while $e_1$ gets bound by the outer scope $\rho$, as it is not necessarily a value and may thus still have free variables that need to remain bound in the outer scope.
In case $e_1$ does not evaluate to a function closure, but to an exceptional value,  \CiteRule{E-AppExn1} will first continue reducing the argument $e_2$ to a (possibly exceptional) value. Once this is done, \CiteRule{E-AppExn2} will reduce the whole application to a single exceptional value with a set of exceptional labels consisting of the union of both the exception labels associated with the applicee as well as the applicant. This behaviour is part of the imprecise exception semantics of our language and will be further motivated in the reduction rules for the \textbf{if-then-else} construct.
\CiteRule{E-Let} binds $x$ to $e_1$ in the scope of $e_2$. \CiteRule{E-Fix} performs a one-step unfolding, binding any recursive occurrences of the binder to the original expression in its original scope.
To reduce an \textbf{if-then-else} expression, \CiteRule{E-If} will start by evaluating the conditional $e_1$. If it evaluates to either the value $\BTrue$ or the value $\BFalse$, \CiteRule{E-IfTrue} respectively \CiteRule{E-IfFalse}, will reduce the whole expression to the appropriate branch $e_2$ or $e_3$. In case the conditional $e_1$ reduces to an exceptional value $\Crash{\ell}$, the rules \CiteRule{If-Exn1} and \CiteRule{If-Exn2} will continue evaluating both branches of the \textbf{if-then-else} expression, as dictated by the imprecise exception semantics. Finally, once both arms have been fully evaluated to possibly exceptional values $v^{\ell_2}$ and $v^{\ell_3}$, \CiteRule{If-Exn3} will join all the exception labels from the conditional and both arms together---remembering that we by convention associate an empty set of exception labels with non-exceptional values---in an exceptional value $\Crash{\ell_1 \sqcup \ell_2 \sqcup \ell_3}$. This ``imprecision'' is necessary to validate program transformations, such as \textbf{case}-switching, in the presence of distinguishable exceptions:
%format e_5
%format e_6
%format e_i
\begin{code}
forall e_i.  if e_1 then
                 if  e_2  then  e_3  else  e_4
             else
                 if  e_2  then  e_5  else  e_6 =  if e_2 then
                                                      if e_1  then  e_3  else  e_5
                                                  else
                                                      if e_1  then  e_4  else  e_6
\end{code}
Note that \CiteRule{E-Op1} and \CiteRule{E-Op2}, as well a several other reduction rules, make the reduction relation non-deterministic, instead of enforcing a left-to-right evaluation order for operators, by requiring its left-hand argument to already be fully evaluated. Not enforcing an evaluation order for operators will allow the compiler to apply optimizing transformations, such as making use of the associativity or commutativity of the operator.
If both the left and right-hand side of the operator reduce to a numeric value, \CiteRule{E-OpNum} will reduce the expression to its interpretation $\InterpretOp{n_1\,\oplus\,n_2}$. %FIXME: strange formatting in InterpretOp
If either of, or both, the arguments reduce to an exceptional value, the rules \CiteRule{E-OpExn1}, \CiteRule{E-OpExn2} and \CiteRule{E-OpExn3} will propagate the exception labels of all the exceptional values in the expression.
The rules \CiteRule{E-Pair} and \CiteRule{E-Cons} wrap the syntactic pair and cons constructors in a closure to make them into values---in a call-by-name language constructors are only evaluated up to weak head normal form (\emph{whnf}) and can still contain unevaluated subexpressions that need to have their free variables closed over in their original scope.
\CiteRule{E-Fst} evaluates the argument passed to $\Fst$to a normal form. If it is an exceptional value, \CiteRule{E-FstExn} will propagate it; if it a closed pair constructor, \CiteRule{E-FstPair} will project the first argument and bind its free variables in the environment it has been closed over. Accordingly for \CiteRule{E-Snd}, \CiteRule{E-SndExn} and \CiteRule{E-SndPair}.
\CiteRule{E-Case} will evaluate the scrutinee of a \textbf{case}-expression to a normal form. If it evaluates to a nil-constructor, \CiteRule{E-CaseNil} will select the first arm. If it evaluates to a closed cons-constructor, \CiteRule{E-CaseCons} will select the second arm, binding $x_1$ and $x_2$ to respectively the first and second component of the constructor in the environment the constructor was closed over. In case the scrutinee evaluates to an exceptional value \CiteRule{E-CaseExn1}, \mbox{\CiteRule{E-CaseExn2}} and \CiteRule{E-CaseExn3} will continue evaluating both arms and gather and propagate all exception labels encountered. In the reduction rule \CiteRule{E-CaseExn-3} we still need to bind $x_1$ and $x_2$ to some expression in $\rho$. As this expression we take $\Crash{\emptyset}$ in both cases, as it is the least committing value in our system: it is associated with both an empty set of exceptional values, as well as with an empty set of non-exceptional values.
\CiteRule{E-Bind1} and \CiteRule{E-Bind2} will continue evaluating any expression $e$ in the given environment $\rho_1$ until it has been fully reduced to a value, which either contains no free variables, or has them explicitly closed over by a \textbf{close}-construct.

%% Constraints %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Constraints}\label{sec-constraints}

A constraint $c$ restricts the $\AnnLat$-substitutions that may be applied to a simply annotated type to turn it into an $\AnnLat$-annotated type. A constraint $c$ is a conditional, consisting of a left-hand side $g$ and a right-hand side $r$:
%\begin{figure}[h]
\begin{eqnarray*}
c &::=& g \Rightarrow r                                                   \\
g &::=& \AnnLat_\iota \sqsubseteq_\iota \alpha
%  \quad || \quad \exists \wp : \Lambda_\iota^\wp \sqsubseteq_\iota \alpha
  \quad || \quad \exists_\iota \alpha
  \quad || \quad g_1 \lor g_2
  \quad || \quad \BTrue                                                   \\
r &::=& \AnnLat_\iota \sqsubseteq_\iota \alpha
  \quad || \quad \alpha_1 \sqsubseteq_\iota \alpha_2
  \quad || \quad \Sh_1 \leq_\iota \Sh_2
\end{eqnarray*}
%\caption{Syntax of constraints}
%\end{figure}

The left-hand side $g$ of a conditional constraint, its \emph{guard}, consists of a disjunction of \emph{atomic guards} $\AnnLat_\iota \sqsubseteq_\iota \alpha$, relating an element of the lattice $\AnnLat_\iota$ to an annotation variable $\alpha$, and \emph{non-emptyness guards} $\exists_\iota \alpha$, a predicate on the annotation variable $\alpha$.

The right-hand side $r$ of a conditional or unconditional constraint can either be an \emph{atomic constraint} $\AnnLat_\iota \sqsubseteq_\iota \alpha$, relating an element of the lattice $\AnnLat_\iota$ to an annotation variable $\alpha$, or an atomic constraint $\alpha_1 \sqsubseteq_\iota \alpha_2$, relating two annotation variables, or it can be a \emph{structural constraint} $\Sh_1 \leq_\iota \Sh_2$, relating two simply annotated types.

The asymmetry between the allowed forms of the antecedent $g$ and consequent $r$ of the conditional constraints are intentional: they allow constraints to be formed that are expressive enough to build an accurate analysis, but limited enough so as to allow tractable constraint solving. Both allowing constraints of the form $g_1 \lor g_2$ on the right-hand side of a conditional, or allowing constraints of the form $\alpha_1 \sqsubseteq_\iota \alpha_2$ on the left-hand side of a conditional make constraint solving notoriously difficult: the former because it cannot be trivially decomposed into a set of simpler constraints and the latter because it does not behave monotonically under a fixed-point iteration.

The atomic and structural constraint relations are qualified by an index $\iota$, which for the purposes of our analysis can be one of two constants:
%\begin{figure}[h]
\begin{eqnarray*}
\iota &::=& \Ref \quad || \quad \Exn
\end{eqnarray*}
%\caption{Constraint indices}
%\end{figure}
Here $\Ref$ is used to indicate data-flow, while $\Exn$ indicates exception-flow.

To ease the syntactic burden we freely write constraint expressions indexed by the two constraint indices $\Ref\Exn$ simultaneously. Formally these should always be read as standing for two separate constraint expressions: one indexed by $\Ref$ and the other indexed by $\Exn$. As none of the constraint expression in this paper contains more than one such paired index, no ambiguities should arise.
Furthermore, \[c^g\quad ::=\quad c\quad ||\quad g\] and constraints $\BTrue \Rightarrow r$ shall be written simply as $r$.

%% Constraint model %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Constraints are given meaning by the \emph{constraint satisfaction} predicate $\CM{c^g}$, which relates a constraint $c$, $g$ or $r$ to the meaning of its free variables, which are in turn given by a pair of ground substitutions $\theta = \left<\theta_\Ref, \theta_\Exn\right>$:

%\begin{figure}[h]
    \begin{gather*}
        \Rule{CM-Impl}
             {\CM{g} \Rightarrow \CM{r}}
             {\CM{g \Rightarrow r}}
        \quad
        \Rule{CM-Con}
             {\Lambda_\iota \sqsubseteq_\iota \theta_\iota \alpha}
             {\CM{\Lambda_\iota \sqsubseteq_\iota \alpha}}
        \BigBreak
        \Rule{CM-Exists}
             {\exists \ell \in \Lambda_\iota : \ell \sqsubseteq_\iota \theta_\iota \alpha }
             {\CM{\exists_\iota \alpha}}
        \quad
        \Rule{CM-Left}
             {\CM{g_1}}
             {\CM{g_1 \lor g_2}}
        \BigBreak
        \Rule{CM-Right}
             {\CM{g_2}}
             {\CM{g_1 \lor g_2}}
        \quad
        \Rule{CM-True}
             {}
             {\CM{\BTrue}}
        \BigBreak
        \Rule{CM-Var}
             {\theta_\iota \alpha_1 \sqsubseteq_\iota \theta_\iota \alpha_2}
             {\CM{\alpha_1 \sqsubseteq_\iota \alpha_2}}
        \quad
        \Rule{CM-Sub}
             {\theta_\iota \tau_1 \leq_\iota \theta_\iota \tau_2}
             {\CM{\tau_1 \leq_\iota \tau_2}}
    \end{gather*}
%    \caption{Interpretation of constraints ($\CM{c_g}$)}
%\end{figure}

%% Constraint logic %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Working with constraints in terms of the constraint satisfaction predicate is rather tedious, so we prefer to work with a \emph{constraint entailment} relation $\Centail[C
]{c^g}$ and an associated constraint logic:

%\begin{figure}[h]
    \begin{gather*}
        \Rule{CL-$\bot$}
             {}
             {\Centail{\bot_\iota \sqsubseteq_\iota \alpha}}
        \quad
        \Rule{CL-$\top$}
             {}
             {\Centail{\alpha \sqsubseteq_\iota \top_\iota}}
        \BigBreak
        \Rule{CL-$\Rightarrow$I}
             {\Centail[C, g]{r}}
             {\Centail{g \Rightarrow r}}
        \quad
        \Rule{CL-$\Rightarrow$E}
             {\Centail{g \Rightarrow r}}
             {\Centail[C, g]{r}}
        \BigBreak
        \Rule{CL-$\lor$I}
             {\Centail{g_1}}
             {\Centail{g_1 \lor g_2}}
        \quad
        \Rule{CL-$\lor$C}
             {\Centail{g_1 \lor g_2}}
             {\Centail{g_2 \lor g_1}}
        \BigBreak
        \Rule{CL-$\exists$I}
             {\Centail{\Lambda_\iota \sqsubseteq_\iota \alpha}}
             {\Centail{\exists_\iota \alpha}}
        \quad
%        \Rule{CL-Lub}
%             {\Centail{\alpha_1 \sqsubseteq_\iota \beta} \quad \Centail{\alpha_2 \sqsubseteq_\iota \beta}}
%             {\Centail{\alpha_1 \sqcup \alpha_2 \sqsubseteq_\iota \beta}}
%        \BigBreak
        \Rule{CL-Weak}
             {\Centail[C_1]{c^g}}
             {\Centail[C_1, C_2]{c^g}}
        \BigBreak
        \Rule{CL-MP}
             {\Centail{c^g_1} \quad \Centail[C, c^g_1]{c^g_2}}
             {\Centail{c^g_2}}
    \end{gather*}
%    \caption{Constraint logic ($\Centail{c^g}$)}
%    \label{fig-constraintlogic}
%\end{figure}

We lift the constraint entailment relation to work on constraint sets $\Centail[C_1]{C_2}$ in the obvious way.

\begin{theorem}[Soundness of constraint logic]
    If $\CM{C}$ and $\Centail{D}$ then $\CM{D}$.
\end{theorem}
%\begin{proof}\small
%    By induction on the derivation of $\Centail{D}$. We show one case; the full proof %can be found in the appendix.
%    
%    \IndCase{CL-$\exists$I} We need to show that if $\CM{C}$ and $\Centail{\exists_\iota \alpha}$ then $\CM{\exists_\iota \alpha}$.
%    The induction hypothesis states that if $\CM{C}$ and $\Centail{\Lambda_\iota \sqsubseteq_\iota \alpha}$ then $\CM{\Lambda_\iota \sqsubseteq_\iota \alpha}$.
%    
%    We can immediately apply the induction hypothesis. Inversion on its result reveals that it can only have been constructed by \CiteRule{CM-Con}, giving us $\Lambda_\iota \sqsubseteq_\iota \theta_\iota \alpha$. We can us this to apply \CiteRule{CM-Exists}, giving us the desired result.
%\end{proof}

%% Subtyping %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The subtyping relation is as usual for a type and effect system, thus note the subeffecting of the annotations:

%\begin{figure}[h]
\begin{gather*}
\Rule{SA-Base}
     {\alpha_1 \sqsubseteq_\iota \alpha_2}
     {\alpha_1 \leq_\iota \alpha_2}
     \BigBreak
\Rule{SA-Fun}
     {\Sh_3 \leq_\iota \Sh_1 \quad \Sh_2 \leq_\iota \Sh_4 \quad \alpha_1 \sqsubseteq_\iota \alpha_2}
     {\TyFun{\Sh_1}{\Sh_2}{\alpha_1} \leq_\iota \TyFun{\Sh_3}{\Sh_4}{\alpha_2}}
     \BigBreak
\Rule{SA-Pair}
     {\Sh_1 \leq_\iota \Sh_3 \quad \Sh_2 \leq_\iota \Sh_4 \quad \alpha_1 \sqsubseteq_\iota \alpha_2}
     {\TyPair{\Sh_1}{\Sh_2}{\alpha_1} \leq_\iota \TyPair{\Sh_3}{\Sh_4}{\alpha_2}}
     \BigBreak
\Rule{SA-List}
     {\Sh_1 \leq_\iota \Sh_2 \quad \alpha_1 \sqsubseteq_\iota \alpha_2}
     {\TyList{\Sh_1}{\alpha_1} \leq_\iota \TyList{\Sh_2}{\alpha_2}}
    \BigBreak
\Rule{S-Refl}
     {}
     {\tau \leq_\iota \tau}
    \quad
\Rule{S-Trans}
     {\tau_1 \leq_\iota \tau_2 \quad \tau_2 \leq_\iota \tau_3}
     {\tau_1 \leq_\iota \tau_3}    
\end{gather*}
%\caption{Subtyping / constraint decomposition}
%\end{figure}

%% Type system %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Type system}

\begin{figure*}[!t]
\begin{gather*}
\Rule{T-Var}
     {C \Vdash \SUBST{D}}
     {\Judge[C; \Gamma, x : \forall\overline{\alpha}.\ \tau\ \textbf{with}\ D]{x}{\SUBST{\tau}}}
     \quad
\Rule{T-Con}
     {C \Vdash i(c) \sqsubseteq_\Ref \alpha}
     {\Judge{c}{\alpha}}
     \quad
\Rule{T-Exn}
     {C \Vdash \ell \sqsubseteq_\Exn \TopLevel{\tau}}
     {\Judge{\Crash{\ell}}{\tau}}
     \BigBreak
\Rule{T-App}
     {\Judge{e_1}{\TyFun{\tau_1}{\tau_2}{\alpha}}
      \quad \Judge{e_2}{\tau_3}
      \quad C \Vdash \tau_3 \leq_{\Ref\Exn} \tau_1
      \quad C \Vdash \alpha \sqsubseteq_\Exn \TopLevel{\tau_2}
      \quad C \Vdash \exists_\Exn \alpha \Rightarrow \TopLevel{\tau_3} \sqsubseteq_\Exn \TopLevel{\tau_2}
     }
     {\Judge{\App{e_1}{e_2}}{\tau_2}}
     \BigBreak
\Rule{T-Abs}
     {\Judge[C; \Gamma, x : \tau_1]{e}{\tau_2}}
     {\Judge{\Abs{x}{e}}{\TyFun{\tau_1}{\tau_2}{\alpha}}}
     \quad
\Rule{T-Let}
     {\Judge[D; \Gamma]{e_1}{\tau_1}
      \quad \Judge[C; \Gamma, x : \TyForall{\alpha}{\tau_1}{D}]{e_2}{\tau_2}
      \quad \overline{\alpha} \cap fv(\Gamma) = \emptyset}
     {\Judge{\Let{x}{e_1}{e_2}}{\tau_2}}
     \BigBreak
\Rule{T-Fix}
     {C \Vdash \SUBST{D}
      \quad \Judge[D; \Gamma, f : \forall\overline{\alpha}.\ \tau_1\ \textbf{with}\ D]{e}{\tau_2}
      \quad D \Vdash \tau_2 \leq_{\Ref\Exn} \tau_1
      \quad \overline{\alpha} \cap fv(\Gamma) = \emptyset}
     {\Judge{\Fix{f}{e}}{\SUBST{\tau_1}}}
     \BigBreak
\Rule{T-If}
     {\begin{gathered}
      \Judge{e_1}{\alpha_1}
      \quad \Judge{e_2}{\tau_2}
      \quad \Judge{e_3}{\tau_3} \\
            C \Vdash \CCD[\Ref\Exn]{\SingletonTrue}{\alpha_1}{\exists_\Exn \alpha_1}{\tau_2}{\tau}
      \quad C \Vdash \CCD[\Ref\Exn]{\SingletonFalse}{\alpha_1}{\exists_\Exn \alpha_1}{\tau_3}{\tau}
      \quad C \Vdash \alpha_1 \sqsubseteq_\Exn \TopLevel{\tau}
     \end{gathered}}
     {\Judge{\IfThenElse{e_1}{e_2}{e_3}}{\tau}
     }
     \BigBreak
\Rule{T-Op}
     {\Judge{e_1}{\alpha_1}
      \quad \Judge{e_2}{\alpha_2}
      \quad C \Vdash \alpha_1 \sqsubseteq_\Exn \alpha
      \quad C \Vdash \alpha_2 \sqsubseteq_\Exn \alpha
      \quad C \Vdash \omega_\oplus(\alpha_1, \alpha_2, \alpha)
     }
     {\Judge{e_1 \oplus e_2}{\alpha}}
     \BigBreak
\Rule{T-Pair}
     {\Judge{e_1}{\tau_1}
      \quad \Judge{e_2}{\tau_2}
     }
     {\Judge{\Pair{e_1}{e_2}}
            {\TyPair{\tau_1}{\tau_2}{\alpha}}
     }
     \BigBreak
\Rule{T-Fst}
     {\Judge{e}{\TyPair{\tau_1}{\tau_2}{\alpha}}
      \quad \Centail{\tau_1 \leq_{\Ref\Exn} \tau}
      \quad C \Vdash \alpha \sqsubseteq_\Exn \TopLevel{\tau}
     }
     {\Judge{\Fst{e}}{\tau}}
     \quad
\Rule{T-Snd}
     {\Judge{e}{\TyPair{\tau_1}{\tau_2}{\alpha}}
      \quad \Centail{\tau_2 \leq_{\Ref\Exn} \tau}
      \quad C \Vdash \alpha \sqsubseteq_\Exn \TopLevel{\tau}
     }
     {\Judge{\Snd{e}}{\tau}}
     \BigBreak
\Rule{T-Nil}
     {C \Vdash \SingletonNil \sqsubseteq_\Ref \alpha} %% FIXME: subtyping/-effecting?
     {\Judge{\LNil}{\TyList{\tau}{\alpha}}}
     \quad
\Rule{T-Cons}
     {\begin{gathered}
      \Judge{e_1}{\tau_1}
      \quad \Judge{e_2}{\TyList{\tau_2}{\alpha_2}}\\
      C \Vdash \tau_1 \leq_{\Ref\Exn} \tau
      \quad C \Vdash \tau_2 \leq_{\Ref\Exn} \tau
      \quad C \Vdash \SingletonCons \sqsubseteq_\Ref \alpha
      \quad C \Vdash \alpha_2 \sqsubseteq_\Exn \alpha
      \end{gathered}}
     {\Judge{\LCons{e_1}{e_2}}{\TyList{\tau}{\alpha}}}
     \BigBreak
\Rule{T-Case}
     {\begin{gathered}
      \Judge{e_1}{\TyList{\tau_1}{\alpha_1}}
      \quad \Judge{e_2}{\tau_2}
      \quad \Judge[C; \Gamma, x_1 : \tau_1, x_2 : \TyList{\tau_1}{\beta}]{e_3}{\tau_3}\\
      C \Vdash\CCD[\Ref\Exn]{\SingletonNil}{\alpha_1}{\exists_\Exn \alpha_1}{\tau_2}{\tau}
      \quad C \Vdash\CCD[\Ref\Exn]{\SingletonCons}{\alpha_1}{\exists_\Exn \alpha_1}{\tau_3}{\tau}
      \quad C \Vdash\alpha_1 \sqsubseteq_\Exn \TopLevel{\tau}\\
      \quad C \Vdash\SingletonNil \sqcup \SingletonCons \sqsubseteq_\Ref \beta
      \quad C \Vdash \alpha_1 \sqsubseteq_\Exn \beta
      \end{gathered}}
     {\Judge{\Case{e_1}{e_2}{x_1}{x_2}{e_3}}{\tau}}
     \BigBreak
\Rule{T-Close}
     {\Judge[C;\Delta]{e}{\sigma} \quad \EC{\Delta}{\rho}}
     {\Judge{\Close{e}{\rho}}{\sigma}}
     \quad
\Rule{T-Bind}
     {\Judge[C;\Delta]{e}{\sigma} \quad \EC{\Delta}{\rho}}
     {\Judge{\Bind{\rho}{e}}{\sigma}}
\end{gather*}
\caption{Normalized type system ($\Judge{e}{\sigma}$)}
\label{fig-normalized-typesystem}
\end{figure*}

A normalized type system for exception analysis is given in Figure~\ref{fig-normalized-typesystem}.

\CiteRule{T-Var} combines a lookup in the type environment with instantiation of variables quantified over in the type scheme.
\CiteRule{T-Con} and \CiteRule{T-Exn} make sure that any constants and exception literals flow into the top-level annotations of their type. Constants will have to be abstracted into an element of the lattice $\Lambda_\delta$, using the auxiliary function $i$, first.
\CiteRule{T-App} incorporates a subtyping check between the formal and the actual parameter and flows all exceptions than can be caused by evaluating the function abstraction---as represented by the annotation on the function-space constructor---into the top-level annotation of the resulting type.
The final premise flows any exceptions that can be raised by evaluating the argument to weak head normal form to the top-level annotation on the result type if it is possible for the function that the argument is applied to, to evaluate to an exceptional value. This is necessary to soundly model the imprecise exception semantics.
\CiteRule{T-Abs} is standard, with only an additional annotation present on the function-space constructor.
\CiteRule{T-Fix} and \CiteRule{T-Let} are the conventional rules for polymorphic recursion and polymorphic let-bindings with constrained types and are the only rules with a non-trivial algorithmic interpretation (see Section~\ref{sec-algorithm}).
\CiteRule{T-If} uses subtyping to ensure that the exceptional and non-exceptional values of both branches, as well as any exceptions that can occur while evaluating the conditional are propagated to the resulting type. Additionally, conditional constraints are used to ensure that only reachable branches will contribute to the resulting type. A branch is considered reachable if either the conditional can evaluate to $\BTrue$ respectively $\BFalse$, or because evaluating the conditional can cause an exception and we have to consider both branches as being reachable to validate the \textbf{case}-switching transformation.
The typing rule \CiteRule{T-Op} for primitive operators will be discussed in Section~\ref{sec-operators}.
\CiteRule{T-Pair} is the standard type rule for pairs, except that we add an unconstrained annotation to the pair constructor.
\CiteRule{T-Fst} and \CiteRule{T-Snd} are standard type rules for projections from a pair. As they implicitly perform a pattern-match, they have to propagate any exceptions that can occur when evaluating the pair-constructor to the resulting type.
\CiteRule{T-Nil} gives the nil-constructor the type list of $\tau$, with $\tau$ unconstrained, and an annotation $\alpha$ indicating the head of the spine of the list can at least contain a nil-constructor.
\CiteRule{T-Cons} merges data-flow and exception-flow of the head and elements in the tail of the list, annotates the resulting type with an $\alpha$ indicating the head of the spine of the list can at least contain a cons-constructor, and propagates the exceptions that can occur in the tail of the spine of the list to the resulting type.
\CiteRule{T-Case} is similar to \CiteRule{T-If}. The additional complication lies in the fact that the pattern for a cons-constructor must also bring its two field into scope and give them an appropriate type.
Note how in \CiteRule{T-Cons} and \CiteRule{T-Case} exceptional and non-exceptional values are treated asymmetrically. In the rule \CiteRule{T-Cons} exceptional values in the spine of the tail of the list flow into the result, while we only remember $\SingletonCons$ as the non-exceptional value than can occur at the head of the spine of the resulting list. 
This choice means that in \CiteRule{T-Case}, while we have more precise information about the head of the list, we have to be \emph{pessimistic} about the shape of the list that gets bound to $x_2$. %\begin{WORKINPROGRESS}We argue that is not such a big problem in practice and in fact unavoidable.\end{WORKINPROGRESS} % FIXME: can't remember the shape up to infinite depth, can easily extend the lattice to record the length of lists
Conversely, for exceptional values we have less precise information about the head of the spine of the list. % FIXME: argue that this isn't going to be a problem in practice.
We can, however, be \emph{optimistic} about the exceptional values occuring in the spine of the list that gets bound to $x_2$. Not being able to do so would be disasterous for the precision of the analysis. Any further pattern-matching on the spine of $x_2$, whether directly or through applying operations such as \emph{map} or \emph{reverse} to it, would cause the---likely spurious---exceptions to propagate.
Finally, \CiteRule{T-Close} and \CiteRule{T-Bind} type the expression $e$ they close over or bind in an expression environment $\rho$ in under a type environment $\Delta$ that types the expression environment $\rho$.
These rules relate the type environments $\Gamma$ with the expression environments $\rho$ using an \emph{environmental consistency} relation $\EC{\Gamma}{\rho}$:
\begin{gather*}
    \Rule{EC-Empty}
         {}
         {\EC{\epsilon}{\epsilon}}
    \BigBreak
    \Rule{EC-Extend}
         {\EC{\Gamma}{\rho} \quad \Judge[C;\Gamma]{e}{\sigma}}
         {\EC{\Gamma, x : \sigma}{\rho, x : e}}
    \\
\end{gather*}

\subsection{Primitive operators}\label{sec-operators}

The typing rule \CiteRule{T-Op} for primitive operators relies on an auxiliary function $\omega$ that assigns a constraint set for each operator, giving its abstract interpretation. For an addition operator $+$ one can take the constraint set: \[ \omega_+(\alpha_1,\alpha_2,\alpha) \isdef \left\{ \top_\mathbb{Z} \sqsubseteq_\Ref \alpha \right\} \] or the more precise: \[ \omega_+(\alpha_1,\alpha_2,\alpha) \isdef \left\{\begin{gathered}\CCS[\Ref]{\SingletonNeg}{\alpha_1}{\SingletonNeg}{\alpha} \\ \CCS[\Ref]{\SingletonNeg}{\alpha_2}{\SingletonNeg}{\alpha} \\ \SingletonZero \sqsubseteq_\Ref \alpha \\ \CCS[\Ref]{\SingletonPos}{\alpha_1}{\SingletonPos}{\alpha} \\ \CCS[\Ref]{\SingletonPos}{\alpha_2}{\SingletonPos}{\alpha} \end{gathered}\right\} \]
If we would extend our constraints to allow conjunctions on the left-hand side of conditionals we can even get rid of the spurious $\SingletonZero$'s: \[ \omega_+(\alpha_1,\alpha_2,\alpha) \isdef \left\{\begin{gathered}\CCS[\Ref]{\SingletonNeg}{\alpha_1}{\SingletonNeg}{\alpha} \\ \CCS[\Ref]{\SingletonNeg}{\alpha_2}{\SingletonNeg}{\alpha} \\ \SingletonNeg \sqsubseteq_\Ref \alpha_1 \land \SingletonPos \sqsubseteq_\Ref \alpha_2 \Rightarrow \SingletonZero \sqsubseteq_\Ref \alpha \\ \SingletonZero \sqsubseteq_\Ref \alpha_1 \land \SingletonZero \sqsubseteq_\Ref \alpha_2 \Rightarrow \SingletonZero \sqsubseteq_\Ref \alpha \\ \SingletonPos \sqsubseteq_\Ref \alpha_1 \land \SingletonNeg \sqsubseteq_\Ref \alpha_2 \Rightarrow \SingletonZero \sqsubseteq_\Ref \alpha \\ \CCS[\Ref]{\SingletonPos}{\alpha_1}{\SingletonPos}{\alpha} \\ \CCS[\Ref]{\SingletonPos}{\alpha_2}{\SingletonPos}{\alpha} \end{gathered}\right\} \]
Similarly, we are able to detect division-by-zero exceptions caused by an integer division operator $\div$: \[ \omega_\div(\alpha_1,\alpha_2,\alpha) \isdef \left\{\begin{gathered}\SingletonZero \sqsubseteq_\Ref \alpha_2 \Rightarrow \left\{\textbf{div-by-0}\right\} \sqsubseteq_\Exn \alpha \\
\SingletonNeg \sqsubseteq_\Ref \alpha_1 \land \SingletonNeg \sqsubseteq_\Ref \alpha_2 \Rightarrow \SingletonPos \sqsubseteq_\Ref \alpha \\
\SingletonNeg \sqsubseteq_\Ref \alpha_1 \land \SingletonPos \sqsubseteq_\Ref \alpha_2 \Rightarrow \SingletonNeg \sqsubseteq_\Ref \alpha \\
\SingletonPos \sqsubseteq_\Ref \alpha_1 \land \SingletonNeg \sqsubseteq_\Ref \alpha_2 \Rightarrow \SingletonNeg \sqsubseteq_\Ref \alpha \\
\SingletonPos \sqsubseteq_\Ref \alpha_1 \land \SingletonPos \sqsubseteq_\Ref \alpha_2 \Rightarrow \SingletonPos \sqsubseteq_\Ref \alpha \\
\SingletonZero \sqsubseteq_\Ref \alpha \end{gathered}\right\} \]

We do impose two restrictions on the operator constraint sets; they need to be \emph{consistent} and \emph{monotonic}:
\begin{mydef}\label{operator-consistency}%[Operator consistency]
An operator constraint set $\omega_\oplus$ is said to be \emph{consistent} with respect to an operator interpretation $\InterpretOp{\ \cdot\oplus\cdot\ }$ if, whenever $\Judge{n_1}{\alpha_1}$, $\Judge{n_2}{\alpha_2}$, and $\Centail{\omega_\oplus(\alpha_1, \alpha_2, \alpha)}$ then $\Judge{\InterpretOp{n_1 \oplus n_2}}{\alpha'}$ with $\Centail{\alpha' \leq_{\Ref\Exn} \alpha}$ for some $\alpha'$.
\end{mydef}
This restriction states that the interpretation of an operator and its abstract interpretation by the operator constraint set should coincide. We need one slightly more technical restriction to be able to prove our system sound:
\begin{mydef}\label{operator-monotonicity}%[Operator monotonicity]
An operator constraint set $\omega_\oplus$ is \emph{monotonic} if, whenever $\Centail{\omega_\oplus(\alpha_1, \alpha_2, \alpha)}$ and $\Centail{\alpha_1' \sqsubseteq_{\Ref\Exn} \alpha_1}$, $\Centail{\alpha_2' \sqsubseteq_{\Ref\Exn} \alpha_2}$, $\Centail{\alpha \sqsubseteq_{\Ref\Exn} \alpha'}$ then $\Centail{\omega_\oplus(\alpha_1', \alpha_2', \alpha')}$.
\end{mydef}
Informally this means that operator constraint sets can only let the result of evaluating an operator and its operands depend on the values of those operands and not the other way around: the operator constraint sets must respect the fact that we are defining a \emph{forwards analysis}.

\subsection{Declarative rules}
While we have formulated the analysis directly as a normalized type system, we do need to appeal to the three logical rules that have been folded into the non-logical ones---in order to make the system syntax-directed---in the metatheoretic proofs. Their formulation should hold no surprises:
%\begin{figure}[h]
\begin{gather*}
    \Rule{T-Inst}
         {\Judge{e}{\TyForall{\alpha}{\tau}{D}} \quad \Centail{D\left[\overline{\beta}/\overline{\alpha}\right]}}
         {\Judge{e}{\tau\left[\overline{\beta}/\overline{\alpha}\right]}}
    \BigBreak
    \Rule{T-Gen}
         {\Judge[C,D;\Gamma]{e}{\tau} \quad \overline{\alpha} \cap fv(\Gamma; C) = \emptyset}
         {\Judge{e}{\TyForall{\alpha}{\tau}{D}}}
    \BigBreak
    \Rule{T-Sub}
         {\Judge{e}{\tau} \quad \Centail{\tau \leq_{\Ref\Exn} \tau'}}
         {\Judge{e}{\tau'}}
\end{gather*}
%\caption{\BLAHBLAHBLAH}
%\end{figure}


\subsection{Metatheory} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Three theorems imply the correctness of the analysis:
\begin{theorem}[Conservative extension]
If $e$ is well-typed in the underlying type system, then it can be given a type in the annotated type system.
\end{theorem}
%\begin{proof}\small
%The shape of the type in both systems will coincide. Any well-shaped expression can be well-typed by assigning it the $\top$ type for the given shape. \begin{WORKINPROGRESS}(Co- and contravariance makes this a bit more complicated.)\end{WORKINPROGRESS}
%\end{proof}

\begin{theorem}[Progress]
    If $\Judge{e}{\sigma}$ then either $e$ is value or there exist an $e'$, such that for any $\rho$ with $\EC{\Gamma}{\rho}$ we have $\Reduce{e}{e'}$.
\end{theorem}
%\begin{proof}\small
%	By induction on the typing derivation. We show a single case; the full proof an be found in the appendix.
%
%	\IndCase{T-If}
%\end{proof}

\begin{theorem}[Preservation]
If $\Judge{e}{\sigma_1}$, $\Reduce{e}{e'}$ and $\EC{\Gamma}{\rho}$ then $\Judge{e'}{\sigma_2}$ with $C \Vdash \sigma_2 \leq_{\Ref\Exn} \sigma_1$.
\end{theorem}
%\begin{proof}\small
%By induction on the reduction relation. We show a single case; the full proof can be found in the appendix.
%
%    \IndCase{E-CaseExn2}
%\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Algorithm}\label{sec-algorithm} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The analysis can be implemented as a three-stage type inference process. In the first stage we invoke a standard Hindley--Milner type inference algorithm to make sure the input program is well-typed and to give the second stage  access to the underlying types of all subexpressions. The second stage generates a set of constraints and the third stage solves those constraints.

%format (V (x) (y)) = "\left<" x ", " y "\right>"
%format (setOf (a)) = "\left\{\begin{gathered}" a "\end{gathered}\right\}"
%format /// = "\\"

%format w = "\mathcal{W}"
%format w' = "\!\!\!\!\!\!\!\!\mathcal{W}"
%format env = "\Gamma"
%format env'
%format (lookup (a) (b)) = a "_" b
%format (topLevel (a)) = "\TopLevel{" a "}"
%format (ulTy (a)) = "\lfloor " a "\rfloor"
%format :*: = "\times"
%format Env = "\textbf{Env}"
%format Expr = "\textbf{Expr}"
%format Ty = "\textbf{Ty}"
%format Constr = "\textbf{Constr}"
%format Set (a) = "\mathcal{P}\ " a
%format kappa = "\kappa"
%format # = "\cup"
%format |#| = "\sqcup"

%format Crash = "\Crash{\ell}"
%format Abs (a) (b) = "\lambda " a "." b
%format App (a) (b) = a "\ " b
%format Let (x) (e1) (e2) = "\Let{" x "}{" e1 "}{" e2 "}"
%format Fix (x) (e) = "\Fix{" x "}{" e "}"
%format If (e1) (e2) (e3) = "\IfThenElse{" e1 "}{" e2 "}{" e3 "}"
%format Op (e1) (e2) = "\Op{" e1 "}{" e2 "}"
%format (Pair (e1) (e2)) = "\Pair{" e1 "}{" e2 "}"
%format Fst (e) = "\Fst{" e "}"
%format Snd (e) = "\Snd{" e "}"
%format Case (e_1) (e_2) (x_1) (x_2) (e_3) = "\Case{" e_1 "}{" e_2 "}{" x_1 "}{" x_2 "}{" e_3 "}"

%format ShFun (a) (b) (c) = a "\xrightarrow{" c "}" b
%format ShPair (e1) (e2) (a) = "\TyPair{" e1 "}{" e2 "}{" a "}"
%format (ShList (t) (a)) = "\TyList{" t  "}{" a "}"

%format T = "\SingletonTrue"
%format F = "\SingletonFalse"
%format NIL = "\SingletonNil"
%format CONS = "\SingletonCons"

%format e_0
%format e_1
%format e_2
%format alpha_1 = "\alpha_1"
%format alpha_2 = "\alpha_2"
%format tau   = "\tau"
%format tau_0 = "\tau_0"
%format tau_1 = "\tau_1"
%format tau_2 = "\tau_2"
%format tau_3 = "\tau_3"
%format sigma_1 = "\sigma_1"
%format C_0
%format C_1
%format C_2
%format C_3
%format C_4

%% Constraints (constructors)
%format <|#  = "\sqsubseteq_{\Ref}"
%format <|&  = "\sqsubseteq_{\Exn}"
%format <<#  = "\leq_{\Ref}"
%format <<&  = "\leq_{\Exn}"
%format <<#& = "\leq_{\Ref\Exn}"
%format exists_exn = "\exists_\Exn"

%format wop a1 a2 a = "\omega_\oplus(" a1 "," a2 "," a ")"

\subsection{Constraint generation}

%\begin{figure}[h]
%    \vspace{-.5em}
%\begin{small}
%      w'  env  (Fix x e)         =   ...
    \begin{code}
      w'                         ::  Env -> Expr -> Ty :*: Set Constr
      w'  env  x                 =   inst (lookup env x)
      w'  env  c                 =   typeOf c
      w'  env  Crash             =   typeOf Crash
      w'  env  (Abs x e)         =   do  tau_1 <- freshFrom (ulTy x)
                                         (V tau_2 C_2) <- w (env, x :: tau_1) e
                                         alpha <- fresh
                                         return (V (ShFun tau_1 tau_2 alpha) C_2)
      w'  env  (App e_1 e_2)     =   do  (V (ShFun tau_1 tau_2 alpha) C_1)  <-  w  env  e_1
                                         (V tau_3 C_2)                      <-  w  env  e_2
                                         C_3 <- setOf (tau_3 <<#& tau_1, alpha <|& topLevel tau_2 /// exists_exn alpha => topLevel tau_3 <<& topLevel tau_2)
                                         return (V tau_2 (C_1 # C_2 # C_3))
      w'  env  (Let x e_1 e_2)   
                                 =   do  (V tau_1 C_1)    <-  w env  e_1
                                         sigma_1          <-  gen env tau_1 C_1
                                         (V tau_2 C_2)    <-  w (env, x :: sigma_1) e_2
                                         return (V tau_2 (C_1 # C_2))
      w'  env  (If e_1 e_2 e_3)  
                                 =   do  (V (alpha_1) (C_1))    <- w env e_1
                                         (V (tau_2) (C_2))      <- w env e_2
                                         (V tau_3 C_3)          <- w env e_3
                                         tau <- freshFrom (ulTy (e_2))
                                         C_4 <- setOf (alpha_1 <|& topLevel tau /// T <|# alpha_1 \/ exists_exn alpha_1 => tau_2 <<#& tau /// F <|# alpha_1 \/ exists_exn alpha_1 => tau_3 <<#& tau)
                                         return (V (tau) (C_1 # C_2 # C_3 # C_4))
      w'  env  (Op e_1 e_2)      =   do  (V alpha_1 C_1)  <-  w env e_1
                                         (V alpha_2 C_2)  <-  w env e_2
                                         alpha <- fresh
                                         C_3 <- setOf (alpha_1 <|& alpha, alpha_2 <|& alpha)
                                         C_4 <- wop alpha_1 alpha_2 alpha
                                         return (V (alpha) (C_1 # C_2 # C_3 # C_4))
      w'  env  (Pair e_1 e_2)    =   do  (V tau_1 C_1)  <-  w env e_1
                                         (V tau_2 C_2)  <-  w env e_2
                                         alpha <- fresh
                                         return (V (ShPair tau_1 tau_2 alpha) (C_1 # C_2))
      w'  env  (Fst e)           =   do  (V (ShPair tau_1 tau_2 alpha) C_1) <- w env e
                                         tau <- freshFrom (ulTy (Fst e))
                                         C_2 <- setOf (tau_1 <<#& tau, alpha <|& topLevel tau)
                                         return (V tau (C_1 # C_2))
      w'  env  (e==[])           =   do  tau <- freshFrom (ulTy e)
                                         alpha <- fresh
                                         return (V (ShList tau alpha) (setOf (NIL <|# alpha)))
      w'  env  (e_1 : e_2)       =   do  (V tau_1 C_1) <- w env e_1
                                         (V (ShList tau_2 alpha_2) C_2) <- w env e_2
                                         tau    <- fresh
                                         alpha  <- fresh
                                         C_3 <- setOf (tau_1 <<#& tau, tau_2 <<#& tau /// CONS <|# alpha, alpha_2 <|# alpha)
                                         return (V (ShList tau alpha) (C_1 # C_2 # C_3))
      w'  env  (Case e_1 e_2 x_1 x_2 e_3)
                                 =   do  (V (ShList tau_1 alpha_1) C_1) <- w env e_1
                                         (V tau_2 C_2) <- w env e_2
                                         (V tau_3 C_3) <- w (env, x_1 :: tau_1, x_2 :: (ShList tau_1 beta)) e_3
                                         tau <- freshFrom (ulTy e_2)
                                         C_4 <- setOf (alpha_1 <|& topLevel tau /// NIL <|# alpha_1 \/ exists_exn alpha_1 => tau_2 <<#& tau /// CONS <|# alpha_1 \/ exists_exn alpha_1 => tau_3 <<#& tau /// NIL |#| CONS <|# beta, alpha_1 <|& beta)
                                         return (V tau (C_1 # C_2 # C_3 # C_4))
    \end{code}
%      w'  env  (Snd e)           =   do  (V (ShPair tau_1 tau_2 alpha) C_1) <- w env e
%                                         tau <- freshFrom (ulTy (Snd e))
%                                         C_2 <- setOf (tau_2 <<#& tau, alpha <|& topLevel tau)
%                                         return (V tau (C_1 # C_2))
%To save space we omitted the case for \textbf{snd}, which is implemented analogous to the case for \textbf{fst}.
The case for \textbf{fix} is discussed in Section~\ref{sec-knowingwhentostop}. As the \textbf{close} and \textbf{bind}-constructs are included for metatheoretic purposes only and assumed not to be present in the initial unevaluated program text, we do not need to include any cases for them in the algorithm.

The auxiliary function |freshFrom| creates a type with the same type-constructor shape as the given underlying type, with all annotation variables fresh; |gen| quantifies over all annotation variables free in $\tau$ but not free in $\Gamma$; |inst| instantiates all quantified annotation variables in $\tau$ and $C$ with fresh ones.

\subsection{Constraint solving}

%format Map (a) (b) = a "\hookrightarrow" b

%format empty = "\emptyset"
%format foreach = "\textbf{for each}"
%format while = "\textbf{while}"
%format repeat = "\textbf{repeat}"
%format until = "\textbf{until}"
%format |-> = "\mapsto"

%format Var = "\textbf{Var}"
%format Subst = "\textbf{Subst}"
%format solve = "\!\!\!\!\mathcal{S}"
%format dep = "\mathcal{D}"
%format dep' = "\!\!\!\!\mathcal{D}"
%format gr = "\left\{g \Rightarrow r\right\}"
%format subst_ref       = "\theta_\Ref"
%format subst_ref_alpha = "\theta_\Ref[\alpha]"
%format subst_exn       = "\theta_\Exn"
%format subst_exn_alpha = "\theta_\Exn[\alpha]"
%format |= = "\vDash"
%format somecon = "\Lambda_\iota"
%format <|? = "\sqsubseteq_\iota"
%format exists_i_a = "\exists_\iota \alpha"
%format theta_i_a = "\theta_\iota[\alpha]"
%format theta_i_a1 = "\theta_\iota[\alpha_1]"
%format theta_i_a2 = "\theta_\iota[\alpha_2]"
%format sigma = "\sigma"
%format sigma'
%format D_a = " D[\alpha]"
%format D_a1 = " D[\alpha_1]"
%format D_a2 = " D[\alpha_2]"
%format g_1
%format g_2
%format worklist = " W"

%format entails = "\Vdash"

The constraint solver $\mathcal{S}$ takes a constraint set $C$ and produces a substitution $\theta$ that solves it. The solver assumes that all subtyping constaints ($\leq_\iota$) have been decomposed into atomic constrains ($\sqsubseteq_\iota$) using the syntax-directed part of the subtyping relation (\textsc{SA}) as a decomposition algorithm.

%\begin{figure}[!h]
    \begin{code}
        solve    ::  Set Constr -> Subst
        solve C  =   do  foreach alpha `elem` fv C do
                           subst_ref_alpha  <- empty
                           subst_exn_alpha  <- empty
                           D_a              <- empty
                         foreach c `elem` C do
                           D <- dep D c
                         worklist <- C
                         while worklist /= empty do
                           gr # worklist <- worklist
                           if V subst_ref subst_exn |= g then
                             case r of
                               somecon  <|? alpha    |-> if  theta_i_a /= theta_i_a |#| somecon then
                                                             theta_i_a <- theta_i_a |#| somecon
                                                             worklist <- worklist # D_a
                               alpha_1  <|? alpha_2  |-> if  theta_i_a /= theta_i_a1 |#| theta_i_a2 then
                                                             theta_i_a1 <- theta_i_a1 # theta_i_a2
                                                             worklist <- worklist # D_a1
                         return (V subst_ref subst_exn)
    \end{code}
%    \label{fig-constraint-solver}
%    \caption{Constraint solver}
%\end{figure}

The constraint solver $\mathcal{S}$ relies on a recursive subroutine $\mathcal{D}$ that performs a dependency analysis on the constraints, expressed as a dependency map |D :: Map Var Constr|. There is an entry in the dependency map for each variable for which we are solving, associating it with a set of constraints that may need to be reconsidered by the constraint solver whenever the variable's value is updated.

%\begin{figure}[!h]
    \begin{code}
        dep'      ::  (Map Var Constr) -> Constr -> (Map Var Constr)
        dep' D c  =   do  case c of
                              g => alpha_1 <|? alpha_2  |-> D_a1 <- D_a1 # c
                          case c of
                              somecon <|? alpha => r    |-> D_a <- D_a # c
                              exists_i_a => r           |-> D_a <- D_a # c
                              g_1 \/ g_2 => r           |-> do  D <- dep D (g_1 => r)
                                                                D <- dep D (g_2 => r)
                          return D
    \end{code}
%    \label{fig-dependency-analysis}
%    \caption{Constraint dependency analysis}
%\end{figure}

The solver runs in $O(||C||^3)$. %, where $||C|| \leq c k^w D T$ and $k$ them maximum number of nested \textbf{fix}-operators, $w$ the maximum number of iterations allowed . 
A practical implementation would iterate over the strongly-connected components in the dependency graph and use other heuristics when picking a constraint from the working list.

\subsection{Knowing when to stop}\label{sec-knowingwhentostop}
%format bottomType = "\bot_{\lfloor f \rfloor}"
%format genericInstanceOf = "\preceq"

So far we have omitted the algorithmic rule for \textbf{fix}. It performs a Kleene--Mycroft fixed-point iteration:
\begin{code}
    w env (Fix f e) = do  sigma <- bottomType
                          repeat
                            sigma' <- sigma
                            (V tau C) <- w (env, f :: sigma) e
                            sigma <- gen env tau C
                          until sigma genericInstanceOf sigma'
                          (V tau_2 C_2) <- inst sigma
                          return (V tau_2 (C_2))
\end{code}

Problematically, it is not guaranteed that $\sigma'$ will ever become a generic instance of $\sigma$. \cite{Dussart:1995:PRS:647163.717680} show that this is the case for a simpler type of constraints (subtyping only) by noting that any variable that does not occur free in $\sigma$ or $\Gamma$ can be eliminated (e.g., the constraint set $\{\alpha_1 \sqsubseteq \alpha_2, \alpha_2 \sqsubseteq \alpha_3\}$ with $\alpha_2$ not free in $\sigma$ and $\Gamma$ can be reduced to $\{\alpha_1 \sqsubseteq \alpha_3\}$). The result then follows from the fact that only a finite (quadratic) number of subtype constraints can be formed over the finite set of remaining variables.

We also have conditional constraints and variables occurring in their left-hand side cannot easily be eliminated. However, as static program analysis is the art of computing sound approximations to (seemingly or actual) intractable problems, we should not immediately despair:
    \begin{enumerate}
        \item The constraint set \[\left\{ \Lambda_\iota \sqsubseteq_\iota \alpha \Rightarrow r, g_1 \Rightarrow \beta_1 \sqsubseteq_\iota \alpha, g_2 \Rightarrow \beta_2 \sqsubseteq_\iota \alpha \right\}\] with $\alpha$ not free in $\sigma$ or $\Gamma$, can---after having suitably extended the allowed syntax of constraints---be rewritten into: \[ \left\{ \Lambda_\iota \sqsubseteq_\iota (g_1 \Rightarrow \beta_1 \sqcup g_2 \Rightarrow \beta_2) \Rightarrow r \right\} \]
        As $g_1$ and $g_2$ may again contain variables that need to be eliminated, and we want to keep the size of the individual constraints bounded, we may eventually need to approximate constraints $g \Rightarrow \alpha$ by setting their guard to \textbf{true}.
        \item Alternatively, during the first $k$ Kleene--Mycroft iterations we can neglect to eliminate variables that occur on the left-hand side of a constraint, building an additional finite set $I$ of ineliminable variables. During the later iterations we intentionally introduce poisoning by, instead of generating a fresh variable that will end up in the left-hand side of constraint, reusing a variable from $I$.
        The trick would be in picking variables in such a way that would not disturb a fixed-point that may already have been reached after $k$ iterations.
    \end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Extensions}\label{sec-extensions} %%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Polymorphism} \label{sec-polymorphism}

Consider the polymorphic function |apply|:

\begin{code}
apply :: forall alphabeta. (alpha -> beta) -> alpha -> beta
apply f x = f x
\end{code}

As we cannot inspect an expression with a polymorphic type other than by the exceptions that it may raise when forced to weak head normal form, it is sufficient to treat them as any other base type.

Thus, the function |apply| will be given the following type by our analysis:
\begin{multline*}
    \TyForallNOOVERLINE{\alpha\beta\gamma\delta\epsilon\zeta}{\TyFun{\left(\TyFun{\alpha}{\beta}{\delta}\right)}{\TyFun{\gamma}{\beta}{\zeta}}{\epsilon}\\}{\left\{\gamma \leq_{\Ref\Exn} \alpha, \delta \sqsubseteq_\Exn \beta, \exists_\Exn \delta \Rightarrow \gamma \sqsubseteq_\Exn \beta \right\}}
\end{multline*}

Care needs to be taken when we instantiate the polymorphic variables of a polymorphic type in the underlying type system. When doing so we must also simultaneously update the corresponding polyvariant type used by the analysis.

For example, instantiating the polymorphic underlying type of |apply| with $\left[\alpha \mapsto \TyPair{\mathbb{Z}}{\mathbb{Z}}{}, \beta \mapsto \TyPair{\TyBool}{\TyBool}{} \right]$ will give rise to the instantiation $\left[\alpha \mapsto \TyPair{\eta}{\theta}{\alpha}, \beta \mapsto \TyPair{\iota}{\kappa}{\beta}, \gamma \mapsto \TyPair{\lambda}{\mu}{\gamma} \right]$ of the polyvariant type used in the analysis:
\begin{multline*}
    \TyForallNOOVERLINE{\alpha\beta\gamma\delta\epsilon\zeta\eta\theta\iota\kappa\lambda\mu}{\TyFun{\left(\TyFun{\TyPair{\eta}{\theta}{\alpha}}{\TyFun{\iota}{\kappa}{\beta}}{\delta}\right)}{\TyFun{\TyPair{\lambda}{\mu}{\gamma}}{\TyFun{\iota}{\kappa}{\beta}}{\zeta}}{\epsilon}\\}{\left\{\TyPair{\lambda}{\mu}{\gamma} \leq_{\Ref\Exn} \TyPair{\eta}{\theta}{\alpha}, \delta \sqsubseteq_\Exn \beta, \exists_\Exn \delta \Rightarrow \gamma \sqsubseteq_\Exn \beta \right\}}
\end{multline*}
In the general case we need to:
    \begin{enumerate}
        \item Generate an \emph{almost} fresh linear type for each of the polyvariant variables positionally corresponding to a polymorphic variable that has been instantiated in the underlying type. This type is almost, but not entirely, fresh as we do need to preserve the original variable as the top-level annotation on the new fresh type. Thus, for a type substitution $\alpha \mapsto \tau$, we need $\TopLevel{\tau} = {\alpha}$.
        
        Note that multiple polyvariant type variables in the type inferred by the analysis might correspond to a single polymorphic type variable that is being instantiated in the underlying type. In the example given above both the polyvariant variables $\alpha$ and $\gamma$ correspond positionally to the polymorphic type variable $\alpha$.
        \item We need to quantify over all the fresh variables introduced.
        \item We need to apply the type substitution to the constraint set, but only to the subtype constraints ($\leq_\iota$) and not the atomic constraints ($\sqsubseteq_\iota$), as the latter were generated solely to relate top-level annotations to each other.
    \end{enumerate}
Due to subtype constraints being treated differently from atomic constraints, the analysis now must also be careful not to decompose the subtype constraints into atomic constraints too early. While an implementation will already want to postpone this until right before sending all the gathered constraints to the constraint solver for performance reasons, this now also becomes important for correctness.

\subsection{Algebraic data types}

We admit that ``non-strict higher-order functional languages with imprecise exception semantics'' is something of a euphemism for Haskell. The biggest remaining piece of the puzzle to scaling this analysis to work on the full Haskell language is the support for pattern-matching on arbitrary user-defined algebraic data types.

While the construction and destruction rules we defined for lists---keeping track of the constructors that can occur at the head of the spine, assuming the constructors occurring in the tail can always be both a nil and a cons-constructor---work adequately for functions operating on nil-terminated lists, this approach will not give useful results when extended to other algebraic data types and applied to the desugaring example from Section~\ref{sec-desugar}, even if extended to keep track of the constructors that can occur in the first $k$ positions of the spine. We critically rely on knowing which of the constructors can occur throughout the \emph{whole} spine of the abstract syntax tree.

We would need to combine both approaches for an accurate analysis: we need to know which constructor can occur at the head of a data structure and which constructors can occur throughout the rest of the spine or, formulated differently, at the recursive positions of the data type. This approach is essentially equivalent to Catch's \emph{multipatterns} \cite{Mitchell:2008:PBE:1411286.1411293}.

The most straightforward implementation splits the data flow into two separate flows $\delta_1$ and $\delta_2$: one to track the constructors occurring at the head of a spine and one to keep track of the constructors occuring in the tail of the spine.
\begin{eqnarray*}
\iota, \kappa &::=& \Ref_1 \quad || \quad \Ref_2 \quad || \quad \Exn
\end{eqnarray*}
While technically simple, the required modifications to the type system are notationally heavy as---unlike between the data flow and the exception flow---values can flow directly between $\delta_1$ and $\delta_2$ and it therefore is no longer sufficient to attach a single flow index $\iota$ to the subtyping relation.
\begin{eqnarray*}
r &::=& ...
  \quad || \quad \alpha_1\ {_\iota}\!\!\sqsubseteq_\kappa \alpha_2
  \quad || \quad ...
\end{eqnarray*}

The updated typing rules rules involving lists would read:
\vspace*{2pt}
%\begin{figure*}[!t]
\begin{gather*}
\Rule{T-Nil}
     {C \Vdash \SingletonNil \sqsubseteq_{\Ref_{12}} \alpha} %% FIXME: subtyping/-effecting?
     {\Judge{\LNil}{\TyList{\tau}{\alpha}}}
     \BigBreak
\Rule{T-Cons}
     {\begin{gathered}
      \Judge{e_1}{\tau_1}
      \quad \Judge{e_2}{\TyList{\tau_2}{\alpha_2}}
      \\ C \Vdash \tau_1 \leq_{{\Ref_{12}}\Exn} \tau
      \quad C \Vdash \tau_2 \leq_{{\Ref_{12}}\Exn} \tau
      \\ C \Vdash \SingletonCons \sqsubseteq_{\Ref_1} \alpha
      \quad C \Vdash \alpha_2\ {_\Exn}\!\!\sqsubseteq_\Exn \alpha
      \quad C \Vdash \alpha_2\ {_{\Ref_{12}}}\!\!\sqsubseteq_{\Ref_2} \alpha
      \end{gathered}}
     {\Judge{\LCons{e_1}{e_2}}{\TyList{\tau}{\alpha}}}
     \BigBreak
\Rule{T-Case}
     {\begin{gathered}
      \Judge{e_1}{\TyList{\tau_1}{\alpha_1}}
      \quad \Judge{e_2}{\tau_2}
      \\ \Judge[C; \Gamma, x_1 : \tau_1, x_2 : \TyList{\tau_1}{\beta}]{e_3}{\tau_3}
      \\ C \Vdash\CCDO[\Ref_{12}\Exn]{\SingletonNil}{\alpha_1}{\exists_\Exn \alpha_1}{\tau_2}{\tau}
      \\ C \Vdash\CCDO[\Ref_{12}\Exn]{\SingletonCons}{\alpha_1}{\exists_\Exn \alpha_1}{\tau_3}{\tau}
      \\ C \Vdash\alpha_1\ {_{\Ref_2}}\!\!\sqsubseteq_{\Ref_{12}} \beta
      \quad C \Vdash \alpha_1\ {_\Exn}\!\!\sqsubseteq_\Exn \beta
      \quad C \Vdash\alpha_1\ {_\Exn}\!\!\sqsubseteq_\Exn \TopLevel{\tau}
      \end{gathered}}
     {\Judge{\Case{e_1}{e_2}{x_1}{x_2}{e_3}}{\tau}}
\end{gather*}
%\label{fig-multipatterns}
%\end{figure*}
\vspace*{2pt}

Issues we have not yet fully investigated include parameterized and higher-kinded data types. In general polyvariance in the analysis should not be directly related to polymorphism in the underlying type system, so all fields in a data type can or should be polyvariantly parameterized, irrespective of whether the field is polymorphically parameterized in the underlying system. Since we are making use of subtyping, the variance (co-, contra-, in- or non-) of fields should be propagated to the polyvariant parameters.

\subsection{Static contract checking} Our analysis can also be used for static contract checking. A contract can be desugared into a Findler--Felleisen wrapper \cite{Findler:2002:CHF:581478.581484}, raising a contract violation exception (together with some additional information on who to blame for the violation) when a contract violation is detected. The data flow-dependence of the analysis should be able to statically determine some contract can never be violated and prevent the contract violation exception from being propagated.

\subsection{Code optimization} While designed as a validating analysis, the analysis can also be used to improve the performance of compiled code. Currently, the Glasgow Haskell Compiler generates inefficient code for |risers|: it will emit code that still contains a \textbf{case}-expression with a branch testing the result in the recursive call as being a nil-constructor and raising an exception if so. Based on the results of our analysis this test can be elided. A small subtlety is that the polyvariance of our analysis should be reduced, as only a single instance of the code will be generated for all polyvariant instantiations; more ambitiously we might want to let the compiler generate specialized instances of the code for different polyvariant instances.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section{Implementation}\label{sec-implementation} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\LORUMIPSUM

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related Work}\label{sec-relatedwork} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{Catch and Dialyzer} Most closely related to our work is Mitchell's case totality checker Catch \cite{Mitchell:2008:PBE:1411286.1411293}. Catch is a first-order backwards analysis, inferring preconditions on functions under which it is guaranteed that no exceptions will be raised or pattern-match failures will occur. To analyze Haskell programs, a specially crafted and incomplete defunctionalization step is required. In contrast, our forwards analysis is type-driven and will naturally work on higher-order programs. Furthermore, Catch assumes functions are strict in all their arguments, while our analysis tries to model the call-by-name semantics more accurately.

The Dialyzer discrepancy analyzer for Erlang \cite{Lindahl:2006:PTI:1140335.1140356} works in a similar spirit to our analysis, except that it has a dual notion of soundness: Dialyzer will only warn about function applications that are guaranteed to generate an exception. 

\paragraph{Exception analyses} Several exception analyses have been described in the literature, primarily targeting the detection of uncaught exceptions in ML.
The exception analysis in \cite{kyi} is based on abstract interpretation.
\cite{Guzman94anextended} and \cite{Fahndrich:1998:TDE:893957} describe type-based exception analyses, neither are very precise.
The row-based type system for exception analysis described in \cite{Leroy:2000:TAU:349214.349230} does containing a data-flow analysis component, although one that is specialized towards tracking value-carrying exceptions instead of value-dependent exceptions and thus employing less precise unification methods instead of subtyping.
\cite{Glynn:2002:EAN:581478.581488} developed the first exception analysis for non-strict languages. It is a type-based analysis using Boolean constraints and, although it does not take data flow into account, has a similar flavour to our system.

\paragraph{Conditional constraints} The use of conditional constraints in program analysis can be traced back to \cite{DBLP:conf/ifip/Reynolds68}. %% \begin{WORKINPROGRESS}(So sayeth Pottier, didn't immediately see this when skimming over the original.)\ \end{WORKINPROGRESS}
\cite{Heintze:1994:SAM:182409.182495} uses conditional constraints to model branches in \textbf{case}-expressions for a dead-code analysis.
Constraint-based $k$-CFA analyses \cite{Shivers:1988:CFA:53990.54007}, although traditionally not formulated as a type system, can use conditional constraints to let the control flow depend on the data flow.
\cite{Aiken:1994:STC:174675.177847} uses conditional constraints to formulate a soft-typing system for dynamic languages.
\cite{Pottier:2000:VCT:763845.763849} developed an expressive constraint-based type system incorporating subtyping, conditional constraints and rows and applied it to several inference problems, including accurate pattern-matchings.

%format data = "\textbf{data}"
%format rectype = "\textbf{rectype}"

\paragraph{Refinement types (\ala intersection types)} The refinement type system in \cite{Freeman:1991:RTM:113445.113468} attempts to assign more accurate, refined types to already well-typed ML programs using \emph{union} and \emph{intersection types} \cite{Pierce91programmingwithIUP} with the detection of potential pattern-match failures and reduction of warnings about incomplete patterns as one of its goals. In addition to allowing the programmer to define algebraic data types, e.g.:
\begin{code}
data FPList = [] | alpha : FPList
\end{code}
it also allows the programmer to specify a finite number of ``interesting'' recursive types that refine those algebraic types:
\begin{code}
rectype FPNil        =           []
rectype FPSingleton  =  alpha :  []
\end{code}

The refinements |FPNil| and |FPSingleton| respectively select the subtypes of empty and singleton lists from the complete list type. From these recursive types, and using a type union operator, a finite type lattice can be computed automatically:
\begin{center}
\begin{tikzpicture}
    \tikzstyle{all nodes}=[inner sep=4pt]
    \draw node(top)at(1,3){|FPList|}
          node(sorn)at(1,2){\raisebox{0pt}[\height][0pt]{{|FPNil alpha|} $\lor$ {|FPSingleton alpha|}}}
          node(s)at(0,1){\raisebox{0pt}[\height][0pt]{|FPNil alpha|}} node(n)at(2,1){|FPSingleton alpha|}
          node(bot)at(1,0){$\bot$};
    \draw[-](top)--(sorn);
    \draw[-](sorn)--(s);
    \draw[-](sorn)--(n);
    \draw[-](s)--(bot);
    \draw[-](n)--(bot);
\end{tikzpicture}
\end{center}
The constructors of the algebraic data type in question can then be more accurately typed in terms of intersection types over this lattice:
\begin{code}
[]     ::  forall alpha.  FPNil alpha
_ : _  ::  forall alpha.  alpha  ->  FPNil        alpha  ->  FPSingleton alpha
           /\             alpha  ->  FPSingleton  alpha  ->  FPList alpha
           /\             alpha  ->  FPList       alpha  ->  FPList alpha
\end{code}

Finally, the |case|-construct, interpreted as a higher-order function and specialized to lists, can be given the intersection type:
\begin{code}
forall alpha  beta_1 beta_2.  FPNil alpha        -> beta_1  -> (alpha  -> FPList  alpha  -> bot     )  -> beta_1
              /\              FPSingleton alpha  -> beta_1  -> (alpha  -> FPNil   alpha  -> beta_2  )  -> beta_1 \/ beta_2
              /\              FPList alpha       -> beta_1  -> (alpha  -> FPList  alpha  -> beta_2  )  -> beta_1 \/ beta_2
\end{code}

Compared to our analysis the inference of intersection types would make this a \emph{relational analysis}, while our use of subtyping and conditional constraints only define a \emph{functional} relation between input and output variables. This would seem to imply our analysis is less precise. As the system by Freeman put some restrictions on recursive definitions of recursive types, it is unclear to us if |risers| could be given a suitable refinement type that precludes the occurrence of pattern-match failures. Additionally, the use of intersection types leads to a superexponential blowup of the size of types in the number of |rectype|-definitions.

\paragraph{Refinement types (\ala dependent types) and contract checking} There has been a long line of work exploring various approaches of \emph{refinement types} in the sense of using \emph{dependent types} to specify contracts (also termed \emph{contract types} or \emph{refinement predicates}).
A refinement type expressing all natural numbers greater than or equal to five would be written as: \[ \{ x : \mathbb{N}\ ||\ x \geq 5 \} \]
Dependent ML \cite{Xi:2007:DMA:1230756.1230759} purposely limits the expressiveness of contracts, so contract checking---although not inference---remains decidable.
\cite{Xu:2009:SCC:1480881.1480889} uses symbolic evaluation to check contracts on Haskell programs.
\cite{Knowles:2010:HTC:1667048.1667051} developed a framework for \emph{hybrid type checking}, where the checking of contracts that could not be proven to either always hold or be violated at compile-time are deferred until run-time.
The work on \emph{liquid types} by \cite{Rondon:2008:LT:1375581.1375602} attempts to automatically infer such refinements using the technique of predicate abstraction.
MoCHi \cite{Kobayashi:2011:PAC:1993498.1993525} employs higher-order model checking.
HALO \cite{Vytiniotis:2013:HHL:2429069.2429121} is a static contract checker that works by translating a Haskell program and its contracts into first-order logic, which can then be proven using an SMT solver.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section{Future Research}\label{sec-futureresearch} %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%\begin{WORKINPROGRESS}
%\begin{description}
%\item[Precision] Not maximally polyvariant due to the mixing of Ref and Exn.
%\item[Scale to Haskell]
%\item[More expressive constraints] Inferring (approximated) regular or context-free grammars. Symbolically evaluate operators (and other expressions) at analysis-time.
%\item[Higher-ranked polyvariance]
%\item[CFL-reachability?]
%\item[Array bounds checking]
%\end{description}
%\end{WORKINPROGRESS}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\clearpage

\acks
We would like to thank \ANONYMOUS{Stefan Holdermans}{Tyrion Lannister} for his contributions in the earlier stages of this research and Neil Mitchell for answering several questions related to Catch.

%\clearpage

\bibliographystyle{abbrvnat}
\bibliography{paper} % FIXME: merge .bbl here and add \softraggedright

\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\appendix %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Metatheory}  %%% QWERTY %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Subtyping} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{lemma}\label{lemma-one}
    If $\Centail{\tau_1 \leq_\iota \tau_2}$ then $\Centail{\TopLevel{\tau_1} \sqsubseteq_\iota \TopLevel{\tau_2}}$.
\end{lemma}
\begin{proof}
    By inversion of the subtype relation; the result is immediate in all cases.
\end{proof}

\subsection{Constraints}

\begin{theorem}[Soundness of constraint logic]
    If $\CM{C}$ and $\Centail{D}$ then $\CM{D}$.
\end{theorem}
\begin{proof}
    By induction on the derivation of $\Centail{D}$.

    \IndCase{CL-$\Rightarrow$I} We need to show that if $\CM{C}$ and $\Centail{g \Rightarrow r}$ then $\CM{g \Rightarrow r}$.
    The induction hypothesis states that if $\CM{C, g}$ and $\Centail[C,g]{r}$ then $\CM{r}$.
    Our assumptions are:
        \begin{gather}
            \CM{C} \label{cl-ii-1} \\
            \Centail{g \Rightarrow r} \label{cl-ii-2} \\
            \Centail[C,g]{r} \label{cl-ii-3}
        \end{gather}
    
    We perform a case-split on $\CM{g}$.
    
        \emph{Subcase} ``$\CM{g}$'': We can now apply the induction hypothesis and find that
            \begin{gather}
                \CM{r} \label{cl-ii-4}
            \end{gather}
        We apply \CiteRule{CL-$\Rightarrow$I} using (\ref{cl-ii-4}) and the assumption introduced in the subcase to obtain
            \begin{gather}
                \CM{g \Rightarrow r}
            \end{gather}
            
        \emph{Subcase} ``$\theta \nvDash g$'': We can immediately apply \CiteRule{CL-$\Rightarrow$I} using the assumption introduced in the subcase to obtain the desired result.
        
    \IndCase{CL-$\Rightarrow$E} We need to show that if $\CM{C,g}$ and $\Centail[C,g]{r}$ then $\CM{r}$.
    The induction hypothesis states that if $\CM{C}$ and $\Centail{g \Rightarrow r}$ then $\CM{g \rightarrow r}$.
    Our assumptions are:
        \begin{gather}
            \CM{C,g} \label{cl-ie-1} \\
            \Centail[C,g]{r} \label{cl-ie-2} \\
            \Centail{g \Rightarrow r} \label{cl-ie-3}
        \end{gather}
    From (\ref{cl-ie-1}) it follows that
        \begin{gather}
            \CM{C} \label{cl-ie-4} \\
            \CM{g} \label{cl-ie-5}
        \end{gather}
    We can now apply the induction hypothesis to find
        \begin{gather}
            \CM{g \Rightarrow r} \label{cl-ie-6}
        \end{gather}
    Applying the inversion lemma to (\ref{cl-ie-6}) reveals that the last inference rule used in its derivation can only have been \CiteRule{CM-Impl}, so we find that
        \begin{gather}
            \CM{g} \Rightarrow \CM{r} \label{cl-ie-7}
        \end{gather}
    From (\ref{cl-ie-5}) and (\ref{cl-ie-7}) we obtain
        \begin{gather}
            \CM{r}
        \end{gather}
    concluding the proof.
    
    \IndCase{CL-$\lor$I} We need to show that if $\CM{C}$ and $\Centail{g_1 \lor g_2}$ then $\CM{g_1 \lor g_2}$.
    The induction hypothesis states that if $\CM{C}$ and $\Centail{g}$ then $\CM{g_1}$.
    Our assumptions are:
        \begin{gather}
            \CM{C} \\
            \Centail{g_1 \lor g_2} \\
            \Centail{g_1}
        \end{gather}
    We can immediately apply the induction hypothesis and get
        \begin{gather}
            \CM{g_1} \label{cl-or-4}
        \end{gather}
    Applying \CiteRule{CM-Left} to (\ref{cl-or-4}) gives us
        \begin{gather}
            \CM{g_1 \lor g_2}
        \end{gather}
    concluding the proof.
    
    \IndCase{CL-$\lor$C} We need to show that if $\CM{C}$ and $\Centail{g_2 \lor g_1}$ then $\CM{g_2 \lor g_1}$.
    The induction hypothesis states that if $\CM{C}$ and $\Centail{g_1 \lor g_2}$ and $\CM{g_1 \lor g_2}$.
    Our assumptions are:
        \begin{gather}
            \CM{C} \\
            \Centail{g_2 \lor g_1} \\
            \Centail{g_1 \lor g_2}
        \end{gather}
    We can immediately apply the induction hypothesis, giving us:
        \begin{gather}
            \CM{g_1 \lor g_2} \label{cl-oc-4}
        \end{gather}
    Applying the inversion lemma to (\ref{cl-oc-4}) reveals it can either have been constructed by \CiteRule{CM-Left} or otherwise by \CiteRule{CM-Right}.
    
    \emph{Subcase} \CiteRule{CM-Left}: We obtain the additional assumption $\CM{g_1}$ and can apply \CiteRule{CM-Right} to get $\CM{g_2 \lor g_1}$.
    
    \emph{Subcase} \CiteRule{CM-Right}: We obtain the additional assumption $\CM{g_2}$ and can apply \CiteRule{CM-Left} to get $\CM{g_2 \lor g_1}$.
    
    \IndCase{CL-$\exists$I} We need to show that if $\CM{C}$ and $\Centail{\exists_\iota \alpha}$ then $\CM{\exists_\iota \alpha}$.
    
    The induction hypothesis states that if $\CM{C}$ and $\Centail{\Lambda_\iota \sqsubseteq_\iota \alpha}$ then $\CM{\Lambda_\iota \sqsubseteq_\iota \alpha}$.
    
    We can immediately apply the induction hypothesis. Inversion on its result reveals that it can only have been constructed by \CiteRule{CM-Con}, giving us $\Lambda_\iota \sqsubseteq_\iota \theta_\iota \alpha$. We can use this to apply \CiteRule{CM-Exists}, giving us the desired result.

    \IndCase{CL-$\emptyset$} We need to show that if $\CM{C}$ and $\Centail{\emptyset \sqsubseteq_\iota \alpha}$ then $\CM{\emptyset \sqsubseteq_\iota \alpha}$.
    
    From the order theoretic axioms it follows that
        \begin{gather}
            \emptyset \sqsubseteq_\iota \theta_\iota \alpha \label{cl-empty-1}
        \end{gather}
    Applying \CiteRule{CM-Con} to (\ref{cl-empty-1}) gives us
        \begin{gather}
            \CM{\emptyset \sqsubseteq_\iota \alpha}.
        \end{gather}
    
    \IndCase{CL-Lub} We need to show that if $\CM{C}$ and $\Centail{\alpha_1 \sqcup \alpha_2}$ then $\CM{\alpha_1 \sqcup \alpha_2 \sqsubseteq_\iota \beta}$.
    The induction hypotheses state that:
        \begin{enumerate}
            \item If $\CM{C}$ and $\Centail{\alpha_1 \sqsubseteq_\iota \beta}$ then $\CM{\alpha_1 \sqsubseteq_\iota \beta}$.
            \item If $\CM{C}$ and $\Centail{\alpha_2 \sqsubseteq_\iota \beta}$ then $\CM{\alpha_2 \sqsubseteq_\iota \beta}$.
        \end{enumerate}
    Our assumptions are:
        \begin{gather}
            \CM{C} \\
            \Centail{\alpha_1 \sqcup \alpha_2 \sqsubseteq-\iota \beta} \\
            \Centail{\alpha_1 \sqsubseteq_\iota \beta} \\
            \Centail{\alpha_2 \sqsubseteq_\iota \beta}
        \end{gather}
    We can immediately apply the induction hypotheses, giving us:
        \begin{gather}
            \CM{\alpha_1 \sqsubseteq_\iota \beta} \label{cl-lub-5} \\
            \CM{\alpha_2 \sqsubseteq_\iota \beta} \label{cl-lub-6}
        \end{gather}
    Applying the inversion lemma to both (\ref{cl-lub-5}) and (\ref{cl-lub-6}) reveals that they can only have been constructed using \CiteRule{CM-Var}, giving us:
        \begin{gather}
            \theta_\iota \alpha_1 \sqsubseteq_\iota \theta_\iota \beta \\
            \theta_\iota \alpha_2 \sqsubseteq_\iota \theta_\iota \beta
        \end{gather}
    By order theoretic reasoning we find that
        \begin{gather}
            \theta_\iota \alpha_1 \sqcup \theta_\iota \alpha_2 \sqsubseteq_\iota \theta_\iota \beta
        \end{gather}
    As substitutions distribute over lattice operations, we also have:
        \begin{gather}
            \theta_\iota \left( \alpha_1 \sqcup \alpha_2 \right) \sqsubseteq_\iota \theta_\iota \beta \label{cl-lub-10}
        \end{gather}
    Finally, we can apply \CiteRule{CM-Var} to (\ref{cl-lub-10}) to obtain
        \begin{gather}
            \CM{\alpha_1 \sqcup \alpha_2 \sqsubseteq_\iota \beta}
        \end{gather}
    
    \IndCase{CL-Weak} We need to show that if $\CM{C_1, C_2}$ and $\Centail[C_1, C_2]{c}$ then $\CM{c}$.
    The induction hypothesis states that if $\CM{c}$ and $\Centail[C_1]{c}$ then $\CM{c}$.
    Our assumptions are:
        \begin{gather}
            \CM{C_1, C_2} \label{cl-weak-1} \\
            \Centail[C_1, C_2]{c} \\
            \Centail[C_1]{c}
        \end{gather}
    From the definition of (\ref{cl-weak-1}) it follows that
        \begin{gather}
            \CM{C_1}
        \end{gather}
    We can now apply the induction hypothesis and obtain
        \begin{gather}
            \CM{c}
        \end{gather}

    \IndCase{CL-MP} We need to show that if $\CM{C}$ and $\Centail{c_2}$ then $\CM{c_2}$.
    The induction hypotheses state that:
        \begin{enumerate}
            \item If $\CM{C}$ and $\Centail{c_1}$ then $\CM{c_1}$.
            \item If $\CM{C, c_1}$ and $\Centail[C, c_1]{c_2}$ then $\CM{c_2}$.
        \end{enumerate}
    
    Our assumptions are:
        \begin{gather}
            \CM{C} \label{mp1} \\
            \Centail{c_1} \label{mp2} \\
            \CM[C, c_1]{c_2} \label{mp3}
        \end{gather}
    Applying the first induction hypothesis using (\ref{mp1}) and (\ref{mp2}) gives us:
        \begin{gather}
            \CM{c_1} \label{mp4}
        \end{gather}
    We can write (\ref{mp1}) and (\ref{mp4}) as
        \begin{gather}
            \CM{C, c_1} \label{mp5}
        \end{gather}
    Applying the second induction hypothesis using (\ref{mp5}) and (\ref{mp3}) gives us:
        \begin{gather}
            \CM{c_2}
        \end{gather}
    which is what was asked for.

\end{proof}

\subsection{Progress} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{lemma}[Canonical forms] %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    If $v$ is a value with underlying type $\TyBool$ then $v = \emph{\BTrue}$, $v = \emph{\BFalse}$ or $v = \Crash{\ell}$ for some $\ell$. If $v$ is a value with underlying type $\TyInt$ then $v = n$ or $v = \Crash{\ell}$. If $v$ is a value of type $\TyFun{\tau_1}{\tau_2}{\alpha}$ then $v = \CloseEMPH{\Abs{x}{e}}{\rho}$ or $v = \Crash{\ell}$. If $v$ is a value of type $\TyPair{\tau_1}{\tau_2}{\alpha}$ then $v = \CloseEMPH{\Pair{e_1}{e_2}}{\rho}$ or $v = \Crash{\ell}$. If $v$ is a value of type $\TyList{\tau}{\alpha}$ then $v = \LNil$, $v = \CloseEMPH{\LCons{e_1}{e_2}}{\rho}$ or $v = \Crash{\ell}$.
\end{lemma}
\begin{proof} Recall that values can only be of the forms $\BTrue$, $\BFalse$, $n$, $\Crash{\ell}$, $\LNil$ or $\Close{e}{\rho}$. Except for values of the last form all cases follow either immediately or can be discarded by inversion of the typing relation. We thus proceed to check values of the last form.

We assumed no subexpressions of the form $\Close{e}{\rho}$ were present in the original program, so they can only have been introduced by evaluation using rules \CiteRule{E-Abs}, \CiteRule{E-Pair} or \CiteRule{E-Cons}. \CiteRule{T-Close} tells us that for $\Close{e}{\rho}$ to have underlying type $\TyBool$ or $\TyInt$, $e$ must be of underlying type $\TyBool$ or $\TyInt$, respectively. None of the three aforementioned evaluation rules can produce an expression of this type. If $v$ is of either type $\TyFun{\tau_1}{\tau_2}{\alpha}$, $\TyPair{\tau_1}{\tau_2}{\alpha}$ or $\TyList{\tau}{\alpha}$ then an expression of the form $\Close{e}{\rho}$ must have been produced by \CiteRule{E-Abs}, \CiteRule{E-Pair} or \CiteRule{E-Cons}, respectively. In each case $e$ is then of the required form.
\end{proof}

\begin{theorem}[Progress] %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	If $\Judge{e}{\sigma}$ then either $e$ is value or there exist an $e'$, such that for any $\rho$ with $\EC{\Gamma}{\rho}$ we have $\Reduce{e}{e'}$.
\end{theorem}

\begin{proof}
	By induction on the typing derivation.

    \IndCase{T-Var} We can make progress by applying $\CiteRule{E-Var}$.
    
    \IndCase{T-Con} $c$ is a value.
    
    \IndCase{T-Exn} $\Crash{\ell}$ is a value.
    
    \IndCase{T-Abs} We can make progress by applying \CiteRule{E-Abs}.
    
    \IndCase{T-App} Given $\Judge{\App{e_1}{e_2}}{\tau_1}$, the last of the typing derivation must have been \CiteRule{T-App} and by inversion on the typing relation we get $\Judge{e_1}{\TyFun{\tau_2}{\tau_1}{\alpha}}$ and $\Judge{e_2}{\tau_2}$. From the induction hypothesis it follows that either $e_1$ is a value or $e_1$ can make progress. In the latter case we can make progress by applying \CiteRule{E-App}. If $e_1$ is a value then it follows from the canonical forms lemma that either $e_1 = \Close{\Abs{x}{e}}{\rho}$ or $e_1 = \Crash{\ell}$. In the first case we can make progress by applying \CiteRule{E-AppAbs}. In the second case it follows from the induction hypothesis that either $e_2$ can make progress or is a value. In these cases we can make progress by applying \CiteRule{E-AppExn1} or \CiteRule{E-AppExn2}, respectively.
    
    \IndCase{T-Fix} We can make progress by applying \CiteRule{E-Fix}.
    
    \IndCase{T-Let} We can make progress by applying \CiteRule{E-Let}.

	\IndCase{T-If} Given $\Judge{\IfThenElse{e_1}{e_2}{e_3}}{\tau}$ then it follows from the induction hypothesis that either $e_1$ is a value or $\Reduce{e_1}{e_1'}$. In the latter case we can make progress by applying \CiteRule{E-If}. In the former case we continue by case-inspection. We assumed that $e$ is well-typed in the underlying type system, thus from the canonical forms lemma if follows that either $e_1 = \BTrue$, $e_1 = \BFalse$ or $e_1 = \Crash{\ell}$. In the first two cases we can make progress by applying \CiteRule{E-IfTrue} or \CiteRule{E-IfFalse}, respectively. In the third case it follows from the induction hypothesis that either $\Reduce{e_2}{e_2'}$ or $\Reduce{e_3}{e_3'}$, or both $e_2$ and $e_3$ are values. In those cases \CiteRule{E-IfExn1}, \CiteRule{E-IfExn2} or \CiteRule{E-IfExn3} apply, respectively.
	
	\IndCase{T-Op} Given $\Judge{e_1 \oplus e_2}{\alpha}$, it follows from the induction hypothesis that either at least one of $e_1$ and $e_2$ can make progress or both are values. In the first case either \CiteRule{E-Op1} or \CiteRule{E-Op2} applies. We assumed the expression was well-typed in the underlying type system, thus in the second case if follows from the canonical forms lemma that either $e_i = n_i$ or $e_i = \Crash{\ell_i}$ for $i \in \{1,2\}$. In these cases either \CiteRule{E-OpNum}, \CiteRule{E-OpExn1}, \CiteRule{E-OpExn2} or \CiteRule{E-OpExn3} applies.

    \IndCase{T-Pair} We can make progress by applying \CiteRule{E-Pair}.

    \IndCase{T-Fst} Given $\Judge{\Fst{e}}{\tau_1}$, it follows from the induction hypothesis that either $e$ can make progress or it is a value. In the first case the whole expression can make progress by applying \CiteRule{E-Fst}. In the second case it follows from the canonical forms lemma that either $e = \Close{\Pair{e_1}{e_2}}{\rho}$ or $e = \Crash{\ell}$. In both cases we can make progress by applying \CiteRule{E-FstPair} or \CiteRule{E-FstExn}, respectively.

    \IndCase{T-Snd} As \CiteRule{T-Fst}.
    
    \IndCase{T-Nil} $\LNil$ is a value.
    
    \IndCase{T-Cons} We can make progress by applying \CiteRule{E-Cons}.
    
    \IndCase{T-Case} Given \[\Judge{\Case{e_1}{e_2}{x_1}{x_2}{e_3}}{\tau},\] it follows from the induction hypothesis that either $e_1$ is a value or it can make progress. In the latter case we can make progress by applying \CiteRule{E-Case}. In the former case we continue by case inspection on the values of $e_1$. We assumed that $e$ is well-typed in the underlying type system, thus from the canonical forms lemma it follows that either $e_1 = \LNil$, $e_1 = \Close{\LCons{e_1}{e_2}}{\rho}$ or $e_1 = \Crash{\ell}$. In the first and second case we can make progress by applying \CiteRule{E-CaseNil} or \CiteRule{E-CaseCons}, respectively. In case $e_1$ is an exceptional value, the induction hypothesis tells us that either at least one of $e_2$ and $e_3$ can make progress, or both of them are values. In these case we can apply \CiteRule{E-CaseExn1} or \CiteRule{E-CaseExn2}, or \CiteRule{E-CaseExn3}, respectively.
    
    \IndCase{T-Close} $\Close{e}{\rho}$ is a value.
    
    \IndCase{T-Bind} Given $\Judge{\Bind{\rho}{e}}{\tau}$ it follows from the induction hypothesis that either $e$ can make progress or it is a value. In these cases we can apply \CiteRule{E-Bind1} or \CiteRule{E-Bind2}, respectively.

\end{proof}

\subsection{Preservation} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{theorem}[Preservation] %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
If $\Judge{e}{\sigma_1}$, $\Reduce{e}{e'}$ and $\EC{\Gamma}{\rho}$ then $\Judge{e'}{\sigma_2}$ with $C \Vdash \sigma_2 \leq_{\Ref\Exn} \sigma_1$.
\end{theorem}
\begin{proof}
By induction on the reduction relation.

    \IndCase{E-Var} We need to show that if
            \begin{gather*}
                \Judge[D;\Delta]{x}{\tau} \\
                \Reduce[\rho,x:e]{x}{\Bind{\rho}{e}}
            \end{gather*}
        and
            \begin{gather*}
                \EC{\Delta}{\rho,x:e}
            \end{gather*}
        then
            \begin{gather*}
                \Judge[C;\Delta]{\Bind{\rho}{e}}{\tau'}
            \end{gather*}
        with
            \begin{gather*}
                \Centail{\tau' \leq_{\Ref\Exn} \tau}.
            \end{gather*}
                
    Applying the inversion lemma to $\Judge[D;\Delta]{x}{\tau}$ reveals it can only have been constructed using \CiteRule{T-Var}, giving us:
        \begin{gather}
            \Judge[C;\Gamma,x:\TyForall{\alpha}{\tau}{D}]{x}{\SUBST{\tau}} \label{e-var-1} \\
            \Centail{\SUBST{D}} \label{e-var-2}
        \end{gather}
    Thus we can take $\Delta \mapsto \Gamma, x :  \TyForall{\alpha}{\tau}{D}$ and $\tau \mapsto \SUBST{\tau}$ and show that if
        \begin{gather*}
            \Judge[C;\Gamma,x:\TyForall{\alpha}{\tau}{D}]{x}{\SUBST{\tau}} \\
            \Reduce[\rho,x:e]{x}{\Bind{\rho}{e}}
        \end{gather*}
    and
        \begin{gather*}
            \EC{\Gamma,x:\TyForall{\alpha}{\tau}{D}}{\rho,x:e}
        \end{gather*}
    then
        \begin{gather*}
            \Judge[C;\Gamma, x : \TyForall{\alpha}{\tau}{D}]{\Bind{\rho}{e}}{\SUBST{\tau}}
        \end{gather*}
    with
        \begin{gather*}
            \Centail{\SUBST{\tau} \leq_{\Ref\Exn} \SUBST{\tau}}.
        \end{gather*}
    
    Applying the inversion lemma to \[\EC{\Gamma,x:\TyForall{\alpha}{\tau}{D}}{\rho,x:e}\] reveals it can only have been constructed by \CiteRule{EC-Extend}, giving us:
        \begin{gather}
            \EC{\Gamma}{\rho} \label{e-var-3} \\
            \Judge{e}{\TyForall{\alpha}{\tau}{D}} \label{e-var-4}
        \end{gather}

    Applying \CiteRule{T-Bind} to (\ref{e-var-3}) and (\ref{e-var-4}) gives us:
        \begin{gather}
            \Judge{\Bind{\rho}{e}}{\TyForall{\alpha}{\tau}{D}} \label{e-var-5}
        \end{gather}

    Applying \CiteRule{T-Inst} to (\ref{e-var-5}) and (\ref{e-var-2}) gives us:
        \begin{gather}
            \Judge{\Bind{\rho}{e}}{\SUBST{\tau}} \label{e-var-6}
        \end{gather}
        
    We conclude the proof by noting that $\Centail{\SUBST{\tau} \leq_{\Ref\Exn} \SUBST{\tau}}$ follows from the reflexivity of the subtype relation.
    
    \IndCase{E-Abs} Apply \CiteRule{T-Close} (and note that the subtype relation is reflexive.)
    
    \IndCase{E-App} We need to show that if $\Judge{\App{e_1}{e_2}}{\tau_{12}}$ and $\Reduce{\App{e_1}{e_2}}{\App{e_1'}{e_2}}$ then $\Judge{\App{e_1'}{e_2}}{\tau_{2}}$ with $\Centail{\tau_2 \leq_{\Ref\Exn} \tau_{12}}$.
    The induction hypothesis states that if
        \begin{gather*}
            \Judge{e_1}{\TyFun{\tau_{11}}{\tau_{12}}{\alpha_1}}
        \end{gather*}
        and \[\Reduce{e_1}{e_1'}\] then
    \begin{equation}\label{eapp-1}
    \Judge{e_1'}{\TyFun{\tau_{21}}{\tau_{22}}{\alpha_2}}
    \end{equation}
    with $\Centail{\TyFun{\tau_{21}}{\tau_{22}}{\alpha_2} \leq_{\Ref\Exn} \TyFun{\tau_{11}}{\tau_{12}}{\alpha_1}}$, which---by inversion of the subtyping relation---implies 
    \begin{gather}
    \label{eapp-2}\Centail{\tau_{11} \leq_{\Ref\Exn} \tau_{21}} \\
    \label{eapp-3}\Centail{\tau_{22} \leq_{\Ref\Exn} \tau_{12}} \\
    \label{eapp-4}\Centail{\alpha_2 \sqsubseteq_{\Ref\Exn} \alpha_1}.
    \end{gather}

    Applying the inversion lemma to $\Judge{\App{e_1}{e_2}}{\tau_{12}}$ reveals it can only have been constructed by \CiteRule{T-App}, thus we have
        \begin{gather}
            \Judge{e_1}{\TyFun{\tau_{11}}{\tau_{12}}{\alpha_1}} \\
            \label{eapp-6}\Judge{e_2}{\tau_{13}} \\
            \label{eapp-7}\Centail{\tau_{13} \leq_{\Ref\Exn} \tau_{11}} \\
            \label{eapp-8}\Centail{\alpha_1 \sqsubseteq_{\Exn} \TopLevel{\tau_{12}}} \\
            \label{e-app-39}\Centail{\exists_\Exn \alpha_1 \Rightarrow \TopLevel{\tau_{13}} \sqsubseteq_\Exn \TopLevel{\tau_{12}}}.
        \end{gather}

    We can now apply the induction hypothesis. By applying \CiteRule{T-App} with $e_1 \mapsto e_1'$, $e_2 \mapsto e_2$, $\tau_1 \mapsto \tau_{21}$, $\tau_2 \mapsto \tau_{12}$, $\tau_3 \mapsto \tau_{13}$ and $\alpha \mapsto \alpha_1$ we find that \[\Judge{\App{e_1'}{e_2}}{\tau_{12}}.\] We still need to check that the preconditions of \CiteRule{T-App} hold:
    \begin{enumerate}
    \item $\Judge{e_1'}{\TyFun{\tau_{21}}{\tau_{12}}{\alpha_1}}$ follows from applying \CiteRule{T-Sub} to (\ref{eapp-1}) using (\ref{eapp-3}) and (\ref{eapp-4}).
    \item $\Centail{\tau_{13} \leq_{\Ref\Exn} \tau_{21}}$ follows from the transitivity of the subtyping relation applied to (\ref{eapp-2}) and (\ref{eapp-7}).
    \end{enumerate}
    The other three preconditions follow directly from (\ref{eapp-6}), (\ref{eapp-8}), and (\ref{e-app-39}) respectively.

    To conclude the proof, we need to show that $\Centail{\tau_{12} \leq_{\Ref\Exn} \tau_{12}}$, which holds by reflexivity of the subtyping relation.

    \IndCase{E-AppAbs} We need to show that if
        \begin{gather}
            \Judge{\App{\left(\Close{\Abs{x}{e_1}}{\rho_1}\right)}{e_2}}{\tau_2}, \label{e-appabs-thm1} \\
            \EC{\Gamma}{\rho} \label{e-appabs-thm2}
        \end{gather}
    and
        \begin{multline}
            \Reduce{\App{\left(\Close{\Abs{x}{e_1}}{\rho_1}\right)}{e_2}\\}{\Bind{\left(\rho_1, x : \Bind{\rho}{e_2}\right)}{e_1}} \label{e-appabs-thm3}
        \end{multline}
    then
        \begin{gather}
            \Judge{\Bind{\left(\rho_1, x : \Bind{\rho}{e_2}\right)}{e_1}}{\tau_2'} \label{e-appabs-thm4}
        \end{gather}
    with
        \begin{gather}
            \Centail{\tau_2' \leq_{\Ref\Exn} \tau_2}. \label{e-appabs-thm5}
        \end{gather}
    
    The inversion lemma reveals that the last inference rule used to construct (\ref{e-appabs-thm1}) can only have been \CiteRule{T-App}, giving us:
        \begin{gather}
            \Judge{\Close{\Abs{x}{e_1}}{\rho_1}}{\TyFun{\tau_1}{\tau_2}{\alpha}} \label{e-appabs-1} \\
            \Judge{e_2}{\tau_3} \label{e-appabs-2} \\
            \Centail{\tau_3 \leq_{\Ref\Exn} \tau_1} \label{e-appabs-3} \\
            \Centail{\alpha \sqsubseteq_\Exn \TopLevel{\tau_2}} \label{e-appabs-4} \\
            \Centail{\exists_\Exn \alpha \Rightarrow \TopLevel{\tau_3} \sqsubseteq_\Exn \TopLevel{\tau_2}} \label{e-appabs-5}
        \end{gather}
    
    Applying the inversion lemma to (\ref{e-appabs-1}) reveals that the last inference rule used in the derivation can only have been \CiteRule{T-Close}, giving us:
        \begin{gather}
            \Judge[C;\Delta]{\Abs{x}{e_1}}{\TyFun{\tau_1}{\tau_2}{\alpha}} \label{e-appabs-6} \\
            \Judge{\Delta}{\rho_1} \label{e-appabs-7}
        \end{gather}

    Applying the inversion lemma to (\ref{e-appabs-6}) reveals that the last inference rule used in the derivation can only have been \CiteRule{T-Abs}, giving us:
        \begin{gather}
            \Judge[C;\Delta,x:\tau]{e_1}{\tau_2} \label{e-appabs-8}
        \end{gather}

    We construct the desired result using \CiteRule{T-Bind} with $e \mapsto e_1$, $\tau \mapsto \tau_2$, $\rho \mapsto \left(\rho_1, x: \Bind{\rho}{e_2}\right)$ and $\Delta \mapsto \Delta, x : \tau_1$.
    We still need to check the preconditions on \CiteRule{T-Bind} hold:
        \begin{enumerate}
            \item The premise $\Judge[C;\Delta,x:\tau]{e_1}{\tau_2}$ is satisfied by (\ref{e-appabs-8}).
            \item The premise $\EC{\Delta,x:\tau_1}{\rho_1,x:\Bind{\rho}{e_2}}$ can be constructed using \CiteRule{EC-Extend}, checking its premises in turn:
                \begin{enumerate}
                    \item $\EC{\Delta}{\rho_1}$ is satisfied by (\ref{e-appabs-7}).
                    \item $\Judge[C;\Delta]{\Bind{\rho}{e_2}}{\tau_1}$ can be constructed by \CiteRule{T-Bind} with $\Gamma \mapsto \Delta$, $\Delta \mapsto \Gamma$, $\rho \mapsto \rho$, $e \mapsto e_2$ and $\tau \mapsto \tau_1$; checking its premises in turn:
                        \begin{enumerate}
                            \item $\EC{\Gamma}{\rho}$ is satisfied by (\ref{e-appabs-thm2}).
                            \item $\Judge{e_2}{\tau_1}$ holds by using \CiteRule{T-Sub} on (\ref{e-appabs-2}) and (\ref{e-appabs-3}).
                        \end{enumerate}
                \end{enumerate}
        \end{enumerate}
    
    We conclude the proof by noting that $\Centail{\tau_2 \leq_{\Ref\Exn} \tau_2}$ follows from the reflexivity of the subtype relation.
    
    \IndCase{E-AppExn1} We need to show that if $\Judge{\Crash{\ell_1}}{\tau_1}$ and $\Reduce{\App{\Crash{\ell_1}}{e_2}}{\App{\Crash{\ell_1}}{e_2'}}$ then $\Judge{e_2'}{\tau_2}$ with $\Centail{\tau_2 \leq_{\Ref\Exn} \tau_1}$.
    The induction hypothesis states that if \[\Judge{e_2}{\tau_3}\] and \[\Reduce{e_2}{e_2'}\] then
        \begin{gather}
            \Judge{e_2'}{\tau_4} \label{e-appexn1-6} \\
            \Centail{\tau_4 \leq_{\Ref\Exn} \tau_3}. \label{e-appexn1-7}
        \end{gather}
    Applying the inversion lemma to $\Judge{\App{\Crash{\ell_1}}{e_2}}{\tau_1}$ reveals it can only have been constructed by \CiteRule{T-App}, thus we have:
        \begin{gather}
            \Judge{\Crash{\ell_1}}{\TyFun{\tau_1}{\tau_2}{\alpha}} \label{e-appexn1-1} \\
            \Judge{e_2}{\tau_3} \label{e-appexn1-2} \\
            \Centail{\tau_3 \leq_{\Ref\Exn} \tau_1} \label{e-appexn1-3} \\
            \Centail{\alpha \sqsubseteq_{\Exn} \TopLevel{\tau_2}} \label{e-appexn1-4} \\
            \Centail{\exists_\Exn \alpha \Rightarrow \TopLevel{\tau_3} \sqsubseteq_\Exn \TopLevel{\tau_2}} \label{e-appexn1-5}
        \end{gather}
    We can now apply the induction hypothesis. By applying \CiteRule{T-App} with $e_1 \mapsto \Crash{\ell_1}$, $e_2 \mapsto e_2'$, $\tau_1 \mapsto \tau_1$, $\tau_2 \mapsto \tau_2$, $\tau_3 \mapsto \tau_4$ and $\alpha \mapsto \alpha$ we find that \[ \Judge{\App{\Crash{\ell_1}}{e_2'}}{\tau_2}. \]
    We still need to check that the preconditions on \CiteRule{T-App} hold:
        \begin{enumerate}
            \item $\Centail{\tau_4 \leq_{\Ref\Exn} \tau_1}$ follows from (\ref{e-appexn1-7}), (\ref{e-appexn1-3}) and the transitivity of the subtype relation.
            \item Using implication elimination on (\ref{e-appexn1-5}) gives us:
                \begin{gather}
                    \Centail[C, \exists_\Exn \alpha]{\TopLevel{\tau_3} \sqsubseteq_\Exn \TopLevel{\tau_2}} \label{e-appexn1-9}
                \end{gather}
            Using Lemma~\ref{lemma-one} on (\ref{e-appexn1-7}) gives us:
                \begin{gather}
                    \Centail{\TopLevel{\tau_4} \sqsubseteq_{\Ref\Exn} \TopLevel{\tau_3}} \label{e-appexn1-10}
                \end{gather}
            Weakening (\ref{e-appexn1-10}) gives us:
                \begin{gather}
                    \Centail[C, \exists_\Exn \alpha]{\TopLevel{\tau_4} \sqsubseteq_{\Ref\Exn} \TopLevel{\tau_3}} \label{e-appexn1-11}
                \end{gather}
            From (\ref{e-appexn1-11}), (\ref{e-appexn1-9}) and the transitivity of the subtype relation we get:
                \begin{gather}
                    \Centail[C,\exists_\Exn \alpha]{\TopLevel{\tau_4} \sqsubseteq_\Exn \TopLevel{\tau_2}} \label{e-appexn1-12}
                \end{gather}
            Using implication introduction on (\ref{e-appexn1-12}) gives us the desired precondition:
                \begin{gather}
                    \Centail{\exists_\Exn \alpha \Rightarrow \TopLevel{\tau_4} \sqsubseteq_\Exn \TopLevel{\tau_2}}
                \end{gather}
        \end{enumerate}
    The other three preconditions are fulfilled by assumptions (\ref{e-appexn1-1}), (\ref{e-appexn1-6}) and (\ref{e-appexn1-4}). respectively.

    To conclude the proof, we need to show that $\Centail{\tau_2 \leq_{\Ref\Exn} \tau_2}$, which holds by the reflexivity of the subtype relation.
    
    \IndCase{E-AppExn2} We need to show that if $\Judge{\App{\Crash{\ell_1}}{v_2^{\ell_2}}}{\tau_{12}}$ and $\Reduce{\App{\Crash{\ell_1}}{v_2^{\ell_2}}}{\Crash{\ell_1 \sqcup \ell_2}}$ then $\Judge{\Crash{\ell_1 \sqcup \ell_2}}{\tau_{12}'}$ with $\Centail{\tau_{12}' \leq_{\Ref\Exn} \tau_{12}}$.

    Applying the inversion lemma to $\Judge{\App{\Crash{\ell_1}}{v_2^{\ell_2}}}{\tau_{12}}$ reveals it can only have been constructed by \CiteRule{T-App}, thus we have:
        \begin{gather}
            \Judge{\Crash{\ell_1}}{\TyFun{\tau_{11}}{\tau_{12}}{\alpha_1}} \label{e-appexn2-1} \\
            \Judge{v_2^{\ell_2}}{\tau_{13}} \label{e-appexn2-2} \\
            \Centail{\tau_{13} \leq_{\Ref\Exn} \tau_{11}} \label{e-appexn2-3} \\
            \Centail{\alpha_1 \sqsubseteq_\Exn \TopLevel{\tau_{12}}} \label{e-appexn2-4} \\
            \Centail{\exists_\Exn \alpha_1 \Rightarrow \TopLevel{\tau_{13}} \leq_\Exn \TopLevel{\tau_{12}}} \label{e-appexn2-5}
        \end{gather}
    Applying the inversion lemma to (\ref{e-appexn2-1}) reveals it can only have been constructed by \CiteRule{T-Exn}, giving us:
        \begin{gather}
            \Centail{\ell_1 \sqsubseteq_\Exn \TopLevel{\TyFun{\tau_{11}}{\tau_{12}}{\alpha_1}}}
        \end{gather}
    or, by simplification of $\TopLevel{\ \cdot\ }$:
        \begin{gather}
            \Centail{\ell_1 \sqsubseteq_\Exn \alpha_1} \label{e-appexn2-7}
        \end{gather}
    
    When inverting (\ref{e-appexn2-2}) we have to distinguish between two cases: either $v_2^{\ell_2}$ is an exceptional value and it can---by the inversion lemma---only have been been constructed by \CiteRule{T-Exn}, or $v_2^{\ell_2}$ is a non-exceptional value and we took $\ell_2 = \emptyset$.
    
    \emph{Subcase} ``$v_2^{\ell_2}$ is an exceptional value'': Applying the inversion lemma to (\ref{e-appexn2-2}) reveals it can only have been constructed by \CiteRule{T-Exn}, giving us:
        \begin{gather}
            \Centail{\ell_2 \sqsubseteq_\Exn \TopLevel{\tau_{13}}} \label{e-appexn2-8}
        \end{gather}
    We use \CiteRule{T-Exn} to construct an exceptional value \[\Judge{\Crash{\ell_1 \sqcup \ell_2}}{\tau_{12}}.\]
    The precondition $\Centail{\ell_1 \sqcup \ell_2 \sqsubseteq_\Exn \TopLevel{\tau_{12}}}$ can be decomposed into:
        \begin{gather}
            \Centail{\ell_1 \sqsubseteq_\Exn \TopLevel{\tau_{12}}} \label{e-appexn2-9}\\
            \Centail{\ell_2 \sqsubseteq_\Exn \TopLevel{\tau_{12}}} \label{e-appexn2-10}
        \end{gather}
    Precondition (\ref{e-appexn2-9}) is satisfied by transitively combining (\ref{e-appexn2-7}) with (\ref{e-appexn2-4}).
    Using implication elimination on (\ref{e-appexn2-5}) using (\ref{e-appexn2-7}), we find:
        \begin{gather}
            \Centail{\TopLevel{\tau_{13}} \sqsubseteq_\Exn \TopLevel{\tau_{12}}} \label{e-appexn2-11}
        \end{gather}
    Precondition (\ref{e-appexn2-10}) is satisfied by transitively combining (\ref{e-appexn2-8}) with (\ref{e-appexn2-11}).
    For this subcase we can conclude the whole proof by noting that $\Centail{\tau_{12} \leq_{\Ref\Exn} \tau_{12}}$ follows from the reflexivity of the subtype relation.
    
    \emph{Subcase} ``$v_2^{\ell_2}$ is a non-exceptional value'': If $v_2^{\ell_2}$ is a non-exceptional value then we took $\ell_2 = \emptyset$.
    We use \CiteRule{T-Exn} to construct an exceptional value $\Judge{\Crash{\ell_1 \sqcup \ell_2}}{\tau_{12}}$.
    The precondition $\Centail{\ell_1 \sqcup \emptyset \sqsubseteq_\Exn \TopLevel{\tau_{12}}}$ can be simplified to:
        \begin{gather}
            \Centail{\ell_1 \sqsubseteq_\Exn \TopLevel{\tau_{12}}} \label{e-appexn2-12}
        \end{gather}
    Precondition (\ref{e-appexn2-12}) follows from transitively combining (\ref{e-appexn2-7}) with (\ref{e-appexn2-4}).
    For this subcase we can conclude the whole proof by noting that $\Centail{\tau_{12} \leq_{\Ref\Exn} \tau_{12}}$ follows from the reflexivity of the subtype relation.

    \IndCase{E-Fix} We need to show that if
        \begin{gather*}
            \Judge{\Fix{f}{e}}{\SUBST{\tau_1}} \\
            \Reduce{\Fix{f}{e}}{\Bind{\left(\rho, f : \Bind{\rho}{\Fix{f}{e}} \right)}{e}}
        \end{gather*}
    and \[\EC{\rho}{\Gamma}\] then \[\Judge{\Bind{\left( \rho, f : \Bind{\rho}{\Fix{f}{e}} \right)}{e}}{\SUBST{\tau_1}}\] with \[\Centail{\SUBST{\tau_1} \leq_{\Ref\Exn} \SUBST{\tau_1}}.\]
    
    Applying the inversion lemma to $\Judge{\Fix{f}{e}}{\SUBST{\tau_1}}$ reveals it can only have been constructed using \CiteRule{T-Fix}, giving us:
        \begin{gather}
            \Centail{\SUBST{D}} \label{e-fix-1} \\
            \Judge[D;\Gamma, f : \TyForall{\alpha}{\tau_1}{D}]{e}{\tau_2} \label{e-fix-2} \\
            \Centail[D]{\tau_2 \leq_{\Ref\Exn} \tau_1} \label{e-fix-3} \\
            \overline{\alpha} \cap fv(\Gamma;C) = \emptyset \label{e-fix-4} 
        \end{gather}
    
    We can now construct the desired result using \CiteRule{T-Bind} with $\rho \mapsto \left( \rho, f : \Bind{\rho}{\Fix{f}{e}} \right)$, $\sigma \mapsto \SUBST{\tau_1}$, $e \mapsto e$ and $\Delta \mapsto \Gamma, f : \TyForall{\alpha}{\tau_1}{D}$.
    
    We still need to check the preconditions on \CiteRule{T-Bind} hold:
        \begin{enumerate}
            \item Applying the substitution $\SUBST{}$ to (\ref{e-fix-2}) gives us
                    \begin{gather}
                        \Judge[\SUBST{D}; \SUBST{\Gamma, f : \TyForall{\alpha}{\tau_1}{D}}]{e}{\SUBST{\tau_2}} \label{e-fix-5}
                    \end{gather}
                However, as $fv(\Gamma)$ and the domain of the substitution are disjoint and $f$ quantifies over the entire domain of the substitution, this is equivalent to
                    \begin{gather}
                        \Judge[\SUBST{D}; \Gamma, f : \TyForall{\alpha}{\tau_1}{D}]{e}{\SUBST{\tau_2}} \label{e-fix-6}
                    \end{gather}
                From (\ref{e-fix-3}) it follows that
                    \begin{gather}
                        \Centail[\SUBST{D}]{\SUBST{\tau_2} \leq_{\Ref\Exn} \SUBST{\tau_1}} \label{e-fix-7}
                    \end{gather}
                Using \CiteRule{T-Sub} on (\ref{e-fix-6}) with (\ref{e-fix-7}) gives us
                    \begin{gather}
                        \Judge[\SUBST{D}; \Gamma, f : \TyForall{\alpha}{\tau_1}{D}]{e}{\SUBST{\tau_2}} \label{e-fix-8}
                    \end{gather}
                From (\ref{e-fix-8}) and (\ref{e-fix-1}) the desired result follows:
                    \begin{gather}
                        \Judge[C; \Gamma, f : \TyForall{\alpha}{\tau_1}{D}]{e}{\SUBST{\tau_2}} \label{e-fix-8}
                    \end{gather}
            \item We can construct \[\EC{\Gamma, f : \TyForall{\alpha}{\tau_1}{D}}{\rho, f : \Bind{\rho}{\Fix{f}{e}}}\] using \CiteRule{EC-Extend}. We check its preconditions:
                \begin{enumerate}
                    \item The precondition $\EC{\Gamma}{\rho}$ is an assumption made by the theorem.
                    \item The precondition $\Judge{\Bind{\rho}{\Fix{f}{e}}}{\TyForall{\alpha}{\tau_1}{D}}$ can be constructed using \CiteRule{T-Bind} with $\Delta \mapsto \Gamma$. We check its preconditions:
                        \begin{enumerate}
                            \item The precondition $\EC{\Gamma}{\rho}$ is an assumption made by the theorem.
                            \item The precondition $\Judge{\Fix{f}{e}}{\TyForall{\alpha}{\tau_1}{D}}$ can be constructed by \CiteRule{T-Gen}. We check its preconditions:
                                \begin{enumerate}
                                    \item The precondition $\overline{\alpha} \cap fv(\Gamma; C)$ is satisfied by (\ref{e-fix-4}).
                                    \item The precondition $\Judge[C,D;\Gamma]{\Fix{f}{e}}{\tau_1}$ can be constructed using \CiteRule{T-Fix} with $C \mapsto C,D$ and $\overline{\beta} \mapsto \overline{\alpha}$.
                                    %We check its preconditions:
                                    %    \begin{itemize}
                                    %        \item The precondition $\Centail[C,D]{\SUBST[\alpha]{D}}$ holds trivially.
                                    %        \item The precondition $\Judge[D;\Gamma, f : \TyForall{\alpha}{\tau_1}{D}]{e}{\tau_2}$ follows from (\ref{e-fix-2}).
                                    %        \item The precondition $\Centail[D]{\tau_2 \leq_{\Ref\Exn} \tau_1}$ follows from (\ref{e-fix-3}).
                                    %        \item The precondition $\overline{\alpha} \cap fv(\Gamma;C,D)$ holds by extremely vigorous handwaving.
                                    %    \end{itemize}
                                \end{enumerate}
                        \end{enumerate}
                \end{enumerate}
        \end{enumerate}
    
    \IndCase{E-Let} We need to show that if
        \begin{gather}
            \Judge{\Let{x}{e_1}{e_2}}{\tau_2} \label{e-let-thm1} \\
            \EC{\Gamma}{\rho}
        \end{gather}
    and
        \begin{multline}
            \Reduce{\Let{x}{e_1}{e_2}\\}{\Bind{\left(\rho, x : \Bind{\rho}{e_1}\right)}{e_2}}
        \end{multline}
    then
        \begin{gather}
            \Judge{\Bind{\left(\rho, x : \Bind{\rho}{e_1} \right)}{e_2}}{\tau_2'}
        \end{gather}
    with
        \begin{gather}
            \Centail{\tau_2' \leq_{\Ref\Exn} \tau}.
        \end{gather}
    
    Applying the inversion lemma to (\ref{e-let-thm1}) reveals that the last inference rule used in its derivation can only have been \CiteRule{T-Let}, giving us:
        \begin{gather}
            \Judge[C,D;\Gamma]{e_1}{\tau_1} \label{e-let-1} \\
            \Judge[C;\Gamma,x : \TyForall{\alpha}{\tau_1}{D}]{e_2}{\tau_2} \label{e-let-2} \\
            \overline{\alpha} \cap fv(\Gamma;C) = \emptyset \label{e-let-3}            
        \end{gather}
        
    We construct the desired result using \CiteRule{T-Bind} with $\tau \mapsto \tau_2$; $e \mapsto e_2$; $\rho \mapsto \left(\rho, x : \Bind{\rho}{e_1}\right)$ and $\Delta \mapsto \Gamma, x : \TyForall{\alpha}{\tau_1}{D}$.
    We still need to check the preconditions on \CiteRule{T-Bind}:
        \begin{enumerate}
            \item The premise $\Judge[C;\Gamma,\TyForall{\alpha}{\tau_1}{D}]{e_2}{\tau_2}$ is satisfied by (\ref{e-let-2}).
            \item The premise $\EC{\Gamma, x : \TyForall{\alpha}{\tau_1}{D}}{\rho, x : \Bind{\rho}{e_1}}$ can be constructed by \CiteRule{EC-Extend}. We check its preconditions:
                \begin{enumerate}
                    \item The premise $\EC{\Gamma}{\rho}$ follows from the assumption made by the theorem.
                    \item The premise $\Judge{\Bind{\rho}{e_1}}{\TyForall{\alpha}{\tau_1}{D}}$ can be constructed by \CiteRule{T-Gen}. We check its preconditions:
                        \begin{enumerate}
                            \item The premise $\overline{\alpha} \cap fv(\Gamma;C)$ is satisfied by (\ref{e-let-3}).
                            \item The premise $\Judge[C,D;\Gamma]{\Bind{\rho}{e_1}}{\tau_1}$ can be constructed by \CiteRule{T-Bind} with $\rho \mapsto \rho$, $e \mapsto e_1$, $\Delta \mapsto \Gamma$, $\tau \mapsto \tau_1$ and $C \mapsto C, D$. We check its preconditions:
                                \begin{enumerate}
                                    \item The premise $\Judge[C,D;\Gamma]{e_1}{\tau_1}$ is satisfied by (\ref{e-let-1}).
                                    \item The premise $\EC[C,D]{\Gamma}{\rho}$ is satisfied by weakening the assumption made by the theorem
                                \end{enumerate}
                        \end{enumerate}
                \end{enumerate}
        \end{enumerate}
        
    We conclude the proof by noting that $\Centail{\tau_2 \leq_{\Ref\Exn} \tau_2}$ follows from the reflexivity of the subtype relation.
    
    \IndCase{E-If} We need to show that if
        \begin{gather}
            \Judge{\IfThenElse{e_1}{e_2}{e_3}}{\tau} \label{e-if-thm1}
        \end{gather}
    and
        \begin{gather}
            \Reduce{\IfThenElse{e_1}{e_2}{e_3}}{\IfThenElse{e_1'}{e_2}{e_3}}
        \end{gather}
    then $\Judge{\IfThenElse{e_1'}{e_2}{e_3}}{\tau'}$ with $\Centail{\tau' \leq_{\Ref\Exn} \tau}$.
    
    The induction hypothesis states that if $\Judge{e_1}{\alpha_1}$ and $\Reduce{e_1}{e_1'}$ then $\Judge{e_1'}{\alpha_1'}$ with $\Centail{\alpha_1' \leq_{\Ref\Exn} \alpha_1}$.
    
    Applying the inversion lemma to (\ref{e-if-thm1}) reveals it can only have been constructed by \CiteRule{T-If}, giving us:
        \begin{gather}
            \Judge{e_1}{\alpha_1} \label{e-if-1} \\
            \Judge{e_2}{\tau_2} \label{e-if-2} \\
            \Judge{e_3}{\tau_3} \label{e-if-3} \\
            \Centail{\SingletonTrue \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1 \Rightarrow \tau_2 \leq_{\Ref\Exn} \tau} \label{e-if-4} \\
            \Centail{\SingletonFalse \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1 \Rightarrow \tau_3 \leq_{\Ref\Exn} \tau} \label{e-if-5} \\
            \Centail{\alpha_1 \sqsubseteq_\Exn \TopLevel{\tau}} \label{e-if-6}
        \end{gather}
        
    We can now apply the induction hypothesis, giving us:
        \begin{gather}
            \Judge{e_1'}{\alpha_1'} \label{e-if-7} \\
            \Centail{\alpha_1' \leq_{\Ref\Exn} \alpha_1} \label{e-if-8}
        \end{gather}
    Using the inversion lemma on (\ref{e-if-8}) reveals it can only have been constructed by
        \begin{gather}
            \Centail{\alpha_1' \sqsubseteq_{\Ref\Exn} \alpha_1} \label{e-if-9}
        \end{gather}
    
    We can construct the desired result using \CiteRule{T-If} with $e_1 \mapsto e_1$. We still need to check that the preconditions on \CiteRule{T-If} hold:
        \begin{enumerate}
            \item Applying \CiteRule{T-Sub} with (\ref{e-if-7}) and (\ref{e-if-9}) gives us $\Judge{e_1'}{\alpha_1}$.
        \end{enumerate}
    The other five preconditions follow immediately from (\ref{e-if-2})--(\ref{e-if-6}).
    
    \IndCase{E-IfTrue} We need to show that if \[\Judge{\IfThenElse{\BTrue}{e_2}{e_3}}{\tau}\] and \[\Reduce{\IfThenElse{\BTrue}{e_2}{e_3}}{e_2}\] then \[\Judge{e_2}{\tau'}\] with \[\Centail{\tau' \leq_{\Ref\Exn} \tau}.\]
    
    Applying the inversion lemma to $\Judge{\IfThenElse{\BTrue}{e_2}{e_3}}{\tau}$ reveals it can only have been constructed by \CiteRule{T-If}, thus we have:
        \begin{gather}
            \Judge{\BTrue}{\alpha_1} \label{e-iftrue-1} \\
            \Judge{e_2}{\tau_2} \label{e-iftrue-2} \\
            \Judge{e_3}{\tau_3} \label{e-iftrue-3} \\
            \Centail{\SingletonTrue \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1 \Rightarrow \tau_2 \leq_{\Ref\Exn} \tau} \label{e-iftrue-4} \\
            \Centail{\SingletonFalse \sqsubseteq_\Exn \alpha_1 \lor \exists_\Exn \alpha_1 \Rightarrow \tau_3 \leq_{\Ref\Exn} \tau} \label{e-iftrue-5} \\
            \Centail{\alpha_1 \sqsubseteq_\Exn \TopLevel{\tau}} \label{e-iftrue-6}
        \end{gather}
    Applying the inversion lemma to (\ref{e-iftrue-1}) reveals it can only have been constructed using \CiteRule{T-Con}, giving us:
        \begin{gather}
            \Centail{\iota(\BTrue) \sqsubseteq_\Ref \alpha_1}, \label{e-iftrue-7}
        \end{gather}
    which is equivalent to
        \begin{gather}
            \Centail{\SingletonTrue \sqsubseteq_\Ref \alpha_1}. \label{e-iftrue-8}
        \end{gather}
    Using $\lor$-introduction on (\ref{e-iftrue-8}) and implication elimination on (\ref{e-iftrue-4}) we find
        \begin{gather}
            \Centail{\SingletonTrue \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1} \label{e-iftrue-9} \\
            \Centail[C, \SingletonTrue \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1]{\tau_2 \leq_{\Ref\Exn} \tau} \label{e-iftrue-10}
        \end{gather}
    Applying the \emph{modus ponens} rules on (\ref{e-iftrue-9}) and (\ref{e-iftrue-10}) gives us
        \begin{gather}
            \Centail{\tau_2 \leq_{\Ref\Exn} \tau} \label{e-iftrue-11}
        \end{gather}
    
    This concludes the proof, as (\ref{e-iftrue-2}) and (\ref{e-iftrue-11}) are what was asked for.
    
    \IndCase{E-IfFalse} As \CiteRule{E-IfTrue}.
    
    \IndCase{E-IfExn1} We need to show that if \[\Judge{\IfThenElse{\Crash{\ell_1}}{e_2}{e_3}}{\tau}\] and \[\Reduce{\IfThenElse{\Crash{\ell_1}}{e_2}{e_3}}{\IfThenElse{\Crash{\ell_1}}{e_2'}{e_3}}\] then \[\Judge{\IfThenElse{\Crash{\ell_1}}{e_2'}{e_3}}{\tau'}\] with \[\Centail{\tau' \leq_{\Ref\Exn} \tau}.\]
    
    The induction hypothesis states that if $\Judge{e_2}{\tau_2}$ and $\Reduce{e_2}{e_2'}$ then $\Judge{e_2'}{\tau_2'}$ with $\Centail{\tau_2' \leq_{\Ref\Exn} \tau_2}$.

    Applying the inversion lemma to $\Judge{\IfThenElse{\Crash{\ell_1}}{e_2}{e_3}}{\tau}$ reveals it can only have been constructed by \CiteRule{T-If}, giving us:
        \begin{gather}
            \Judge{\Crash{\ell_1}}{\alpha_1} \label{e-ifexn1-1} \\
            \Judge{e_2}{\tau_2} \label{e-ifexn1-2} \\
            \Judge{e_3}{\tau_3} \label{e-ifexn1-3} \\
            \Centail{\SingletonTrue \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1 \Rightarrow \tau_2 \leq_{\Ref\Exn} \tau} \label{e-ifexn1-4} \\
            \Centail{\SingletonFalse \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1 \Rightarrow \tau_3 \leq_{\Ref\Exn} \tau} \label{e-ifexn1-5} \\
            \Centail{\alpha_1 \sqsubseteq_\Exn \TopLevel{\tau}} \label{e-ifexn1-6}
        \end{gather}
        
    We can now apply the induction hypothesis, giving us:
        \begin{gather}
            \Judge{e_2'}{\tau_2'} \label{e-ifexn1-7} \\
            \Centail{\tau_2' \leq_{\Ref\Exn} \tau_2} \label{e-ifexn1-8}
        \end{gather}

    By applying \CiteRule{T-If} with $\alpha_1 \mapsto \alpha_1$, $\tau_2 \mapsto \tau_2'$, $\tau_3 \mapsto \tau_3$, $e_1 \mapsto \Crash{\ell_1}$, $e_2 \mapsto e_2'$ and $e_3 \mapsto e_3$ we find that
        \begin{gather}
            \Judge{\IfThenElse{\Crash{\ell_1}}{e_2'}{e_3}}{\tau} \label{e-ifexn1-9}
        \end{gather}
    
    We still need to check that the preconditions on \CiteRule{T-If} hold:
        \begin{enumerate}
            \item Using weakening on (\ref{e-ifexn1-8}) we get
                    \begin{gather}
                        \Centail[C, \SingletonTrue \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1]{\tau_2' \leq_{\Ref\Exn} \tau_2} \label{e-ifexn1-10}
                    \end{gather}
                Using implication elimination on (\ref{e-ifexn1-4}) we get
                    \begin{gather}
                        \Centail[C, \SingletonTrue \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1]{\tau_2 \leq_{\Ref\Exn} \tau} \label{e-ifexn1-11}
                    \end{gather}
                Using the transitivity of the subtype relation on (\ref{e-ifexn1-10}) and (\ref{e-ifexn1-11}) we get
                    \begin{gather}
                        \Centail[C, \SingletonTrue \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1]{\tau_2' \leq_{\Ref\Exn} \tau} \label{e-ifexn1-12}
                    \end{gather}
                Using implication introduction on (\ref{e-ifexn1-12}) get
                    \begin{gather}
                        \Centail{\SingletonTrue \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1 \Rightarrow \tau_2' \leq_{\Ref\Exn} \tau} \label{e-ifexn1-13}
                    \end{gather}
        \end{enumerate}
    The other five preconditions follow directly from (\ref{e-ifexn1-1}), (\ref{e-ifexn1-3}), (\ref{e-ifexn1-5}), (\ref{e-ifexn1-6}) and (\ref{e-ifexn1-7}). This---together with the reflexivity of the subtype relation giving us $\Centail{\tau \leq_{\Ref\Exn} \tau}$---concludes the proof.
    
    \IndCase{E-IfExn2} As \CiteRule{E-IfExn1}.
    
    \IndCase{E-IfExn3} We need to show that if \[\Judge{\IfThenElse{\Crash{\ell_1}}{v_2^{\ell_2}}{v_3^{\ell_3}}}{\tau}\] and \[\Reduce{\IfThenElse{\Crash{\ell_1}}{v_2^{\ell_2}}{v_3^{\ell_3}}}{\Crash{\ell_1 \sqcup \ell_2 \sqcup \ell_3}}\] then \[\Judge{\Crash{\ell_1 \sqcup \ell_2 \sqcup \ell_3}}{\tau}\] with \[\Centail{\tau \leq_{\Ref\Exn} \tau}.\]
    
    Applying the inversion lemma to $\Judge{\IfThenElse{\Crash{\ell_1}}{v_2^{\ell_2}}{v_3^{\ell_3}}}{\tau}$ reveals it can only have been constructed by \CiteRule{T-If}, thus we have:
        \begin{gather}
            \Judge{\Crash{\ell_1}}{\alpha_1} \label{e-ifexn3-1} \\
            \Judge{v_2^{\ell_2}}{\tau_2} \label{e-ifexn3-2} \\
            \Judge{v_3^{\ell_3}}{\tau_3} \label{e-ifexn3-3} \\
            \Centail{\SingletonTrue \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1 \Rightarrow \tau_2 \leq_{\Ref\Exn} \tau} \label{e-ifexn3-4} \\
            \Centail{\SingletonFalse \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1 \Rightarrow \tau_3 \leq_{\Ref\Exn} \tau} \label{e-ifexn3-5} \\
            \Centail{\alpha_1 \sqsubseteq_\Exn \TopLevel{\tau}} \label{e-ifexn3-6}
        \end{gather}

    We construct a new exceptional value $\Judge{\Crash{\ell_1 \sqcup \ell_2 \sqcup \ell_3}}{\tau}$ using \CiteRule{T-Exn}. This gives us the precondition
        \begin{gather}
            \ell_1 \sqcup \ell_2 \sqcup \ell_3 \sqsubseteq_\Exn \alpha_1
        \end{gather}
    that we need to check it satisfied. It can be decomposed into
        \begin{gather}
            \Centail{\ell_1 \sqsubseteq_\Exn \alpha_1} \label{e-ifexn3-8} \\
            \Centail{\ell_2 \sqsubseteq_\Exn \alpha_1} \label{e-ifexn3-9} \\
            \Centail{\ell_3 \sqsubseteq_\Exn \alpha_1} \label{e-ifexn3-10}
        \end{gather}
        \begin{enumerate}
            \item (\ref{e-ifexn3-8}) follows from applying the inversion lemma to (\ref{e-ifexn3-1}).
            \item (\ref{e-ifexn3-9}) follows from case inspection on $v_2^{\ell_2}$: either $v_2^{\ell_2}$ is an exceptional value and must thus have been constructed by \CiteRule{T-Exn}, from which the requested constraint follows immediately by inversion of (\ref{e-ifexn3-2}); or $v_2^{\ell_2}$ is a non-exceptional value and we took $\ell_2 = \emptyset$, which simplifies (\ref{e-ifexn3-9}) to the trivially satisfied $\Centail{\emptyset \sqsubseteq_\Exn \alpha_1}$.
            \item The reasoning for (\ref{e-ifexn3-10}) if analogous to (\ref{e-ifexn3-9}).
        \end{enumerate}

    We conclude the proof by noting that $\Centail{\tau \leq_{\Ref\Exn} \tau}$ follows from the reflexivity of the subtype relation.

    \IndCase{E-Op1} We need to show that if $\Judge{\Op{e_1}{e_2}}{\alpha}$ and $\Reduce{\Op{e_1}{e_2}}{\Op{e_1'}{e_2}}$ then $\Judge{\Op{e_1'}{e_2}}{\alpha'}$ with $\Centail{\alpha' \sqsubseteq_{\Ref\Exn} \alpha}$.
    The induction hypothesis states that if $\Judge{e_1}{\alpha_1}$ and $\Reduce{e_1}{e_1'}$ then
        \begin{gather}
            \Judge{e_1'}{\alpha_1'} \label{e-op1-6} \\
            \Centail{\alpha_1' \sqsubseteq_{\Ref\Exn} \alpha_1}.  \label{e-op1-7}
        \end{gather}
    Applying the inversion lemma to $\Judge{\Op{e_1}{e_2}}{\alpha_1}$ can only have been constructed by \CiteRule{T-Op}, thus we have
        \begin{gather}
            \Judge{e_1}{\alpha_1} \label{e-op1-1} \\
            \Judge{e_2}{\alpha_2} \label{e-op1-2} \\
            \Centail{\alpha_1 \sqsubseteq_\Exn \alpha} \label{e-op1-3} \\
            \Centail{\alpha_2 \sqsubseteq_\Exn \alpha} \label{e-op1-4} \\
            \Centail{\omega_\oplus(\alpha_1, \alpha_2, \alpha)} \label{e-op1-5}
        \end{gather}
    Applying \CiteRule{T-Op} with $e_1 \mapsto e_1'$, $e_2 \mapsto e_2$, $\alpha_1 \mapsto \alpha_1'$, $\alpha_2 \mapsto \alpha_2$ and $\alpha \mapsto \alpha$ we find that \[ \Judge{\Op{e_1'}{e_2}}{\alpha}. \]
    We still need to check that the preconditions of \CiteRule{T-Op} hold:
        \begin{enumerate}
            \item $\Centail{\alpha_1' \sqsubseteq_{\Exn} \alpha}$ follows from (\ref{e-op1-3}), (\ref{e-op1-7}) and the transitivity of the subtype relation.
            \item $\Centail{\omega_\oplus(\alpha_1',\alpha_2,\alpha)}$ follows from (\ref{e-op1-7}) and the monotonicity of the operator constraint set $\omega_\oplus$ (Definition~\ref{operator-monotonicity}).
        \end{enumerate}
    The other three preconditions follow directly from assumptions (\ref{e-op1-6}), (\ref{e-op1-2}) and (\ref{e-op1-4}), respectively.
    
    To conclude the proof, we need to show that $\Centail{\alpha \sqsubseteq_{\Ref\Exn} \alpha}$, which holds by the the reflexivity of the subtype relation.

    \IndCase{E-Op2} As \CiteRule{E-Op1}.
    
    \IndCase{E-OpNum} We need to show that if $\Judge{\Op{n_1}{n_2}}{\alpha}$ and $\Reduce{\Op{n_1}{n_2}}{\InterpretOp{n_1\oplus n_2}}$ then $\Judge{\InterpretOp{n_1 \oplus n_2}}{\alpha'}$ with $\Centail{\alpha' \leq_{\Ref\Exn} \alpha}$.
    Applying the inversion lemma to $\Judge{\Op{n_1}{n_2}}{\alpha}$ can only have been constructed by \CiteRule{T-Op}, thus we have
        \begin{gather}
            \Judge{n_1}{\alpha_1} \\
            \Judge{n_2}{\alpha_2} \\
            \Centail{\alpha_1 \sqsubseteq_\Exn \alpha} \\
            \Centail{\alpha_2 \sqsubseteq_\Exn \alpha} \\
            \Centail{\omega_\oplus(\alpha_1, \alpha_2, \alpha)} \label{e-opnum-5}
        \end{gather}
    From the consistency (Definition~\ref{operator-consistency}) of the operator constraint set $\omega_\oplus$ and assumption (\ref{e-opnum-5}) we conclude that
        \begin{gather}
            \Judge{\InterpretOp{n_1 \oplus n_2}}{\alpha'} \\
            \Centail{\alpha' \leq_{\Ref\Exn} \alpha}
        \end{gather}
    This finishes the proof.
    
    \IndCase{E-OpExn1} We need to show that if $\Judge{\Op{\Crash{\ell_1}}{n_2}}{\alpha}$ and $\Reduce{\Op{\Crash{\ell_1}}{n_2}}{\Crash{\ell_1}}$ then $\Judge{\Crash{\ell_1}}{\alpha'}$ with $\Centail{\alpha' \leq_{\Ref\Exn} \alpha}$.
    
    Applying the inversion lemma to $\Judge{\Op{\Crash{\ell_1}}{n_2}}{\alpha}$ reveals it can only have been constructed by \CiteRule{T-Op}, thus we have
        \begin{gather}
            \Judge{\Crash{\ell_1}}{\alpha_1} \label{e-opexn1-1} \\
            \Judge{n_2}{\alpha_2} \\
            \Centail{\alpha_1 \sqsubseteq_\Exn \alpha} \label{e-opexn1-3} \\
            \Centail{\alpha_2 \sqsubseteq_\Exn \alpha} \\
            \Centail{\omega_\oplus(\alpha_1, \alpha_2, \alpha)}
        \end{gather}
    Applying the inversion lemma to (\ref{e-opexn1-1}) reveals it can only have been constructed by \CiteRule{T-Exn}, giving us
        \begin{gather}
             \Centail{\ell_1 \sqsubseteq_\Exn \alpha_1} \label{e-opexn1-6}
        \end{gather}
    Applying \CiteRule{T-Exn} with $\ell \mapsto \ell_1$ and $\tau \mapsto \alpha$, noting that its precondition is fulfilled by transitively combining (\ref{e-opexn1-6}) with (\ref{e-opexn1-3}), we find that
        \begin{gather}
            \Judge{\Crash{\ell_1}}{\alpha}
        \end{gather}
    To conclude the proof we note that $\Centail{\alpha \leq_{\Ref\Exn} \alpha}$ follows from the transitivity of the subtype relation.
    
    \IndCase{E-OpExn2} As \CiteRule{E-OpExn1}.
    
    \IndCase{E-OpExn3} We need to show that if $\Judge{\Op{\Crash{\ell_1}}{\Crash{\ell_2}}}{\alpha}$ and $\Reduce{\Op{\Crash{\ell_1}}{\Crash{\ell_2}}}{\Crash{\ell_1 \sqcup \ell_2}}$ then $\Judge{\Crash{\ell_1 \sqcup \ell_2}}{\alpha'}$ with $\Centail{\alpha' \sqsubseteq_{\Ref\Exn} \alpha}$.

    Applying the inversion lemma to $\Judge{\Op{\Crash{\ell_1}}{\Crash{\ell_2}}}{\alpha}$ reveals it can only have been constructed by \CiteRule{T-Op}, thus we have
        \begin{gather}
            \Judge{\Crash{\ell_1}}{\alpha_1} \label{e-opexn3-1} \\
            \Judge{\Crash{\ell_2}}{\alpha_2} \label{e-opexn3-2} \\
            \Centail{\alpha_1 \sqsubseteq_\Exn \alpha} \label{e-opexn3-3} \\
            \Centail{\alpha_2 \sqsubseteq_\Exn \alpha} \label{e-opexn3-4} \\
            \Centail{\omega_\oplus(\alpha_1, \alpha_2, \alpha)}
        \end{gather}
    The inversion lemma shows that the last derivation rule used to construct both (\ref{e-opexn3-1}) and (\ref{e-opexn3-2}) can only have been \CiteRule{T-Exn}, giving us
        \begin{gather}
            \Centail{\ell_1 \sqsubseteq_\Exn \TopLevel{\alpha_1}} \label{e-opexn3-6}\\
            \Centail{\ell_2 \sqsubseteq_\Exn \TopLevel{\alpha_2}} \label{e-opexn3-7}
        \end{gather}
    Transitively combining (\ref{e-opexn3-3}) with (\ref{e-opexn3-6}) and (\ref{e-opexn3-4}) with (\ref{e-opexn3-7}), we find
        \begin{gather}
            \Centail{\ell_1 \sqcup \ell_2 \sqsubseteq_\Exn \alpha} \label{e-opexn3-8}
        \end{gather}
    Finally, we construct $\Judge{\Crash{\ell_1 \sqcup \ell_2}}{\alpha}$ by \CiteRule{T-Exn} using (\ref{e-opexn3-8}) to fulfil its precondition and conclude by noting that $\Centail{\alpha \sqsubseteq_{\Ref\Exn} \alpha}$ follows from the reflexivity of the subtype relation.

    \IndCase{E-Pair} Apply \CiteRule{T-Close} (and note that the subtype relation is reflexive.)
    
    \IndCase{E-Cons} Apply \CiteRule{T-Close} (and note that the subtype relation is reflexive.)
    
    \IndCase{E-Fst} We need to show that if
        \begin{gather*}
            \Judge{\Fst{e}}{\tau} \\
            \EC{\Gamma}{\rho}
        \end{gather*}
    and \[\Reduce{\Fst{e}}{\Fst{e'}}\] then \[\Judge{\Fst{e'}}{\tau'}\] with \[\Centail{\tau' \leq_{\Ref\Exn} \tau}.\]

    The induction hypothesis states that if
        \begin{gather*}
            \Judge{e}{\TyPair{\tau_{1}}{\tau_{2}}{\alpha}} \\
            \EC{\Gamma}{\rho}
        \end{gather*}
    and
        \begin{gather*}
            \Reduce{e}{e'}
        \end{gather*}
    then
        \begin{gather}
            \Judge{e'}{\TyPair{\tau_{1}'}{\tau_{2}'}{\alpha'}} \label{e-if17}
        \end{gather}
    with $\Centail{\TyPair{\tau_{1}'}{\tau_{2}'}{\alpha'} \leq_{\Ref\Exn} \TyPair{\tau_{1}}{\tau_{2}}{\alpha}}$, which---by inversion of the subtyping  relation---entails:
        \begin{gather}
            \Centail{\tau_{1}' \leq_{\Ref\Exn} \tau_{1}} \label{e-if18} \\
            \Centail{\tau_{2}' \leq_{\Ref\Exn} \tau_{2}} \label{e-if19} \\
            \Centail{\alpha' \sqsubseteq_{\Ref\Exn} \alpha} \label{e-if20}
        \end{gather}
    Applying the inversion lemma to $\Judge{\Fst{e}}{\tau_1}$ reveals it can only have been constructed by \CiteRule{T-Fst}, thus we have
        \begin{gather}
            \Judge{e}{\TyPair{\tau_{1}}{\tau_{2}}{\alpha}} \label{e-if17} \\
            \Centail{\tau_1 \leq_{\Ref\Exn} \tau} \label{e-ifstuff} \\
            \Centail{\alpha \sqsubseteq_\Exn \TopLevel{\tau}} \label{e-if22}
        \end{gather}
    We can now apply the induction hypothesis. By applying \CiteRule{T-Fst} with $e \mapsto e'$, $\tau \mapsto \tau$, $\tau_1 \mapsto \tau_1'$, $\tau_2 \mapsto \tau_{2}'$ and $\alpha \mapsto \alpha'$ we find that \[ \Judge{\Fst{e'}}{\tau}. \]
    We still need to check that the preconditions on \CiteRule{T-Fst} hold:
        \begin{enumerate}
            \item $\Judge{e'}{\TyPair{\tau_{1}'}{\tau_{2}'}{\alpha'}}$ follows from (\ref{e-if-4}).
            \item $\Centail{\tau_1' \leq_{\Ref\Exn} \tau}$ follows from (\ref{e-if18}), (\ref{e-ifstuff}) and the transitivity of the subtype relation.
            \item $\Centail{\alpha' \sqsubseteq_\Exn \TopLevel{\tau}}$ follows from (\ref{e-if20}), (\ref{e-if22}) and the transitivity of the subeffect relation.
        \end{enumerate}
    
    \IndCase{E-FstPair} The last three inference rules used in the derivation of $\Judge{\Fst{\left(\Close{\Pair{e_1}{e_2}}{\rho_1}}\right)}{\tau_1}$ must have been \CiteRule{T-Fst}, \CiteRule{T-Close} and \CiteRule{T-Pair}. By inversion we find that:
        \begin{gather}
            \Judge[C;\Delta]{e_1}{\tau_1} \label{e-fstpair-6} \\
            \Judge[C;\Delta]{e_2}{\tau_2} \\
            \Centail{\tau_1 \leq_{\Ref\Exn} \tau} \label{e-fstpair-2} \\
            \Centail{\alpha \sqsubseteq_\Exn \TopLevel{\tau}} \\
            \EC{\Delta}{\rho_1} \label{e-fstpair-5}
        \end{gather}
    Applying \CiteRule{T-Bind} with $e \mapsto e_1$, $\sigma \mapsto \tau_1$ and $\rho \mapsto \rho_1$ gives us $\Judge{\Bind{\rho_1}{e_1}}{\tau_1}$, with its preconditions following from (\ref{e-fstpair-5}) and (\ref{e-fstpair-6}) $\Centail{\tau_1 \leq_{\Ref\Exn} \tau}$ follows from (\ref{e-fstpair-2}).
    
    \IndCase{E-FstExn} The last two inference rules used in the derivation of $\Judge{\Fst{\Crash{\ell}}}{\tau_1}$ must have been \CiteRule{T-Fst} and \CiteRule{T-Exn}. By inversion be find that:
        \begin{gather}
            \Judge{\Crash{\ell}}{\TyPair{\tau_1}{\tau_2}{\alpha}} \\
            \Centail{\tau_1 \leq_{\Ref\Exn} \tau} \\
            \Centail{\alpha \sqsubseteq_\Exn \TopLevel{\tau}} \label{e-fstexn27} \\
            \Centail{\ell \sqsubseteq_\Exn \TopLevel{\TyPair{\tau_1}{\tau_2}{\alpha}}} \label{e-fstexn28}
        \end{gather}
    We can simplify (\ref{e-fstexn28}) to $\Centail{\ell \sqsubseteq_\Exn \alpha}$ and transitively combine it with (\ref{e-fstexn27}) to obtain:
        \begin{gather}
            \Centail{\ell \sqsubseteq_\Exn \TopLevel{\tau}} \label{e-fstexn29}
        \end{gather}
    We finish the proof by applying \CiteRule{T-Exn} with $\tau \mapsto \tau$, noting that its precondition is satisfied by (\ref{e-fstexn29}) and $\Centail{\tau \leq_{\Ref\Exn} \tau}$ follows from the reflexivity of the subtype relation.

    \IndCase{E-Snd} As \CiteRule{E-Fst}.
    
    \IndCase{E-SndPair} As \CiteRule{E-FstPair}.
    
    \IndCase{E-SndExn} As \CiteRule{E-FstExn}.
    
    \IndCase{E-Case} We need to show that if
        \begin{gather}
            \Judge{\Case{e_1}{e_2}{x_1}{x_2}{e_3}}{\tau} \label{e-case-thm1} \\
            \EC{\Gamma}{\rho} \label{e-case-thm2}
        \end{gather}
    and
        \begin{multline}
            \Reduce{\Case{e_1}{e_2}{x_1}{x_2}{e_3}\\}{\Case{e_1'}{e_2}{x_1}{x_2}{e_3}} \label{e-case-thm3}
        \end{multline}
    then
        \begin{gather}
            \Judge{\Case{e_1'}{e_2}{x_1}{x_2}{e_3}}{\tau'} \label{e-case-thm4}
        \end{gather}
    with
        \begin{gather}
            \Centail{\tau' \leq_{\Ref\Exn} \tau}. \label{e-case-thm5}
        \end{gather}
    
    The induction hypothesis states that if $\Judge{e_1}{\TyList{\tau_1}{\alpha_1}}$, $\EC{\Gamma}{\rho}$ and $\Reduce{e_1}{e_1'}$ then $\Judge{e_1'}{\TyList{\tau_1'}{\alpha_1'}}$ with $\Centail{\TyList{\tau_1'}{\alpha_1'} \leq_{\Ref\Exn} \TyList{\tau_1}{\alpha_1}}$.
    
    Applying the inversion lemma to (\ref{e-case-thm1}) reveals that it can only have been constructed by \CiteRule{T-Case}, thus we have:
        \begin{gather}
            \Judge{e_1}{\TyList{\tau_1}{\alpha_1}} \label{e-case-1} \\
            \Judge{e_2}{\tau_2} \label{e-case-2} \\
            \Judge[C;\Gamma,x_1:\tau_1,x_2:\TyList{\tau_1}{\beta}]{e_3}{\tau_3} \label{e-case-3} \\
            \Centail{\SingletonNil \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1 \Rightarrow \tau_2 \leq_{\Ref\Exn} \tau} \label{e-case-4} \\
            \Centail{\SingletonCons \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1 \Rightarrow \tau_3 \leq_{\Ref\Exn} \tau} \label{e-case-5} \\
            \Centail{\alpha_1 \sqsubseteq_\Exn \TopLevel{\tau}} \label{e-case-6} \\
            \Centail{\SingletonNil \sqcup \SingletonCons \sqsubseteq_\Ref \beta} \label{e-case-7} \\
            \Centail{\alpha_1 \sqsubseteq_\Exn \beta} \label{e-case-8}
        \end{gather}
        
    We can now apply the induction hypothesis, giving us
        \begin{gather}
            \Judge{e_1'}{\TyList{\tau_1'}{\alpha_1'}} \label{e-case-9} \\
            \Centail{\TyList{\tau_1'}{\alpha_1'} \leq_{\Ref\Exn} \TyList{\tau_1}{\alpha_1}} \label{e-case-10}
        \end{gather}
    
    We construct the desired result using \CiteRule{T-Case} with $e_1 \mapsto e_1'$ and verify that all the premises hold:
        \begin{enumerate}
            \item Invoking \CiteRule{T-Sub} using (\ref{e-case-9}) and (\ref{e-case-10}) gives us \[\Judge{e_1'}{\TyList{\tau_1}{\alpha_1}}.\]
        \end{enumerate}
    All other cases follow immediately from (\ref{e-case-2})--(\ref{e-case-8}).
    
    \IndCase{E-CaseNil} We need to show that if
        \begin{gather}
            \Judge{\Case{\LNil}{e_2}{x_1}{x_2}{e_3}}{\tau} \label{e-casenil-0}
        \end{gather}
    and $\Reduce{\Case{\LNil}{e_2}{x_1}{x_2}{e_3}}{e_2}$ then $\Judge{e_2}{\tau'}$ with $\Centail{\tau' \leq_{\Ref\Exn} \tau}$.
    
    Applying the inversion lemma to (\ref{e-casenil-0}) reveals it can only have been constructed by \CiteRule{T-Case}, thus we have
        \begin{gather}
            \Judge{\LNil}{\TyList{\tau_1}{\alpha_1}} \label{e-casenil-1} \\
            \Judge{e_2}{\tau_2} \\
            \Judge[C; \Gamma, x_1 : \tau_1, x_2 : \TyList{\tau_1}{\beta}]{e_3}{\tau_3} \label{e-casenil-2} \\
            \Centail{\SingletonNil \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \Rightarrow \alpha_1 \tau_2 \leq_{\Ref\Exn} \tau} \label{e-casenil-3} \\
            \Centail{\SingletonCons \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \Rightarrow \alpha_1 \tau_3 \leq_{\Ref\Exn} \tau} \label{e-casenil-4} \\
            \Centail{\alpha_1 \sqsubseteq_\Exn \TopLevel{\tau}} \label{e-casenil-5} \\
            \Centail{\SingletonNil \sqcup \SingletonCons \sqsubseteq_\Ref \beta} \label{e-casenil-6} \\
            \Centail{\alpha_1 \sqsubseteq_\Exn \beta} \label{e-casenil-7}
        \end{gather}

    Applying the inversion lemma to (\ref{e-casenil-1}) reveals it can only have been constructed by \CiteRule{T-Nil}, giving us:
        \begin{gather}
            \Centail{\SingletonNil \sqsubseteq_\Ref \alpha_1} \label{e-casenil-9}
        \end{gather}
    Using $\lor$-introduction on (\ref{e-casenil-9}) gives us
        \begin{gather}
            \Centail{\SingletonNil \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1} \label{e-casenil-10}
        \end{gather}
    Using implication elimination on (\ref{e-casenil-3}) gives us
        \begin{gather}
            \Centail[C, \SingletonNil \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1]{\tau_2 \leq_{\Ref\Exn} \tau} \label{e-casenil-11}
        \end{gather}
    Using \emph{modus ponens} on (\ref{e-casenil-10}) and (\ref{e-casenil-11}) gives us
        \begin{gather}
            \Centail{\tau_2 \leq_{\Ref\Exn} \tau}
        \end{gather}
    which---together with (\ref{e-casenil-2})---concludes the proof.
    
    \IndCase{E-CaseCons} We need to show that if
        \begin{multline}
            C;\Gamma\vdash\CaseBREAK{\left(\Close{\LCons{e_1}{e_1'}}{\rho_1}\right)}{e_2}{x_1}{x_2}{e_3}:\tau \label{e-casecons-thm1}
        \end{multline}
        \begin{gather}
            \EC{\Gamma}{\rho}
        \end{gather}
    and
        \begin{multline*}
            \Reduce{\Case{\left(\Close{\LCons{e_1}{e_1'}}{\rho_1}\right)}{e_2}{x_1}{x_2}{e_3}\\}{\Bind{\left(\rho, x_1 : \Bind{\rho_1}{e_1}, x_2 : \Bind{\rho_1}{e_1'} \right)}{e_3}}
        \end{multline*}
    then
        \begin{gather*}
            \Judge{\Bind{\left(\rho, x_1 : \Bind{\rho_1}{e_1}, x_2 : \Bind{\rho_1}{e_1'} \right)}{e_3}}{\tau'}
        \end{gather*}
    with
        \begin{gather*}
            \Centail{\tau' \leq_{\Ref\Exn} \tau}.
        \end{gather*}
    
    Applying the inversion lemma to (\ref{e-casecons-thm1}) reveals that the last inference rule used in its derivation can only have been \CiteRule{T-Case}, giving us:
        \begin{gather}
            \Judge{\Close{\LCons{e_1}{e_1'}}{\rho_1}}{\TyList{\tau_1}{\beta}} \label{e-casecons-1} \\
            \Judge{e_2}{\tau_2} \label{e-casecons-2} \\
            \Judge[C;\Gamma,x_1:\tau_1,x_2:\TyList{\tau_1}{\beta}]{e_3}{\tau_3} \label{e-casecons-3} \\
            \Centail{\SingletonNil \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1 \Rightarrow \tau_2 \leq_{\Ref\Exn} \tau} \label{e-casecons-4} \\
            \Centail{\SingletonCons \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1 \Rightarrow \tau_3 \leq_{\Ref\Exn} \tau} \label{e-casecons-5} \\
            \Centail{\alpha_1 \sqsubseteq_\Exn \TopLevel{\tau}} \label{e-casecons-6} \\
            \Centail{\SingletonNil \sqcup \SingletonCons \sqsubseteq_\Ref \beta} \label{e-casecons-7} \\
            \Centail{\alpha_1 \sqsubseteq_\Exn \beta} \label{e-casecons-8}
        \end{gather}
    
    Applying the inversion lemma to (\ref{e-casecons-1}) reveals that the last inference rule used in its derivation can only have been \CiteRule{T-Close}, giving us:
        \begin{gather}
            \Judge[C;\Delta]{\LCons{e_1}{e_1'}}{\TyList{\tau_1}{\alpha_1}} \label{e-casecons-9} \\
            \EC{\Delta}{\rho_1} \label{e-casecons-10}
        \end{gather}
    
    Applying the inversion lemma to (\ref{e-casecons-9}) reveals that the last inference rules used in its derivation can only have been \CiteRule{T-Cons}, giving us:
        \begin{gather}
            \Judge[C;\Delta]{e_1}{\tau_{11}} \label{e-casecons-11} \\
            \Judge[C;\Delta]{e_1'}{\TyList{\tau_{12}}{\alpha_{12}}} \label{e-casecons-12} \\
            \Centail{\tau_{11} \leq_{\Ref\Exn} \tau_1} \label{e-casecons-13} \\
            \Centail{\tau_{12} \leq_{\Ref\Exn} \tau_1} \label{e-casecons-14} \\
            \Centail{\SingletonCons \sqsubseteq_\Ref \alpha_1} \label{e-casecons-15} \\
            \Centail{\alpha_{12} \sqsubseteq_\Exn \alpha_1} \label{e-casecons-16}
        \end{gather}
    
    We construct the desired result using \CiteRule{T-Bind} with $e \mapsto e_3$; $\tau \mapsto \tau$; $\rho \mapsto \left(\rho, x_1 : \Bind{\rho_1}{e_1}, x_2 : \Bind{\rho_1}{e_1'}\right)$ and ${\Delta \mapsto \Gamma, x_1 : \tau_1, x_2 : \TyList{\tau_1}{\beta}}$. We still need to verify all the preconditions on \CiteRule{T-Bind} are satisfied:
        \begin{enumerate}
            \item Using $\lor$-introduction on (\ref{e-casecons-15}) gives us:
                \begin{gather}
                    \Centail{\SingletonCons \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1} \label{e-casecons-18}
                \end{gather} 
            Using implication elimination on (\ref{e-casecons-5}) gives us:
                \begin{gather}
                    \Centail[C, \SingletonCons \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1]{\tau_3 \leq_{\Ref\Exn} \tau} \label{e-casecons-19}
                \end{gather}
            Using \emph{modus ponens} on (\ref{e-casecons-18}) and (\ref{e-casecons-19}) gives us:
                \begin{gather}
                    \Centail{\tau_3 \leq_{\Ref\Exn} \tau} \label{e-casecons-20}
                \end{gather}
            Applying \CiteRule{T-Sub} to (\ref{e-casecons-3}) and (\ref{e-casecons-20}) gives us the first premise: \[ \Judge[C;\Gamma,x_1:\tau_1,x_2:\TyList{\tau_1}{\beta}]{e_3}{\tau}. \]
            \item The premise
                \begin{multline}
                    C \vdash \Gamma, x_1 : \tau_1, x_2 : \TyList{\tau_1}{\beta} \\ \bowtie \rho, x_1 : \Bind{\rho_1}{e_1}, x_2 : \Bind{\rho_1}{e_1'}
                \end{multline}
            can be constructed by applying \CiteRule{EC-Extend} twice. We verify that their preconditions hold:
                \begin{enumerate}
                    \item The premise $\EC{\Gamma}{\rho}$ is an assumption given by the theorem.
                    \item The premise $\Judge{\Bind{\rho_1}{e_1}}{\tau_1}$ can be constructed by \CiteRule{T-Bind} with $e \mapsto e_1$, $\rho \mapsto \rho_1$, $\tau \mapsto \tau_1$ and $\Delta \mapsto \Delta$. We need to check its preconditions:
                        \begin{enumerate}
                            \item The premise $\EC{\Delta}{\rho_1}$ is satisfied by (\ref{e-casecons-10}).
                            \item The premise $\Judge[C;\Delta]{e_1}{\tau_1}$ can be constructed by applying \CiteRule{T-Sub} to (\ref{e-casecons-11}) and (\ref{e-casecons-13}).
                        \end{enumerate}
                    \item The premise $\Judge{\Bind{\rho_1}{e_1'}}{\tau_1}$ can be constructed by \CiteRule{T-Bind} with $e \mapsto e_1'$, $\rho \mapsto \rho_1$, $\tau \mapsto \tau_1$ and $\Delta \mapsto \Delta$. We need to check its preconditions:
                        \begin{enumerate}
                            \item The premise $\EC{\Delta}{\rho_1}$ is satisfied by (\ref{e-casecons-10}).
                            \item From \CiteRule{CL-$\top$} we get
                                    \begin{gather}
                                        \alpha_{12} \sqsubseteq_\Ref \SingletonNil \sqcup \SingletonCons \label{e-casecons-20}
                                    \end{gather}
                                From (\ref{e-casecons-20}), (\ref{e-casecons-7}) and the reflexivity of the subeffecting relation it follows that
                                    \begin{gather}
                                        \alpha_{12} \sqsubseteq_\Ref \beta \label{e-casecons-21}
                                    \end{gather}
                                From (\ref{e-casecons-16}), (\ref{e-casecons-8}) and the transitivity of the subeffecting relation it follows that
                                    \begin{gather}
                                        \alpha_{12} \sqsubseteq_\Exn \beta \label{e-casecons-22}
                                    \end{gather}
                                We construct the desired premise $\Judge[\Delta]{e_1'}{\TyList{\tau_1}{\beta}}$ by applying \CiteRule{T-Sub} to (\ref{e-casecons-12}) using (\ref{e-casecons-14}), (\ref{e-casecons-21}) and (\ref{e-casecons-22}).
                        \end{enumerate}
                \end{enumerate}
        \end{enumerate}
        
    We conclude the proof by noting that $\Centail{\tau \leq_{\Ref\Exn} \tau}$ follows from the reflexivity of the subtype relation.
    
    \IndCase{E-CaseExn1} We need to show that if
        \begin{gather}
            \Judge{\Case{\Crash{\ell_1}}{e_2}{x_1}{x_2}{e_3}}{\tau} \label{e-caseexn1-0}
        \end{gather}
    and
        \begin{multline}
            \Reduce{\Case{\Crash{\ell_1}}{e_2}{x_1}{x_2}{e_3}\\}{\Case{\Crash{\ell_1}}{e_2'}{x_1}{x_2}{e_3}}
        \end{multline}
    then
        \begin{gather}
            \Judge{\Case{\Crash{\ell_1}}{e_2'}{x_1}{x_2}{e_3}}{\tau'}
        \end{gather}
    with
        \begin{gather}
            \Centail{\tau' \leq_{\Ref\Exn} \tau}.
        \end{gather}

    The induction hypothesis states that if $\Judge{e_2}{\tau_2}$ and $\Reduce{e_2}{e_2'}$ then $\Judge{e_2'}{\tau_2'}$ with $\Centail{\tau_2' \leq_{\Ref\Exn} \tau_2}$.

    Applying the inversion lemma to (\ref{e-caseexn1-0}) reveals it can only have been constructed by \CiteRule{T-Case}, thus we have
        \begin{gather}
            \Judge{\Crash{\ell_1}}{\TyList{\tau_1}{\alpha_1}} \label{e-caseexn1-1} \\
            \Judge{e_2}{\tau_2} \label{e-caseexn1-2} \\
            \Judge[C; \Gamma, x_1 : \tau_1, x_2 : \TyList{\tau_1}{\beta}]{e_3}{\tau_3} \label{e-caseexn1-3} \\
            \Centail{\SingletonNil \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1 \Rightarrow \tau_2 \leq_{\Ref\Exn} \tau} \label{e-caseexn1-4} \\
            \Centail{\SingletonCons \sqsubseteq_\Exn \alpha_1 \lor \exists_\Exn \alpha_1 \Rightarrow \tau_3 \leq_{\Ref\Exn} \tau} \label{e-caseexn1-5} \\
            \Centail{\alpha_1 \sqsubseteq_\Exn \TopLevel{\tau}} \label{e-caseexn1-6} \\
            \Centail{\SingletonNil \sqcup \SingletonCons \sqsubseteq_\Ref \beta} \label{e-caseexn1-7} \\
            \Centail{\alpha_1 \sqsubseteq_\Exn \beta} \label{e-caseexn1-8}
        \end{gather}

    We can now apply the induction hypothesis, giving us:
        \begin{gather}
            \Judge{e_2'}{\tau_2'} \label{e-caseexn1-9} \\
            \Centail{\tau_2' \leq_{\Ref\Exn} \tau_2} \label{e-caseexn1-10}
        \end{gather}
    
    Applying the inversion lemma to (\ref{e-caseexn1-1}) reveals it can only have been constructed by \CiteRule{T-Exn}, giving us:
        \begin{gather}
            \Centail{\ell_1 \sqsubseteq_\Exn \TopLevel{\TyList{\tau_1}{\alpha_1}}}
        \end{gather}
    which, by simplification of $\TopLevel{\ \cdot\ }$, equals
        \begin{gather}
            \Centail{\ell_1 \sqsubseteq_\Exn \alpha_1} \label{e-caseexn1-12}
        \end{gather}
    Using $\exists$-introduction on (\ref{e-caseexn1-12}) gives us
        \begin{gather}
            \Centail{\exists_\Exn \alpha_1} \label{e-caseexn1-13}
        \end{gather}
    Using $\lor$-introduction on (\ref{e-caseexn1-13}) gives us
        \begin{gather}
            \Centail{\SingletonNil \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1} \label{e-caseexn1-14}
        \end{gather}
    
    Applying \CiteRule{T-Case} with $e_1 \mapsto \Crash{\ell_1}$, $e_2 \mapsto e_2'$, $e_3 \mapsto e_3$, $x_1 \mapsto x_1$, $x_2 \mapsto x_2$, $\tau \mapsto \tau$, $\tau_1 \mapsto \tau_1$, $\tau_2 \mapsto \tau_2'$, $\tau_3 \mapsto \tau_3$, $\alpha_1 \mapsto \alpha_1$ and $\beta \mapsto \beta$ we find:
        \begin{gather}
            \Judge{\Case{\Crash{\ell_1}}{e_2'}{x_1}{x_2}{e_3}}{\tau} \label{e-caseexn1-15}
        \end{gather}
    
    We still need to check that the preconditions on \CiteRule{T-Case} hold:
        \begin{enumerate}
            \item Using implication elimination on (\ref{e-caseexn1-4}) gives us:
                \begin{gather}
                    \Centail[C, \SingletonNil \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1]{\tau_2 \leq_{\Ref\Exn} \tau} \label{e-caseexn1-16}
                \end{gather}
            Using \emph{modus ponens} on (\ref{e-caseexn1-14}) and (\ref{e-caseexn1-16}) gives us:
                \begin{gather}
                    \Centail{\tau_2 \leq_{\Ref\Exn} \tau} \label{e-caseexn1-17}
                \end{gather}
            From (\ref{e-caseexn1-10}), (\ref{e-caseexn1-17}) and the transitivity of the subtype relation it follows that:
                \begin{gather}
                    \Centail{\tau_2' \leq_{\Ref\Exn} \tau} \label{e-caseexn1-18}
                \end{gather}
            Using weakening and implication introduction on (\ref{e-caseexn1-18}) gives us:
                \begin{gather}
                    \Centail{\SingletonNil \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1 \Rightarrow \tau_2' \leq_{\Ref\Exn} \tau}
                \end{gather}
            which is what was asked for.
        \end{enumerate}
            
        The other seven preconditions follow immediately from (\ref{e-caseexn1-1}), (\ref{e-caseexn1-9}), (\ref{e-caseexn1-3}), (\ref{e-caseexn1-5}), (\ref{e-caseexn1-6}), (\ref{e-caseexn1-7}) and (\ref{e-caseexn1-8}).
        
        We conclude the proof using (\ref{e-caseexn1-15}) and noting that $\Centail{\tau \leq_{\Ref\Exn} \tau}$ follows from the reflexivity of the subtype relation.
    
    \IndCase{E-CaseExn2} We need to show that if
        \begin{gather}
            \Judge{\Case{\Crash{\ell_1}}{e_2}{x_1}{x_2}{e_3}}{\tau}, \label{e-caseexn2-thm1} \\
            \EC{\Gamma}{\rho} \label{e-caseexn2-thm2}
        \end{gather}
    and
       \begin{multline}
            \Reduce{\Case{\Crash{\ell_1}}{e_2}{x_1}{x_2}{e_3}\\}{\Case{\Crash{\ell_1}}{e_2}{x_1}{x_2}{e_3'}} \label{e-caseexn2-thm3}
        \end{multline}
    then
        \begin{gather}
            \Judge{\Case{\Crash{\ell_1}}{e_2}{x_1}{x_2}{e_3}}{\tau} \label{e-caseexn2-thm4}
        \end{gather}
    with
        \begin{gather}
            \Centail{\tau \leq_{\Ref\Exn} \tau}. \label{e-caseexn2-thm5}
        \end{gather}
    
    The induction hypothesis states that if
        \begin{gather}
            \Judge[C;\Gamma, x_1 : \tau_1, x_2 : \TyList{\tau_1}{\beta}]{e_3}{\tau_3}, \label{e-caseexn2-ih1} \\
            \EC{\Gamma, x_1 : \tau_1, x_2 : \tau_2}{\rho, x_1 : \Crash{\emptyset}, \label{e-caseexn2-ih2} x_2 : \Crash{\emptyset}}
        \end{gather}
    and
        \begin{gather}
            \Reduce[\rho, x_1 : \Crash{\emptyset}, x_3 : \Crash{\emptyset}]{e_3}{e_3'} \label{e-caseexn2-ih3}
        \end{gather}
    then
        \begin{gather}
            \Judge[C;\Gamma, x_1 : \tau_1, x_2 : \TyList{\tau_1}{\beta}]{e_3}{\tau_3'} \label{e-caseexn2-ih4}
        \end{gather}
    with
        \begin{gather}
            \Centail{\tau_3' \leq_{\Ref\Exn} \tau_3}. \label{e-caseexn2-ih5}
        \end{gather}
        
    Applying the inversion lemma to (\ref{e-caseexn2-thm1}) reveals that the last rule used to construct it can only have been \CiteRule{T-Case}, giving us:
        \begin{gather}
            \Judge{\Crash{\ell_1}}{\TyList{\tau_1}{\alpha_1}} \label{e-caseexn2-1} \\
            \Judge{e_2}{\tau_2} \label{e-caseexn2-2} \\
            \Judge[C;\Gamma,x_1 : \tau_1, x_2 : \TyList{\tau_1}{\beta}]{e_3}{\tau_3} \label{e-caseexn2-3} \\
            \Centail{\SingletonNil \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1 \Rightarrow \tau_2 \leq_{\Ref\Exn} \tau} \label{e-caseexn2-4} \\
            \Centail{\SingletonCons \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1 \Rightarrow \tau_3 \leq_{\Ref\Exn} \tau} \label{e-caseexn2-5} \\
            \Centail{\alpha_1 \sqsubseteq_\Exn \TopLevel{\tau}} \label{e-caseexn2-6} \\
            \Centail{\SingletonNil \sqcup \SingletonCons \sqsubseteq_\Ref \beta} \label{e-caseexn2-7} \\
            \Centail{\alpha_1 \sqsubseteq_\Exn \beta} \label{e-caseexn2-8}
        \end{gather}
    
    If we can show that
        \begin{gather}
            \Judge{\Crash{\emptyset}}{\tau_1} \label{e-caseexn2-10} \\
            \Judge[C;\Gamma,x_1:\tau_1]{\Crash{\emptyset}}{\TyList{\tau_1}{\beta}} \label{e-caseexn2-11}
        \end{gather}
    then we can apply \CiteRule{EC-Extend} twice to (\ref{e-caseexn2-thm2}) in order to get
        \begin{gather}
            \EC{\Gamma, x_1 : \tau_1, x_2 : \TyList{\tau_1}{\beta}}{\rho, x_1 : \Crash{\emptyset}, x_2 : \Crash{\emptyset}}. \label{e-caseexn2-9}
        \end{gather}
    Both (\ref{e-caseexn2-10}) and (\ref{e-caseexn2-11}) can be constructed using \CiteRule{T-Exn} as their premises $\Centail{\emptyset \sqsubseteq_\Exn \TopLevel{\tau_1}}$ and $\Centail{\emptyset \sqsubseteq_\Exn \beta}$ follow immediately from \CiteRule{CL-$\emptyset$}.
    
    We can now apply the induction hypothesis using (\ref{e-caseexn2-3}), (\ref{e-caseexn2-9}) and the premise on \CiteRule{E-CaseExn2}. We can construct (\ref{e-caseexn2-thm4}) using \CiteRule{T-Case} with $e_1 \mapsto \Crash{\ell_1}$, $e_3 \mapsto e_3'$ and $\tau_3 \mapsto \tau_3'$. We still need to show that its premises are satisfied, though:
        \begin{enumerate}
            \item Using weakening on (\ref{e-caseexn2-ih5}), we get
                \begin{gather}
                    \Centail[C, \SingletonCons \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1]{\tau_3' \leq_{\Ref\Exn} \tau_3}. \label{e-caseexn2-15}
                \end{gather}
            Using implication eliminiation on (\ref{e-caseexn2-5}), we get
                \begin{gather}
                    \Centail[C, \SingletonCons \sqsubseteq_\Ref \alpha_1 \lor \exists_\Ref \alpha_1]{\tau_3 \leq_{\Ref\Exn} \tau}. \label{e-caseexn2-16}
                \end{gather}
            From (\ref{e-caseexn2-15}), (\ref{e-caseexn2-16}) and the transitivity of the subtype relation it follows that
                \begin{gather}
                    \Centail[C, \SingletonCons \sqsubseteq_\Ref \alpha_1 \lor \exists_\Ref \alpha_1]{\tau_3 \leq_{\Ref\Exn} \tau}. \label{e-caseexn2-17}
                \end{gather}
            Using implication introduction on (\ref{e-caseexn2-17}), we obtain the premise
                \begin{gather*}
                    \Centail{\SingletonCons \sqsubseteq_\Ref \alpha_1 \lor \exists_\Ref \alpha_1 \Rightarrow \tau_3 \leq_{\Ref\Exn} \tau}.
                \end{gather*}
        \end{enumerate}
        The other seven premises follow directly from (\ref{e-caseexn2-ih4}), (\ref{e-caseexn2-1}), (\ref{e-caseexn2-2}), (\ref{e-caseexn2-4}), (\ref{e-caseexn2-6}), (\ref{e-caseexn2-7}) and (\ref{e-caseexn2-8}).
        
    Finally, we observe that (\ref{e-caseexn2-thm5}) follows from the reflexivity of the subtype relation, concluding the proof.
    
    \IndCase{E-CaseExn3} We need to show that if
        \begin{gather}
            \Judge{\Case{\Crash{\ell_1}}{v_2^{\ell_2}}{x_1}{x_2}{v_3^{\ell_3}}}{\tau} \label{e-caseexn3-0}
        \end{gather}
    and $\Reduce{\Case{\Crash{\ell_1}}{v_2^{\ell_2}}{x_1}{x_2}{v_3^{\ell_3}}}{\Crash{\ell_1 \sqcup \ell_2 \sqcup \ell_3}}$ then $\Judge{\Crash{\ell_1 \sqcup \ell_2 \sqcup \ell_3}}{\tau'}$ with $\Centail{\tau' \leq_{\Ref\Exn} \tau}$.
    
    Applying the inversion lemma to (\ref{e-caseexn3-0}) reveals that it can only have been constructed by \CiteRule{T-Case}, thus we have:
        \begin{gather}
            \Judge{\Crash{\ell_1}}{\TyList{\tau_1}{\alpha_1}} \label{e-caseexn3-1} \\
            \Judge{v_2^{\ell_2}}{\tau_2} \label{e-caseexn3-2} \\
            \Judge[C; \Gamma, x_1 : \tau_1, x_2 : \TyList{\tau_1}{\beta}]{v_3^{\ell_3}}{\tau_3} \label{e-caseexn3-3} \\
            \Centail{\SingletonNil \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1 \Rightarrow \tau_2 \leq_{\Ref\Exn} \tau} \label{e-caseexn3-4} \\
            \Centail{\SingletonCons \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1 \Rightarrow \tau_3 \leq_{\Ref\Exn} \tau} \label{e-caseexn3-5} \\
            \Centail{\alpha_1 \sqsubseteq_\Exn \TopLevel{\tau}} \label{e-caseexn3-6} \\
            \Centail{\SingletonNil \sqcup \SingletonCons \sqsubseteq_\Ref \beta} \label{e-caseexn3-7} \\
            \Centail{\alpha_1 \sqsubseteq_\Exn \beta} \label{e-caseexn3-8}
        \end{gather}

    Applying the inversion lemma to (\ref{e-caseexn3-1}) reveals it can only have been constructed by \CiteRule{T-Exn}, giving us:
        \begin{gather}
            \Centail{\ell_1 \sqsubseteq_\Exn \TopLevel{\TyList{\tau_1}{\alpha_1}}} \label{e-caseexn3-10}
        \end{gather}
    which, after simplification of $\TopLevel{\ \cdot\ }$, is equivalent to
        \begin{gather}
            \Centail{\ell_1 \sqsubseteq_\Exn \alpha_1}. \label{e-caseexn3-11}
        \end{gather}
    Using $\lor$-introduction on (\ref{e-caseexn3-11}) gives us:
        \begin{gather}
            \Centail{\SingletonNil \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1} \label{e-caseexn3-12} \\
            \Centail{\SingletonCons \sqsubseteq_\Ref \alpha_1 \lor \exists_\Exn \alpha_1} \label{e-caseexn3-13}
        \end{gather}
    Using implication elimination and \emph{modus ponens} on both (\ref{e-caseexn3-4}) and (\ref{e-caseexn3-12}), and, (\ref{e-caseexn3-5}) and (\ref{e-caseexn3-13}) gives us:
        \begin{gather}
            \Centail{\tau_2 \leq_{\Ref\Exn} \tau} \label{e-caseexn3-14} \\
            \Centail{\tau_3 \leq_{\Ref\Exn} \tau} \label{e-caseexn3-15}
        \end{gather}
    
    We construct---using \CiteRule{T-Exn}---an exceptional value
        \begin{gather}
            \Judge{\Crash{\ell_1 \sqcup \ell_2 \sqcup \ell_3}}{\tau}
        \end{gather}
    which needs as a precondition that
        \begin{gather}
            \Centail{\ell_1 \sqcup \ell_2 \sqcup \ell_3 \sqsubseteq_\Exn \TopLevel{\tau}}
        \end{gather}
    This precondition can be decomposed into
        \begin{gather}
            \Centail{\ell_1 \sqsubseteq_\Exn \TopLevel{\tau}} \label{e-caseexn3-18} \\
            \Centail{\ell_2 \sqsubseteq_\Exn \TopLevel{\tau}} \label{e-caseexn3-19} \\
            \Centail{\ell_3 \sqsubseteq_\Exn \TopLevel{\tau}} \label{e-caseexn3-20}
        \end{gather}
    \begin{enumerate}
        \item (\ref{e-caseexn3-18}) follows (\ref{e-caseexn3-10}), (\ref{e-caseexn3-6}) and the transitivity of the subtype relation.
        \item (\ref{e-caseexn3-19}) follows by case analysis on $v_2^{\ell_2}$: if $v_2^{\ell_2}$ is an exceptional value then the inversion lemma reveals (\ref{e-caseexn3-2}) must have been constructed by \CiteRule{T-Exn} and we have
            \begin{gather}
                \Centail{\ell_2 \sqsubseteq_\Exn \TopLevel{\tau_2}} \label{e-caseexn3-21}
            \end{gather}
        Applying Lemma~\ref{lemma-one} to (\ref{e-caseexn3-14}) we get:
            \begin{gather}
                \Centail{\TopLevel{\tau_2} \sqsubseteq_{\Ref\Exn} \TopLevel{\tau}} \label{e-caseexn3-22}
            \end{gather}
        Using the transitivity of the subtype relation on (\ref{e-caseexn3-21}) and (\ref{e-caseexn3-22}) gives us the result we were asked for.
        \item The reasoning for (\ref{e-caseexn3-20}) is analogous to (\ref{e-caseexn3-19}).
    \end{enumerate}
    
    \IndCase{E-Bind1} We need to show that if \[\Judge{\Bind{\rho_1}{e_1}}{\sigma_1}\] and \[\Reduce{\Bind{\rho_1}{e_1}}{\Bind{\rho_1}{e_1'}}\] then $\Judge{\Bind{\rho_1}{e_1'}}{\sigma_2}$ with $\Centail{\sigma_2 \leq_{\Ref\Exn} \sigma_1}$.
    The induction hypothesis states that if $\Judge{e_1}{\sigma_1}$ and $\Reduce{e_1}{e_1'}$ then $\Judge{e_1'}{\sigma_2}$ with $\Centail{\sigma_2 \leq_{\Ref\Exn} \sigma_1}$.
    Applying the inversion lemma to $\Judge{\Bind{\rho_1}{e_1}}{\sigma_1}$ reveals it can only have been constructed by \CiteRule{T-Bind}, thus we have
        \begin{gather}
            \Judge[C;\Delta]{e_1}{\sigma_1} \\
            \EC{\Delta}{\rho_1} \label{e-bind1-2}
        \end{gather}
    Applying the induction hypothesis we get
        \begin{gather}
            \Judge{e_1'}{\sigma_2} \label{e-bind1-3} \\
            \Centail{\sigma_2 \leq_{\Ref\Exn} \sigma_1}
        \end{gather}

    Applying \CiteRule{T-Bind} with $e_1 \mapsto e_1'$ and $\sigma_1 \mapsto \sigma_2$ we find that $\Judge{\Bind{\rho_1}{e_1'}}{\sigma_2}$ with $\Centail{\sigma_2 \leq_{\Ref\Exn} \sigma_1}$.
    The preconditions on \CiteRule{T-Bind} follow immediately from (\ref{e-bind1-3}) and (\ref{e-bind1-2}).

    \IndCase{E-Bind2} We need to show that if \[\Judge{\Bind{\rho_1}{v_1^{\ell_1}}}{\sigma_1}\] and $\Reduce{\Bind{\rho_1}{v_1^{\ell_1}}}{v_1^{\ell_1}}$ then $\Judge{v_1^{\ell_1}}{\sigma_2}$ with $\Centail{\sigma_2 \leq_{\Ref\Exn} \sigma_1}$.

    Applying the inversion lemma to $\Judge{\Bind{\rho_1}{v_1^{\ell_1}}}{\sigma_1}$ reveals it can only have been constructed by \CiteRule{T-Bind}, thus we have $\Judge{v_1^{\ell_1}}{\sigma_1}$, with $\Centail{\sigma_1 \leq_{\Ref\Exn} \sigma_1}$ following from the reflexivity of the subtype relation.
\end{proof}

%include algorithmproperties.lhs2tex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Extensions}

\subsection{seq}

\newcommand{\SEQ}[2]{#1\ \textbf{seq}\ #2}

\begin{figure}[!h]
    \paragraph{Syntax}
        \begin{gather*}
            e \quad ::= \quad ... \quad || \quad \SEQ{e_1}{e_2}
        \end{gather*}
    \paragraph{Evaluation relation}
        \begin{gather*}
            \Rule{E-Seq1}
                 {\Reduce{e_1}{e_1'}}
                 {\Reduce{\SEQ{e_1}{e_2}}{\SEQ{e_1'}{e_2}}}
            \BigBreak
            \Rule{E-Seq2}
                 {\Reduce{e_2}{e_2'}}
                 {\Reduce{\SEQ{e_1}{e_2}}{\SEQ{e_1}{e_2'}}}
            \BigBreak
            \Rule{E-SeqVal}
                 {}
                 {\Reduce{\SEQ{v_1}{v_2^{\ell_2}}}{v_2^{\ell_2}}}
            \BigBreak
            \Rule{E-SeqExn}
                 {}
                 {\Reduce{\SEQ{\Crash{\ell_1}}{v_2^{\ell_2}}}{\Crash{\ell_1 \sqcup \ell_2}}}
        \end{gather*}
    \paragraph{Typing relation}
        \begin{gather*}
            \Rule{T-Seq}
                 {\begin{gathered}\Judge{e_1}{\tau_1} \quad \Judge{e_2}{\tau_2} \\ \Centail{\tau_2 \leq_{\Ref\Exn} \tau} \quad \Centail{\TopLevel{\tau_1} \sqsubseteq_\Exn \TopLevel{\tau}}\end{gathered}}
                 {\Judge{\SEQ{e_1}{e_2}}{\tau}}
        \end{gather*}
    \caption{\BLAHBLAHBLAH}
\end{figure}


\subsection{User-defined data types}

\begin{figure*}[h]
    \begin{gather*}
        \Rule{T-Nil}
             {C \Vdash \MP{\SingletonNil}{\SingletonNil} \sqsubseteq_\Ref \alpha} %% FIXME: subtyping/-effecting?
             {\Judge{\LNil}{\TyList{\tau}{\alpha}}}
             \quad
        \Rule{T-Cons}
             {\begin{gathered}
              \Judge{e_1}{\tau_1}
              \quad \Judge{e_2}{\TyList{\tau_2}{\alpha_2}}\\
              C \Vdash \tau_1 \leq_{\Ref\Exn} \tau
              \quad C \Vdash \tau_2 \leq_{\Ref\Exn} \tau
              \quad C \Vdash \MP{\SingletonCons}{\alpha_2} \sqsubseteq_\Ref \alpha
              \quad C \Vdash \alpha_2 \sqsubseteq_\Exn \alpha
              \end{gathered}}
             {\Judge{\LCons{e_1}{e_2}}{\TyList{\tau}{\alpha}}}
             \BigBreak
        \Rule{T-Case}
             {\begin{gathered}
              \Judge{e_1}{\TyList{\tau_1}{\alpha_1}}
              \quad \Judge{e_2}{\tau_2}
              \quad \Judge[C; \Gamma, x_1 : \tau_1, x_2 : \TyList{\tau_1}{\beta}]{e_3}{\tau_3}\\
              C \Vdash\CCD[\Ref\Exn]{\SingletonNil}{\alpha_1}{\exists_\Exn \alpha_1}{\tau_2}{\tau}
              \quad C \Vdash\CCD[\Ref\Exn]{\SingletonCons}{\alpha_1}{\exists_\Exn \alpha_1}{\tau_3}{\tau}
              \quad C \Vdash\alpha_1 \sqsubseteq_\Exn \TopLevel{\tau}\\
              \quad C \Vdash\SingletonNil \sqcup \SingletonCons \sqsubseteq_\Ref \beta
              \quad C \Vdash \alpha_1 \sqsubseteq_\Exn \beta
              \end{gathered}}
             {\Judge{\Case{e_1}{e_2}{x_1}{x_2}{e_3}}{\tau}}
    \end{gather*}
    \caption{Modified type rules for multipatterns}
\end{figure*}

\clearpage

\section{Natural semantics}

A Launchbury-style natural semantics \cite{Launchbury:1993:NSL:158511.158618}.

\begin{figure*}[h]
\begin{equation*}
\left.
\begin{gathered}[c]
\Rule{B-Var}
     {\Eval{H_1}{e_1}{H_2}{e_2}\ }
     {\Eval{H_1, x \mapsto e_1}{x}{H_2, x \mapsto e_2}{\Transform{e_2}}}
     \\
\Rule{B-Con}
     {?}
     {?}
     \\
\Rule{B-Abs}
     {}
     {\Eval{H}{\Abs{x}{e}}{H}{\Abs{x}{e}}}
     \\
\Rule{B-App}
     {\Eval{H_1}{e_1}{H_2}{\Abs{y}{e_2}}
      \quad \Eval{H_2}{e_2\left[x/y\right]}{H_3}{e_3}}
     {\Eval{H_1}{\App{e_1}{x}}{H_3}{e_3}}
     \\
\Rule{B-Let}
     {\Eval{H_1, x \mapsto e}{e_1}{H_2}{e_2}}
     {\Eval{H_1}{\Let{x}{e}{e_1}}{H_2}{e_2}}
     \\
\Rule{B-IfTrue}
     {\Eval{H_1}{e_1}{H_2}{\BTrue}
      \quad \Eval{H_2}{e_2}{H_3}{e}}
     {\Eval{H_1}{\IfThenElse{e_1}{e_2}{e_3}}{H_3}{e}}
     \\
\Rule{B-IfFalse}
     {\Eval{H_1}{e_1}{H_2}{\BFalse}
      \quad \Eval{H_2}{e_3}{H_3}{e}}
     {\Eval{H_1}{\IfThenElse{e_1}{e_2}{e_3}}{H_3}{e}}
     \\
\Rule{B-IfExn}
     {\Eval{H_1}{e_1}{H_2}{\Crash{\ell}}}
     {\Eval{H_1}{\IfThenElse{e_1}{e_2}{e_3}}{H_2}{\Crash{\ell}}}
     \\
\Rule{B-Op}
     {\Eval{H_1}{e_1}{H_2}{n_1}
      \quad \Eval{H_2}{e_2}{H_3}{n_2}}
     {\Eval{H_1}{e_1 \oplus e_2}{H_3}{\InterpretOp{\Op{n_1}{n_2}}}}
     \\
\Rule{B-OpExnL}
     {\Eval{H_1}{e_1}{H_2}{\Crash{\ell}}}
     {\Eval{H_1}{e_1 \oplus e_2}{H_2}{\Crash{\ell}}}
     \\
\Rule{B-OpExnR}
     {\Eval{H_1}{e_1}{H_2}{n_1}
      \quad \Eval{H_2}{e_2}{H_3}{\Crash{\ell}}}
     {\Eval{H_1}{e_1 \oplus e_2}{H_3}{\Crash{\ell}}}
     \\
\end{gathered}
\quad\middle||\quad
\begin{gathered}
\Rule{B-Pair}
     {}
     {\Eval{H}{\Pair{e_1}{e_2}}{H}{\Pair{e_1}{e_2}}}
     \\
\Rule{B-Fst}
     {\Eval{H_1}{e}{H_2}{\Pair{e_1}{e_2}}
      \quad \Eval{H_2}{e_1}{H_3}{e_3}}
     {\Eval{H_1}{\Fst{e}}{H_3}{e_3}}
     \\
\Rule{B-FstExn}
     {\Eval{H_1}{e}{H_2}{\Crash{\ell}}}
     {\Eval{H_1}{\Fst{e}}{H_2}{\Crash{\ell}}}
     \\
\Rule{B-Snd}
     {\Eval{H_1}{e}{H_2}{\Pair{e_1}{e_2}}
      \quad \Eval{H_2}{e_2}{H_3}{e_3}}
     {\Eval{H_1}{\Snd{e}}{H_3}{e_3}}
     \\
\Rule{B-SndExn}
     {\Eval{H_1}{e}{H_2}{\Crash{\ell}}}
     {\Eval{H_1}{\Snd{e}}{H_2}{\Crash{\ell}}}
     \\
\Rule{B-Nil}
     {}
     {\Eval{H}{\LNil}{H}{\LNil}}
     \\
\Rule{B-Cons}
     {}
     {\Eval{H}{\LCons{e_1}{e_2}}{H}{\LCons{e_1}{e_2}}}
     \\
\Rule{B-CaseNil}
     {\Eval{H_1}{e_1}{H_2}{\LNil}
      \quad \Eval{H_2}{e_2}{H_3}{e}}
     {\Eval{H_1}{\Case{e_1}{e_2}{x_1}{x_2}{e_3}}{H_3}{e}}
     \\
\Rule{B-CaseCons}
     {\Eval{H_1}{e_1}{H_2}{\LCons{y_1}{y_2}}
      \quad \Eval{H_2}{e_2\left[x_1,x_2/y_1,y_2\right]}{H_3}{e}}
     {\Eval{H_1}{\Case{e_1}{e_2}{x_1}{x_2}{e_3}}{H_3}{e}}
     \\  % note somewhere that patterns are assumed to be left linear
\Rule{B-CaseExn}
     {\Eval{H_1}{e_1}{H_2}{\Crash{\ell}}}
     {\Eval{H_1}{\Case{e_1}{e_2}{x_1}{x_2}{e_3}}{H_2}{\Crash{\ell}}}
     \\
\end{gathered}
\right.
\end{equation*}
\caption{Natural semantics}
\label{fig-natural-semantics}
\end{figure*}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Algorithmic type system}

\begin{figure*}[h]
\begin{gather*}
\Rule{T-Var}
     {\Gamma(x) = \PmSch \quad \PmTy = inst(\PmSch)}
     {\Judgement{\PmTy}{}{}{}{}}
     \\\\
% \Rule{Con}
% \Rule{Abs}
% \Rule{Fix}
\Rule{\color{Red}{T-App}}
     {\Judgement{e_1}{\TyFun{\tau_1}{\tau_2}{\alpha}}{R_1}{E_1}
      \quad \Judgement{e_2}{\tau_3}{R_2}{E_2}}
     {\Judgement{\App{e_1}{e_2}}
                {\tau_2}
                {\left\{\tau_2 \leq \tau_1\right\} \cup R_1 \cup R_2}
                {\left\{\alpha \sqsubseteq \TopLevel{\tau_2}, \tau_2 \leq \tau_1 \right\} \cup E_1 \cup E_2}}
     \\\\
\Rule{T-Let}
     {\Judgement{e_1}{\tau_1}{R_1}{E_1}
      \quad \PmSch = gen(\Gamma, \tau_1, R_1, E_1)
      \quad \Judgement[\Gamma, x \mapsto \PmSch]{e_2}{\tau_2}{R_2}{E_2}}
     {\Judgement{\Let{x}{e_1}{e_2}}{\tau_2}{R_1 \cup R_2}{E_1 \cup E_2}}
     \\\\
\Rule{T-If}
     {\begin{gathered}
      \Judgement{e_1}{\tau_1}{R_1}{E_1}
      \quad \Judgement{e_2}{\tau_2}{R_2}{E_2}
      \quad \Judgement{e_3}{\tau_3}{R_3}{E_3}
      \quad \tau \Fresh \\ %% FIXME: freshLinearShapeFromType
      R = \left\{\CC{\SingletonTrue}{\TopLevel{\tau_1}}{\tau_2}{\tau}, \CC{\SingletonFalse}{\TopLevel{\tau_1}}{\tau_3}{\tau}\right\} \cup R_1 \cup R_2 \cup R_3 \\
      E = \left\{\TopLevel{\tau_1} \sqsubseteq \TopLevel{\tau}, \CC{\SingletonTrue}{\TopLevel{\tau_1}}{\tau_2}{\tau}, \CC{\SingletonFalse}{\TopLevel{\tau_1}}{\tau_3}{\tau}\right\} \cup E_1 \cup E_2 \cup E_3
     \end{gathered}}
     {\Judgement{\IfThenElse{e_1}{e_2}{e_3}}
                {\tau}
                {R}
                {E}
     }
     \\\\
\Rule{T-Op}
     {}
     {}
     \\\\
\Rule{T-Pair}
     {\Judgement{e_1}{\tau_1}{R_1}{E_1}
      \quad \Judgement{e_2}{\tau_2}{R_2}{E_2}
      \quad \alpha \Fresh}
     {\Judgement{\Pair{e_1}{e_2}}
                {\TyPair{\tau_1}{\tau_2}{\alpha}}
                {R_1 \cup R_2}
                {E_1 \cup E_2}}
     \\\\
\Rule{T-Fst}
     {\Judgement{e}{\TyPair{\tau_1}{\tau_2}{\alpha}}{R}{E}}
     {\Judgement{\Fst{e}}
                {\tau_1}
                {R}
                {\left\{\alpha \sqsubseteq \TopLevel{\tau_1}\right\} \cup E}}
     \quad
\Rule{T-Snd}
     {\Judgement{e}{\TyPair{\tau_1}{\tau_2}{\alpha}}{R}{E}}
     {\Judgement{\Snd{e}}
                {\tau_2}
                {R}
                {\left\{\alpha \sqsubseteq \TopLevel{\tau_2}\right\} \cup E}}
     \\\\
\Rule{T-Nil}
     {\tau, \alpha \Fresh} %% FIXME: freshLinearShapeFromType
     {\Judgement{\LNil}
                {\TyList{\tau}{\alpha}}
                {\left\{\left\{\E\right\} \sqsubseteq \alpha\right\}}
                {\emptyset}}
     \\\\
\Rule{T-Cons}
     {\Judgement{e_1}{\tau_1}{R_1}{E_1}
      \quad \Judgement{e_2}{\TyList{\tau_2}{\alpha_2}}{R_2}{E_2}
      \quad \tau, \alpha \Fresh} %% FIXME: freshLinearShapeFromType
     {\Judgement{\LCons{e_1}{e_2}}
                {\TyList{\tau}{\alpha}}
                {\left\{ \tau_1 \leq \tau, \tau_2 \leq \tau, \left\{\NE\right\} \sqsubseteq \alpha \right\} \cup R_1 \cup R_2}
                {\left\{ \right\} \cup E_1 \cup R_2}}
     \\\\
\Rule{T-Case}
     {\begin{gathered}
      \Judgement{e_1}{\TyList{\tau_1}{\alpha_1}}{R_1}{E_1}
      \quad \Judgement{e_2}{\tau_2}{R_2}{E_2}
      \quad \tau, \beta \Fresh\\ %% FIXME: freshLinearShapeFromType
      R = \left\{ \CC{\SingletonNil}{\alpha_1}{\tau_2}{\tau}, \CC{\SingletonCons}{\alpha_1}{\tau_3}{\tau} \right\} \cup R_1 \cup R_2 \cup R_3 \\
      E = \left\{ \alpha_1 \sqsubseteq \TopLevel{\tau}, \CC{\SingletonNil}{\alpha_1}{\tau_2}{\tau}, \CC{\SingletonCons}{\alpha_1}{\tau_3}{\tau} \right\} \cup E_1 \cup E_2 \cup E_3
      \end{gathered}}
     {\Judgement{\Case{e_1}{e_2}{x_1}{x_2}{e_3}}
                {\tau}
                {R}
                {E}}
\end{gather*}
\caption{Algorithmic type system}
\end{figure*}

\begin{WORKINPROGRESS}
We left out
\begin{code}
      w  env  (Snd e)           =   do  (V (ShPair tau_1 tau_2 alpha) C_1) <- w env e
                                        C_2 <- setOf (alpha <|& topLevel tau_2)
                                        return (V tau_2 (C_1 # C_2))
\end{code}
to conserve some space.
\end{WORKINPROGRESS}
